{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NickKar30/GM-HSE-AI-masters-course/blob/main/Hometasks/Base/GenDL_HT1_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ2DRg1TS_np"
   },
   "source": [
    "# Домашнее задание - 1 (базовая группа)\n",
    "\n",
    "В этом домашнем задании вы потренируетесь решать задачу speech-to-text.\n",
    "\n",
    "Вы не будете тренировать сложную архитектуру с нуля, а попробуете решить эту задачу, пройдя по пайплайну, в котором задача разбита на несколько простых шагов.\n",
    "\n",
    "- В этом задании мы призываем вас по-максимуму использовать документацию моделей и получить опыт написания кода без заготовок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p9lL-VPdDCo"
   },
   "source": [
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASgAAACFCAIAAABnkPLKAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAABKKADAAQAAAABAAAAhQAAAAAdA4tqAAA3IUlEQVR4Ae19CXxV1bX+vTfzQEgIEIYwySCjE5RJLCpqFQWf2uKrpa1jba22/m1ra6vPp9T2VV/poK+2VYuiLYojYh2IqCgiMohMIhkgEJKQhJCQebi59/+ttfbe92S4Se7NzU0CZ//yO9l3n332Xnud9e219trDcXq9XocdbA7YHAgvB1zhrc6uzeaAzQHigA08Ww5sDvQAB2zg9QDT7SptDtjAs2XA5kAPcMAGXg8w3a7S5oANPFsGbA70AAds4PUA0+0qbQ5EhowFHq/DxVOCHqfD5VTFIhGBfno4xeVQ2SQi2TwOj7O0tl494nCkxsXop3QaPaXL1GlclJSM7kOXT3etcZPbjtgc6EUccIZuAh3ibvSn2xI3ib5ml1bXFRxv3HekIre49kBx3Ylqd3l1Y1k1YS8lIcblcg1Ocg1PjR+bljhmUMzoofGjU+P1wxpUCorWSpFF/2wTqLoI+7/NgR7nQAiBZ9pCGowVFOAHjSpQwV1XVmH1jpyK9/aVHiquLa1yl1c2eBxNTocnLirSy/rMyQrS3eRtAHIIuxHxsZGx0d4xgxPPHpP41UkDTx+amJIQ4XA1ccko26oJbdSZV2BHejsHQgs8hhwhxmdDCgP+vbNk7bbizw+Wl1bUASvRLmdkhBNgA9IEci34ZE1HvK4Rl8bY6MiRg/rNn9x/ybxho1PitAVr0ag+HGoQtijX/mlzoHdwILTAQ5tEvykwwKRcv6Ps1W1FOw+UuT2u2CgvYOZ1OZxGCzbngsGbiZjMSEGoaaQnByZFX3TGoGvPHTZtRD8uwOhY/BLIyZVv2hebA72PA6EGHpuIovH+vaP4uQ0FgFyjpwnKytr2CFeUp6mxttEN7Qd7MtLliYh0CrSg3JATKbA2zS3EEASueLa6rtbpiBqQFHH1rCE3XZSemhDNhVtUH/+2LzYHei0HQg08NNTjzS2r/d81Wes+K8evmGhWVcwAQAvjN+AwJjYyPipmbFrc8JTYwcmRowfH4X5CbBSu1XWNuJZWNOSXNeQcrT1YXFVR1QhtCSi6op1WVdnk9iJ97ND42y4etWjmYK7BXGyNZ1hhR3ojB0IHPD2+gqJb/kZeXlFVdKzX4ASQg5UIP8rItJQ54xNnnZYycUTC+LR4moEQT4x+nJjkU5ue3NK6vYertudUfLK/LLvwBG5alacUGx/lWnp++i0Xjk4hw7OZaqXS7GBzoPdxIAjgyYAKekybdoIZunofXnPg6fV50GlwVLoiopo8pL7qGtz4OWVU8lUz0uZPTUlLhmWon+00R8oq3Zuyj7+0KX/HwZqquvq4aCoBZieqAPxgoE4f1/+3355AEw8+DNOAkIEt1NpqsNPs7l0ZrWN46pdXf1qwJbOyqsFd39AYE02GEgLiuJqfnNbVS+vypcTLzhm8ZM5Q7b231qJFDmk0re1XzoMAHlfTSrjLqpseeiX79a1FYlvKqMzTQHbmmael3HpR+vmTU2nshweJJnF7clGdv/Czm7NP/C3j4Mf7KszIUPyi9Q1OmJ0Pf2cie1wMxlp1E52vzs7ZGzjgExh6p18cql326v7t2ScwESXUQaQw4IfTGx1/COmFfwFV4IqS693O2MhImfpCFagoMTZm2ZLxi2YO1NACbZA0THRZu3gjhG3Q1TXgafjBe3n/C/tf33KsfzxmCaga0NBQ54T/49aLx/zHjLSUfmAK/oSU9ghqg0aV5OaGMWK5z1vxXkFWYaWoPuAcIIeHJi4m5qnbphL2iDYhhR8JDur+qbHvhIkDImN8zS2t+eHf9+3PPyEvHQSIydMdlBhjCt06vAkQLakFkoYBFFLgcXjs+qnnTx2gsSf3uaNHlORN5rHbpi4I4AE2CIJv1mAu7+pPCu/9ZzYGdZjZhvsEVEL/nDsp6a7F41p5/Bl1GrFtE9VBKrfH480qqvn9Gwff3VmMWUHjd5F6V/zwTM2O5iDvUr0dkGXf7jYOKAl+eE32kxn5WFOB8QVeNHQRdJ1RfUZHhYQMo98wSpJJLIiZgR+qqG3wYFrrsZumzBib4uvlResqMRNrSyG2BVWBuyKUL0QvyGTd+mV+bZ3bHe2IQOmYGa9tcN9y8Wh29McqLUdPwTYQvSf9QQtKOvppGiNtcznHD437601THs9IePTfucaLA/tzX351aXVDagKqRjBqFoRAB7bNhY7qtu/3LAci8e6wmnfHwSq8X6AOamf88MRZ4/t3N1n1noYYl0xWUVXw8B0qqgL8AHpoXawGue/57D/fOHn80ATMdrGoM0UECvx0iai2SWTgwCPZ9Wh5ptI3Z5a/+dnRxGgXkAUnB1hz16KxP/jaGBJ0knUhBTlNXaIz5UabVLWViHpNaXSfe0GX4wdfG5WaFP3gy1l1dR7pkzD98NS7R+6+cpzCfLPCmivAZrfsH72SA/TSmxwuEh4s6KUFTyRJUT9bNOr8qRhiWWSJckLMQhisdiNJzvef2APXeoSDVjgC/HCw4+edT3/5f9+bxEupuGoig7t7UVF+yAlQ+lUpeEoehLu/5oEXswB9cCQ2NgauxUdumAIwMEig5cAlJkIxSJ43j/shqu1koJ1wrqvGmxCmO5bMGQ5r+9zxA5ISo2SECYNk9Sf5lBNcUKS2Xaid2ts5IC+d3iMFDGRwjY5yJcbBvJJuVESRb4fywoWjdrLUBIEeODlh3KISjABhZOEK7O0+VH7Ps5lFFfXk5UEQzwKkrt1eIHCiNQuoXI/zf145QB6OqMj4uMg/3zBp1Y/OvPxszGWbWqV8QQtaoqASFH/8kUroQuf3zI/PeOIHZ4IMdAHQusvXHtydV6krQr1ujVudZv/vQxxweV0eZTHBsVFbX+/G6noVRKisV32nS/+NvHG9gn9doJi7DQ0NSIBDEV7WX/xzH29tAxnmQSFJP9P8v8nUPLmdXwJoht/qTUfX7zwaG+tCP3TXwrGzJyTr51pXyQShS6AHW9/Vz9F/2JASkK11TmuiEM+aEMV6nNNGJNz3jQl4GNg7VtGw/PVs6n6oRuRUr00Xbv/vQxzA68PCJSUYGGJB1TD1IgD62hwbIW2eVKGKhJEJ8C+ZnY55MsxRIxVTaOt3H//Vv7KV0lMZxeDShDBk+AdJdbMSdZZO/Hc5YWQufzMnyhWBwdXC6UOXzMN8ohjZbaKFywQMWE8yGEwt0OPKkGCdTh4aDkKbBWkKQtweiqPNUhewJ1W7oG+xigVuKCxnwVzf6o1FSuOr/Lps+7/NgaA4AGNKnps4JAELNsYN7S/Yg957b2fpvasztUxyLun3RbwRV+JKgh0s8Bye1RsLjlc0YSnzqLT+t14yohnqxNj1NQy1WFBEPROCBZ9Ekw7qrvyUBzWRZG1zIJghDiUGEMrAj9PRQo8Xa8dOH94fShj90IoNR4rK63RdttJT/LP/Bc0BLA/Gs7hWN3qwTGrZf45LTYrF1ALUIOTthY15D750gLBAYOORIcmqMbu0JAdlgNHDReUN7+w6gW0+MLWXzhsCzz77T3EHcIpklCGCnHLVzaSpfeCEnaKcCagormw8fKy2uroJs/BNTZEJcS5MBIxMTRiSGk2eIgQfFA1yUDK3Ac1Td7VadzmxU/a75w/571UVeDSnsOaVTwvJ2SP1cnF0sYPNgWA5ALcKphDlaUzi/c91E3/xry/hS4cNDF/L8x/mDeoXQV59mlEA/BgFhD1+QguzEeVOU0Gy7n1xU8mhIlqy/JVxAxbPTOXSeWUJpvIYEaSIJOIrGDWDFODOCRfQhn2lH+47llPYgK3oGCujz8AdzIHiKtv2EmIjZeP5hVNTZ4xJ1gCjAigwGcpvq9om9cGJErngjNRXP03Zln0MlvBLW45fPWtoWjKm9VoSJCXZV5sDnecATSS6HZAr8wgce/As/OLZL+BRxzQD/AuYWI6Njr7hguFaaFnwYKMqS5AigQPP5Swqr391ezEmEDHEvG7uMJqqJsUq2ozpoZ8SAfy0wuUEnP7wzIYj7+4qgZmKxQGYeUMyugoMyXhuhDY0uLFND3tea917DpdvzT6+8qMj09KTUdGimVieQ3OpPKJDY6QWRESvyhUtcmOHHhZkA3jgAjqIN3eU3jB/GNWv+xuK28HmQOAcgFEJyRc9oZ72eOFZwHaAh17LhNAiEVL3yKuZAxOieDEn5F+gwfPpJL0UCRx4DgeMt+KySowpJwxPmTslieUeAGNtJrRAsYp6QSLBgXRuWaXnifdyX9pcUlZZjQ4jPja6SeMT9jEeAOToz0s4pBRSgbQ+oKnBC3ctEPjK1pTvzh/B06ZsNMs0JVXEPYpUTVdq1IKzU575KCUzvwx1r9tZQsAjqjRhvsx2zOZAABygOTSvC578vYcrP9hzDCM9PJwQ5eoX7zprTPKHu0sgvVLcfauz4Hyl2TXSPZZOn7AXhMbzeN/47Dh0HZ6+4pwBamWWT/KpBlKp5PzhVEKd+4M95Y+sPQQYYMYPqANxmAkxzaWVCdhDxHYz9B6CcaPgJzJHOLxNbue2nBPYE3TdeeW0GE2OAGwGOVQntZNKBGFfnz3koZdpQS0057aD5W3Yq4YCO2JzoHMcgGzRamSn852dR9d9fhT+c1htUHEitxThcqKjo3HGwrIXM2F80TQbzYWwkqPBHom4DzFt1Ks1Et3S8d35VaWVtUiAQM+bjDU7pFvprs5APyn4Sl69seSOf+wR1IE+LGiWHOaKRCsOkY4U+TN5AD+0CdmeyMjFhAktFGgW0KmINtMLXDzeC85IwTJWPAXDYPP+KtZ4zZ6xf/R9DqCrlWAiOqGL/0mcmpfJEg6xB6ggVIIwqD7IM2RVfiKCgDjNsDsdmEyGI4MJAeqkNLW2xAePNuhsZj0qtGzLrkBx2Oo6dWTytOGJPhyrzChQ1oigPKrp8XcOLntlP0iBroOtiwB7MrgArYgHoTCxIwEL5HiewJTEDVHM4gpcTjhF4Z7B8lGYB9sPSvtNfjtyEnEA7934LULVLCXPFmF1Ocek9TtR04R92FB6wBUODcIkNqwz9OyI4wo5xxCM7rYLLNAY8BgPpi0vP3GdOwHOTBNQD0iU2uRKP1e8n//424eaeKMQaDKQk81O5uFORty0DYQCeh2M+oC9P14/MS1JHzutBpaonacW6KcTp3EiJ5y82LKAUyRGp9q+zU4yu7dni8QOVQoseHQRqRTZCwnxRp5NaW7s566odu8rqEZSEi0WdVTUNiFirpIVJmF1nRsCL15687w14h946EUE9BQRK86BqTbUKoO0qSPlZEuUJvYrs4DK5sZ7nP/eWbx8bZagDqlQd1hUDvCgh2hhWNJDHQWDVdLsPOUAREGXPnYjtt6hdBApTGcyKA6QemeOTX7ugyNwk0JLb8ksGz1neEf12Pf7BgdorSZeOoK8d3n5RmhD0Ag9MyxFERYi05Jd//vdiSxspGOxOFP7Giz1uZz3Pr//+Y35sEI9jXrJh+W+Kq9Viv8Ej7eyziMDPEyyDU/F7DYrYrEg8Zyoe2YHdqliZIndihhuSolQd8AbUGey+6/J7x1RmygKZic2RL7zWQlMWSLDGAZUu7wE/HdOSk8cNEDO3nTsOlTlt1z7Rl/jAGk8vHRSCRLY16DEQKd18T8Kpyrg+tO1iIRTLRiqkQOP7yIPCzllRoRB0VHVWkbbySfVcIZj5fUebwQGePjCwcBE2HjNH5ecTOWf3srGTJ1MheslrVQEzF9jcLZTZ+tboiTNKBY/8Ydx498ycAAEOXtUIBrQdnCK2o9588H9iGDEj1U2qj6Sctih73MAb1ksTGoKey+40++GhrH2Q+EAoQSqSIRf24wQe1U7pUMdk3rgBSFt0qMfa/MmJRpLFxFnYWljVTWdwT4kOZK+YQAjE/oLsk40yZUIwvzGhj1lOCZTnDyCGanBzHL4rdD/DQxY0RgpU3IhjpEuDoDAVnTubIQXaDEijEB8eyiJjW2HA59G8V+2faePcUBtCzL9LHf3cLnX83aBrjcG5csw0kRQpjWOnzRBJYHIgA4kjEgCb9vTelJlavbPP/CoJaoU80RtA62Kxk86RI0qiyytrdu0t4IOycTud0oh+D2zIQ/OH6zXlgch+Fa0mNGaKbYzERrY8fQ6MqM0UyYcLZv3n8DRY7MnYCqfgId1pPuOVPE8O6m+/olR6HiwuA4jYDLK1ZEQnanTztO7OUDyxv4FklWXnMgCIyskRNNkHU+FY8qaZpL57HNoGXT9kD3cRS0XnjXggWtPZ4ki80rEj0miH+07NkVFUL5WgW+JUUv31PwDYsDWwH7w7Htwdu13/rz358/tLYUVJ8HjxVQ1ZrrNcWNItqIOP60KUD3ViX9SCK4mYh6C0ntu4yE1wnR4sOoai1a/+cfP139RjL6gf0w01tdBI3s8HrOZ0jxrR/owB0gHsIWJNni8G744gYN/AImQ/KFIQA5/EsGeVxSLk+yQggg8F9BAMOvg9SCFQD2+gRIpMzoridaraNMUSc2Df43XPJ/8wgIZoE52v2OrG5yKmLuAztG+XdTuxMJISWyBt7bKC00alg7sy3fDncNnzjhiCWe0KRgLVu67mlqOTRxOXhbTgPWt9KrscFJwgDQeAiSeFM5tl454bgN59jmxGy/Ug7MrFUuj1JcbZagVSJ0BSyFQh31H63YeX7OlEDoXqEN1yuDGNw+q6z7NOiFLnwMho0t50f0UllTsyC0n4LGKdjnJr4OFmega4IBF3N2k7N4u1WQ/3Ks4QOIOjcTaxuW4/MxBPNwIE4mwntjNwepOdQEBVB0w8Fh7urCRRyoRh4eu0HPwaO3hkkpZsWaGYfpuN/6H3sdswZI5vipE34IGs2C8gbcw+nLYsb7OARJ3MgVVcDnDNYAX2xKeRdQsFqakaEo68V8e60RGnQWmpo7SZJr4V7Wp6TpQWCdmsckThggwBh2LTwuRc1UHQA4Bt+QPdnk0OZ3scDJxQMSdndV49fT2w/CKUQUvDBZ/vrDT5wrpLHuDAF6UcdfATQKB1lVRm3NxlKyHlrGFP+CDXvh+g5nrJLxx44BAAWH4SbJr7GYO4AVD6mC1YQKJJ7R8Ho5uq5kwxnaimJcC+MBNzYCBhwbBXYMgYg2r0jo/Xlyu5sog6+GEHxaM49sxx6pgAFOL4FzBFdoYZFgXykRHBGxaU1Pt0Gs5oFQNXnowkhx8swhpMDUZ7RRnSARSXMDkYoynNInAz7ejh2b3S8rrxBYNG+pADLl98bEuj+NEDZ1ziADniopE0MGjQgzGeOzVlDv29aTggFE7SvQDBkDAXCB3Dgdfj45KA8aR/wda6lBfk8y6GdQPlaI1nsqATkBRFpZ/WHhtVsOwc9VHJ/AGQAp50MwY49kaLyzvJLyViNoh4GHo1f2DHKqCZUyMW9QOgadrYMG/6YW+hIpDHVwuT1yMGRQjh6OgEkCOto3zmkmuE3jzxsVH8vo0oiM81iYIgNJDXwCYsY9HwR5qUBYcIAOIwa685IQo9v8ysfalj3OA3rVATim9CEzkrvq4EPPc3dqyunpvbIxTrleckzZ7HD6cIksUA6vWP/BQDjWpWRcybUwiPuyKQ4Sww030CXKJ5UnVupyJ0fT9PsJquALBm72X+DJe/3jfh11kSgPb76UFoArHJXGLwkWZXU93coCsG5JPMXBoWdVvXsnEcc7R+siTbqpcjaRYwj/JqvrXHVP4ADvWT4FU2S7wTEHSqWDBcUI0Ntrg3CHRJ3Ifxh5HqO7ByWg3zj+j3UCysM2U0U0RaF0v67TUxEjZm2itSHQyUnAGBBaUWm/Z8ZOCA7qL9+D84ih8t9Wc9Cytk6XFiIdqUQc8BbDpolyeqgZPbKQjkpZOwvbTZHSapx0BT7Q5itORr05MxpGdok+s8JMaRw+Ok22y1onNThMTfEbst8eGCe57fIVgdAc7EyoR2/JnjO0/Pi2eO8iAeeQr0Y71Gg74TE0iCZ2+84FvjJs1Dh8zUA627qYUJ2fOm5hMG2HJ3dLMMOxM1R0BD7pOWdJSugufMp91ejI+S4Dvv2IQBbHGpnJuO1S/4+zRyYkJsVjXAkNUZh06Q0RX8sgQDn0OzsNgMmh4iQACaLc7z2qgL/j6XHvvuTCmZ66vvfZabm7uggULpk2ZGjKDXwkn3jhMTey9jKQzZLs9aKuScIFRFQ/HtFrqfOX+u3+URR0J/poHl/eHl45O7hctuMIEugIYG9z46PnYtDgad/kvuHlxXf2FilAdloxOH4ttQTTOtJYI+GHFNrZvYCEf3woXWVYi7Di+KVlevnLlyjvvvPP2H90BEBYWFnaRKzTGE3H3eTKhRVqJaxeraeNxESE4VCBpiDNGmktdGw+1Smpf46FQZFA6hJ6lprpwXvxPLx/965f3A3XGlc8le7BYDucLffxlaVJimBYlA/YgY+igpBljkow9DGLEDAbqcMj8fVefLuTx1cYesyHsl/h4mPqOzzkMGzZs2rRps2fPPmfuecEvsOS+noSfRFRea/e/XKXcuCJgXmgInJn+gUcl8l2FZq5J4h7vknlpcdERy17NOVpWk8zHLXHVyO+57Jy0Zzccqa3z4LAXUYakALUeIgXVqlcyGcyg0aS0jrRuI3b9fO2M/tq5pGqSUSiG1EvnD0tLhrcT6ZYepHUpbaXs3r376NGj5s6oUaMmTKDv7yHYtwLiRl5envAtJoZOhSstLX2Hw5gxY6ZPn37eeeeNnjglIASq5cFdEH2hJ9grhNjsUAU0+GcgZfkHnt9SUAeE2IUvGcBP+Ld1eR9+WcYz1/LREvo65NfOHPLa1gJTgNW9aVAHBMrkm8mGFKM/DVDlWcDPWggeAUTlsF7khH171cyh1HiyOrx1bg+WjHki3CgfeXC8tq7CRHRCR//Xr1+/adMmkZX6+vqFCxca4Nm3AuIGOC1sNCzHT7B07969BQUFlZWVNw8b5kjAS+xs0KYmOlOj7gKW/s5WZs2n9BAn0XCMQ+BeTacXZ7EHFtA8BN9sPSYu4cdXCod7oC8O1V736GfYtAu5F+eHUWXiacTziGCSDbARHQhoIQjerHFK1UHS8cvAEnH4M2+5ePTdV47TFr8XS6X3F1YteznnYGEFkPzojVPhEGox9tNF2v/DxIGnn376ySefNF0YakV80qRJF1100axZs4YO7Rhy2Oq59I+7DxVV4Z1CeP76vSk0eU3uDdOfmkiYGsWnPLShuuR4P/gdMNL53sUjSTgpNOsX2nisI6q5ecrSJRDKvm/1FPUH7smj4q6enfbcB/kRvKwEWs6oMsEhMlNEDr62nKQihVhxJSkCV0kXoOKKgK34Kf0Svjs/nVnAo0pXU0q/yNn9ktAXYA4njpQzXg1fKWaHnuQAVByqh3k5b968uXPnYpjXJWrIjw85UHgDMjdnVlTXsY+9S+V29uH5k1Jx0iYRoODQ2QeRLwjg4SngTXxK0mYDZaEAZdKZu9iKnldcieXKBkhQWRIHkODrb8CCah0w74lRGRZ2ISIf3UQEyMEKNWTxwZUXgiEFYBbT9P4lY/kwaZrM4MAtIpuzRTBEtki3f4aDA4AcVNz5558Ph8rFCy4KUVfIr1zbe39YewjHyIZqorx9poiITh9X8tgtE7GqpBsm0P3V30yHoP2k+igQK4BJWJ6u+64Ze+fTe+RLmQI5g8Dqulpoqnmn98OMJ079SsBJgK0Cuq4v82s/2V8m1gVKACwxjHM1YEMrrcfDkPBHC0+7/Gx8OAUw0wtkWeXSx/o4AOHNC7bh15wf4fp1wQUXLF68uDMmZYAU4YWya9HjxU7oBrcX5/+0WYLITJu3AkqE1HFRTagrp6jWDf1Kw6uAyqDMQWg8FnGqyQixiSCR9+PRWNOLAzAeWjrhzie/wDAMaztxT+zD+jr33PED77hiFKYlOD9uoQRpgChSMSEoERtrV28sxIfBEJdD6iVSXt14zviE2y+FkSnKDfMquCPN8bGB1mo2C75bzZLtH93MAeOUClU9euUK3rv6VulPFo3qnxCEPAdP0aIZg1v40jtfVhCE0ioBXyDrVn4z/OB8JMtbQXHBZHyldvyyF7PEuYJVndB1QN3ym1lBoxTkh1dKSqBiZKE3Y4nNRbiY8TnpH1w8WtUog2mxJJst1RHucwlEH/lqAGJXBDmvDT1B2OL8uH3pdRzgRdJ4y/LeITBO9OPh+ASiGc5JxCf/gbHIiqHAnlSDWp/NyUXRT0RMsa4lc4bDr4gJbnh44OccN7T/A0sn8KcedH7gB9T7AjQqfvK3vkzhiMgf6TSeP1EVAVPWxxXg4djEMW8ANEpNlGlGyUZYtcPJwgEzkieBIfsoREPHdvkjIoQaSQJl/QpX3e5DrW8GofFaF9JuiseLQ53xhRPZtbFk7jD+VhYRDTNy/a5SDOTMHipsc0JZ2O+E65Ck+G/MHUSOE2qh/6CwJGqTeeFwHSmvLalogMaLjnKpvUKqkHaL8l+Jfae3cYBMTSX60str7Pk6/W4iWSsMGlUhLqhTPX7nq+x+4LHEY2fAih+ejdHazEnYOChzgE64oVZ+cEQ2UMF7ia/aAir4Dgki0oC3dhb/bNEogBZnOuA86PZbFeGJbHK5cZpt5tHq1R8W4BsP9W7nOaf1400JRtEFzKD2K7Xv9hQH9AS6oE5ea1herug6urJAkrINRtN2IM0hYis4Ql6TJfMGaaPcuzuv+o1tx4A6ORIX5MMRHBEZidEZUmSuHDPgtz+9Jz5Kxmkd0IItETJLgWEgoItCkqIjbr5wOPWL6r2IVuygHPt2n+GAsmKgeUSMBYTdTH4zNWsgZ2jobO3hAZ7xx6A6BqHDha+6YCqPIMarN8nvH6k8kOT8RC4OmOvzNGARmAvTev7ahLvw8EJnYgyJPMiXGBszPDUWZ3orxyl1TuL2BMDD8nr80Wqnh5gDeNsiw4iE5c2SrpM2WGewAsZRwA90jW/CHUi/Z8yQuGnpybSPIToCPk9nRGNtowc4pGn0OooATtGxjpvPGz4oCV/A9Buw8RFbEs21qSkyIc6Fs2HOHJWMJSz8GK6oFxce4IXl7fgl174RQg6QmSdzaCxXHi++BhWe79LwbHIkCxiqJmuuA09Eq1aHAXgs9BB9mmnQi2s8OEUi9rffnvDYG4fxbWd8BUIIw756Oe8ZEeyrh8q6/OzBCja6n2nVBGa6QAt5lM2NV4LnwA5WcYAcDFAxyls9byf0VQ6I1UfvH72pZ+22Y3/JOBTOtiyeMRBzXVSjMnoDqDwMwBMwyHoCmaZThMK9iS9Kl1XCPnaYEy/lBD6Py6031VOz2m0Q3yVoQaGJPYkUo9wkgqu0NGBbvN2q7Zs9xgG1LQiyQe+fXutf1+ftzasIw2FHYmti5UpeWfVlM9LYS9++iLbBpa4DT5SVSL8o3OYqCJUKJIhDDAMfGfSUxSD03dA4aZHfksGq3EXLkdIz7Tc0mBR+lrSupRA72mc5oL2abNHwS73inAH5pXWYQApPmxoaPVfMGDg6BeMg/1Lqn5QggMcyraw4FCztRCK0jZTGKaSC2N5TdZts5hH/RLV5R6FLYIwrCpfy0efpiOQRvU9xGQCgOCYPpKpFNm1WYCf2NQ7Qi9av3uGG1Qf9U1lD63i7O8A1iPlhbARl2QsT8AAhyDEqk4i0EXEDLY74mGJlguRBCqPXeqfDuMDJlw1FoRBcRPObSiVFLBBkwIuBrQsEBtHF+CqzY72NA5Yd6EIarR2jz0SmhoFSWa6sMU8SyGIWSM2BiyNVA7FmmSaB5tooUeMecQSXN7e0LqeoqvR4Ez4hdLi0Wj4NWd/QYtVyZ4n1uJ2uSDo7EWfmYmnL8JTokYMTRg6MS0+OI2PVSoChhOkQYhjpoDBwwHeWQDtfT3DAZ/hA5Ey33q2UGNTp6kjerPtxO1V74MBDU0l6RcPoOiQRmwlqG/Btyvf2lO7NrTpS0YQPtTZ6SPWLVpLc2FiBSKDbNPR2DCrDlDCgXxwONRs7JO6M9KT5U1PobBXlZZGquB7qG0QB8qPmjh3pyxxQYzwZX0lXq3p8rQC6q3UiS9KJSz8OAQsYRwE/QJCB2UYaxqpeXbllNW9tK/pwH315HOuhZfEXjn7AJnRwQO3HY7Q6hUFKV3aePdbqvDztTh+m3Z7dgJOtX3DkYfn1lPR+X58zZPaEZK3ZuD7qJxCYRy1h2fna7Zy9jwM+vAkA0MF2N+qYCQrh3KFTgujAwKoOAngizahO7ExPVmHtq1sK399Tll14gr+QLh9GJ1xiO1xTk5cO/GKqMJdm9sJ28TWaQ5Nwrq6nwRkdHYf9slmFle/sPHrupIHXz09n+EklIBgvhltKFnJgDOoinfbj3c4BApuIF64agd1YK/bNQJZQEUw/QACVQsB4eBVIpcECj+rD9oL617eUPrfxaF5RFZZ0JcTGyRkNsu8bccAMp62AKFkXFjLU6WaiQDnQBXWhIjlh5b2dpR/uLrl67jCcxTJ+KLy90lOE4ZUEwng7bwg4gHcKMYT0UyfPfavWCiEo3E8RakZKenPJo2en/TzRZnL7wBNhbXFFOVQrVjn/5uWc7dknYqPg80Ci03cyCpuX1vqMgrImBh1vH8Ax0XgNztUbj767q+SuhWOXzB1iGXabF8OHEYbHMgm6nfaDHXCA3yZdRO10kDs0t30y0yXHgRHEdqhCHogp2obArnmHY/XGolse34nvdUHRkdrRKqidUsJ8CyYojnv55fP7bn96V1F5HQ1KyTSnVTIciaRuUo02YaP3vgaEmV92deHlQDvAY0UnEknqlWxLEdCH12Tf+3wmxDomNlLO7WtfBYW3Rao2MUGxOWjdZ+U3Pr4Xh39yE9g6l07LZ6K0w4Qeod2u9OTnQDsyx4pO1ALZ0MCdE6u/f/rs/icz8qFP4DIhZ0k7BfQO7oHUrPyq7z/55bacMuo7ZMiHDgXUq+Ef/os+7x0U21ScAhxoHzc8AjRC6fLe/8L+1Z/ky9Y4aDl89jG0g7cQMtxYv6AQoz64f25/au+2nBOMPSANXQlPilCVQKMdbA6ElQPtA48nKIgeynbv81kw2/CJElc06ToEeFOMfNPv3hRgHYM2+YNaBvaOVTTc93w2fEJMJloEZxSmG0XX2djrTS/vFKDFP/BkdEcIo6Hd4+8cxDG9EF8ZzkGsZc5AfvZCgxOKDrTJn6hljPdyCmvgiSVfCwXBHlSffyacAhJgN7FHOOBf5sjCxF1Ym64Pvij9v4xDEFwhEXKMjxbI5IFoPJHsHmlAO5Uq2rTeow8MxXrhiX1kTa5yb1IDpVGqae2UZt+yORBCDrQrcKT0PNAPv1tzEJpP5FjqNh8hEY0XQoJCWJTSxlrvgWZ0EDjT+vWtRas3llgqsu1MCzN6W5SF0DoOhxyaGWMxx9RdsdF6iv7mdMpyYrlqIgVrLGye9m1EHgI9+vYhLMWCH6U3YywgbnsdjcvfzMkqxGAPXLBRFxDzwp5Z+fZc5jAVyCGGOeoIdxgs5Hjngbr43sNOoKqQage0lCZTDkiH7MUBkaDQImkuZzsaD/ncm7NPrNlSCOBa+piealnI6sXRnccrmvBJTeaFWhIQstLtgkLLAa3HcBoICsYklhSvj3DHL8YepUKYLcIt+cJ5FaXn8eJcZnzoCjVHueTEE0QthPGtdoCHW5F/yziIrQYYGuFRaEertRnOFoW2LnSZWOa27vOjmzOr7DUroeVt95SmpBRHYOF796hCqwEtvco1DfFWsOweMtovVdQakYT9onCXQy3LnjiNOqFWsmnN2EaRHu/mzHJMfJlPmWOYd/JYm0766NdzGw9Rw1uYAW3wwk7qOQ4oUxNbryNx8Bw0Hnp/ZWrKAkB6g3r1n87cE+RCIUOtkWbzupqg67A1B5t1NCW6j6DflKe9RdKQy/oGJ6YQ0E70MRjm6Z5Gl9YH/+O1ofuA9oYVvmFPGWxpfE6MrZQ+2JhTh2SPV0xNaDxgDzK9eX8VfxWDPjHbqwJOXz5QgJOQmuhYdIeDz0HXqBOzmX/5BR4WN27JqoF0Yi+d4O0kQJ31DcHJiW7ljc+KLDv3rPfteO/iAA5iHTEwZn++2t7594yclR8dMSS6IKRQEHw1iT0SqWmsF+c5OncorTFDLR8ggEIm7BHy/ALv3V3FxytrYWd6+aPHvXOmLgjO0ooWD5od5fE2YqS3PacC8yUdf5MoiJrsR0LCAUgq5JVtSHwI8uN9x9z8OW6YLTh/ADUYv4O7qZFdL7wBJSRVB1UIUAXbEDq5ts5z+vD+c8cNILAJ5GASE+gIfqz2pALRg7QDyIvvuOMQB5yjTuM6/rZBUDT0xoekB4H2JoPT6cBalg37SnnpZm+k1qbJMgL34Fjxb89Ph8MQpgrwJpCT94grTBgT75GITLnhiq+vltc2jUrr/8CS0+gkLu41+EqopHeKTxXQP0EkxRDI6wJv+8HiKmoJ4KkdofiB9vT10LoVO/NO4OuZfb1dJzv9kEKIrOfuK8dNGZn03IaCfUeqId+9qtXw8IAeaOLUpNiLzhh03ZyRk0f5/eyHxdQUXDIid+SWA3v4ZggVpIF3EqDO+p7EY4TDzjAUhobHEMJ61473Ig5gksAnnKT3Lj9zEHwQcGP0IiKZFPlI4+B+UfxtdCRJf9EGmQw8ahXnINVHg79dh6qQ10Cujef6fpL4ivBxr5yiWvQyqQl9v0knawtIJtknQfKpTLXxQ3vbCzO9ALwp/L0QA6u23gs3o9kNSskvrcG6KkTEjG52v4//aKG38RM+pPzS3mW09HEeh5x8yKTCGw2LemmQJVBMqm/sZrEom5PN7aEkE8HZYXXFFR4c62DNefIh0Nq6gyW9bjrISt6pHSdvXyu8GfXSm3ijVBzv8+yIrmboEjuzss5TWllLG/Gg4LU3xUQ6KrCP3ZcOJc/WeL33vcEraCEOwk1KD6M+S2JviWImQwBl+gW/VOKGOsLIEN/Y4K3Cd5KbaM+rdboB3giTp09HWjekorqHJ3/6ND+7l3irbSlxYI9Gfb0wWFEnkDMIbEktsiKHNAOZCIdwFuFjyPjunoO+KG4NrAStCeGN45uDRJUOLX7q5M78b9mQ0ip7jNcZvvVEHrLfdPDFRax1uvU/wOnLZr0RtrihzUTaqJoxqgiVfC44Q3+yaEwbeU/SJHw2vdm6npO0madKs3oYdZ1ls9Pr9emQzj7kN58o1vaA7vfRDm/4erKQ1GIKUXre4l7qkBQ7g82BrnKAJxyoEMif/EmJgY95yP4G5PDHMi3meFfJa/N5DWyqgutqM1cHiUKqZEIhuswOnrJv2xwIDQdCq/GEJpZjpaBCKNOCMUGIxKW6rmPGWnJo2GqXYnOgfQ5AaiF2Wo6VmtI/23+09V2lghgJZGoHW07rkimFi0UVVAvi8tMy8m77qbZSVTPNLfv0B8OKvh9p+XKlRaEVxRBwSUtwy6KCIlQ5ec2z/gpvWVmnf2MBdxP7rKQKtYu+04/rjESn2NKa1D4yItcNsP/750Abr1K/Zf8Phf+OfNsVCGHiaCEcR2hZahDE0DM5Wzd8tPcgIpNmzp81OXTeUfRkxFMmi8nL+nTtS9sb7rntmsAJlUJk4Z+8lWBaG3i99hPh5wCdhr59x2dSMT5R3NCgZsmmTz9biVP4iaKJdtVDGMnjiPkVGE3ulffcsHztgTPnTm8szVr9et4/n7mH9iOZQOCBtgG6Zb05hB41EWuIDHO3NejVLQEelFUEMtcXHdm19XhbTyGDpVJTe7MItKX8DrKpzQqzf/QeDqgOGmLFkoZvANedeOHX926vaEisr9yx//DI08fFxMQkDTzt0RVPpMdzNpJJEYOWAnn8aGZWeTTpj3aEM6i2dyigAZR68OPnfrkm86V178we1l+vLeD2KKIh6xih8aiMmoqItBOt5p/UBfBd4Z1cpX5zi36is9AP+qiT9eCGg74bduzU4oBSJFgwCfmCOEU64lMffvlN9Oz1BZuvXHDnI6vemjain48nlB9igyAKABHdKbuaCra998dXj69acQ8DExnwvTrO2+VLCIHnOXa8rP+k82enJ6vOhpvucNRlZh+ZMGHClnUvb/oiLyIu7apvfzM9XlbcRRw/un/l6rcqKysvuWbprMmjdMfjQOZ3Pv0iefC4Jddepbc2ORw1pU+vXnv46JGx48659LILa530CQT0SSihuLrxhhtvG58Wz3wJYaO6zGC7gPBzgLpsrhWgku5bodFKimfLuletMrZ7996BAwcOHTqU9YFn+/adyL3h092ZhfUZGeuHjpg4deIIDVFrOUHGQ4Rf1O5xnjF9TtP7z/9h1ada3SGVyn/y5z++7prLfvvU2wDY+tf+eOXVN20+Uo4eKGvrGxdecuPWgrKEusLbFl/xh1VbuRHuf9x/1Y3L/u6Ncu56759XXHpNbmkN0jGiO2fexe9vImP97TWrNu2tGDggZd/WN7967Y9QbNWhzRcsuHBzAb7ChQB9aIdTmANkQCGwbBPkIA/yR6nVTiwYdC//1e2QsVpXbN7bK89bcAuOFS/64LkrbrgXW3MgyRuefeCGWx7ctm3bhg3big7vWbNmzdZd+SGWK6xcCU3AKU9e75bXl48YmHb7HQ9mFlThsyZeL5ZaV183Ytjkq+/WtVT/eN6kb/3X35G++NyvLP/XZs7mPbBxxZR5lxyrqpVIXjUepQLvvu7ib/33y3V1uVdeOpMyU0CZdEXO/sNPf3dvEf/yUE4qtkke5Dz25RTmAOSHRciwoC7/k69NnAXRgpROO3sxyRiFJi05jd84d5wI2zljJ7+w6Qju7V7zl/+8/tcscpA6ETx+qMuX0Gk81uZfWXTH5zs3xJd+9NXpc1d/WoBep76+JHrctIfv/Qn1NtTxxN/8szvy8o9kfbo+x5ky98zB8DhlZGSUVPeLLKvKKqvLeGrtyEHzivZtz1j/7vbt208/Lb4pd9/hz3cdKBry/745i8vgcSC6rtLaWYuWLpg8mBJdzoWXzmo6XMxxdHi20iNOnNIBAok/mJryZxGJ3Vs2DJ31FZKxjIzt23ecNn7cjj3ZGA0+9PvluRnLr732GxPOu27JHNicOmCsKH86oev/QzccEmPaEzFg2Om/++e6uQ/e9f1rFo7csmF2+iBQmZoQrdS9xxmTlj6s6TgSo6tLnv3L700bzrvw0vQByeubnIdLNq5YUaTT06+4/Oy8A4fAKbbXZQ4AN6nLGFCnjXjUDl/nSIAwdF2JpsD+36c4IH2uiAFcLEYeVH+NtkS6+7kz31+x4qhul2vpgpmIj5+16MYLnrrpoU15Vb9iYTP32V4Vv6BO6+L/0AGPNR6P7ggDV/7Xwys+OXfH3rLZ6Wn4We3myRNyCjkLMrcURBA7Ro2f/thjj1kawHuNHY6zLrr1sfuvpnQCMzlC97zx14Nb9lMHJg4oAbk8qTyibNa7Uhne4uH0MdpShR092TkAeIgoUkMZdUpamhlBV9z8G2VAUTY1/wS359vv7z37rPRnn3651fwwXJ3wapJtRU90OZj+oMsloYCaUm4qUeeoOXGi4HhqEhRddEP27hUvblRccNT86Xcv/ceChSPPOqP8yw/woVmlCR3uzMwDgNm8iybtWvPMEfKnUCOPF2QVVdQPm3FhvxOf4fPrqhA1euY81n7IU0omAT/I9+zLqceB1sBQKT5RHzV59L/+9CD7UdBfewoLS/gjwTUPfv/H0Qvu/uSNv/z51w+u/6KY+n1faIZbX3KwsdBpPIdj6/qVV/38+e986+uDE6JWrlw5aO53F5wBFdQwaFT/l1743VVfvHXlZee++eRDpbOv+87iM2NiYh9ddtfCpXM23nDrxZPHrFv7gjdp3qoVv5r/7XtmvbHkipnn3vnTW45nbXllw64fPfLCkjnjH1l2+/WLp39+508mDB+0dtXa65c9PsRZ1wQHlbCV8VZSXMQaEolgmY/RwTLHfu5k4oBCTllpJWTskhcvuHTBNTffsLj68M5/fJjzuz8/m7jn0XXFA1/9+S0x8Y6Hbhrzw5vv/jjjrxgWZX702C8fih4//rwblswMlboDW0O4O8HjqCl7bd1Hubm5KHdQ+oRvfX0hlHh9ff73L7t16WMr87a8KVNwlK5tyJztH679eIfkx9RcalwMY6buvVXP7CqiA4jmXHKlmd/DjMK/P8kxmZ0nDhVUxNPsCvdMepEBJltkHVxoTAJUZ4eThQM1GRkfz5h9Aa+mcr+36gmrjGGyLuW0GTPG9qfG1pS9+cbWWZefD98Epvsw/3zWRUvPnzowhHwIHfCMJa2MPaVz6usPCfCU+7EF7fQUqS2toGT1gKh4o7Iw9sPgUAqUfsvc4p+oUZkTMNZNUS1qsn/aHAAHjPwgIlLEIoc7EDASJG0rcW/OciUyiX7cPBICThoJDkFZijJgQMGgeZnUEsEJ40p+Uk6GirQTcaQQdDVTqAxZUCopfPUVxTlVdSgcug4pdrA50IoDImA+0ZIMGksih3RFCpAGfSBizBJLaERyKEVLpLkVlUEkCOkKEkwuFxITM2j2BV8d3C9Oo1FOHdRXysM0yHGCUi8VZQJzgT+lonCLO8ggXBCOqLwoR4o1z9oRmwOaAyRUEA+GENIgPySrIns6kfLC68GJSpJlr2brbLrYYP+HztSkrgKBSRRqiHQGCf0Tc1FPuyFB7lIGaT8e52kAyqwTkUdAqCKWPM3AiQd07ZRTM5RLsi82B5gDWkLwwyokKo5UiK4lj8rGOsCan8vq+iWEwNNYUp2KIJChQu3BT+tQjZrFicIF7o3QCUm3JOil1lpVnzximszlG46ozLpMk8uO2BxQHGgxlhONBxlsIWPIrcWVtJ/+2YY08s1gLyEFXrBE2M/ZHDjVOCB66VRrtd1emwM9zAEbeD38AuzqT00O2MA7Nd+73eoe5oANvB5+AXb1pyYH/j8ar0jQrnvQSgAAAABJRU5ErkJggg==)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/host\n",
      "all_pairs_1.json  \u001b[0m\u001b[01;34mdata_russian_speech\u001b[0m/               \u001b[01;34mwav2vec2-large-ru-golos\u001b[0m/\n",
      "all_pairs_2.json  \u001b[01;34mmodels\u001b[0m/                            \u001b[01;34mwhisper\u001b[0m/\n",
      "all_pairs_3.json  result_array.json                  \u001b[01;34mwhisper-large\u001b[0m/\n",
      "all_pairs_4.json  \u001b[01;34mrussian_spell_correction_dataset\u001b[0m/  \u001b[01;34mwhisper-large-v3\u001b[0m/\n",
      "all_pairs.json    urls_normalized.tsv\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p /content/host/\n",
    "%cd /content/host/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LHP5e6rrEXzd"
   },
   "outputs": [],
   "source": [
    "# Установка всех необходимых пакетов\n",
    "%pip install -q pandas transformers datasets torchaudio torcheval evaluate openai huggingface_hub accelerate dotenv matplotlib\n",
    "\n",
    "# не обновлять pandas выше 2.2.2 - требуется для Google Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJTV1KLsgF99"
   },
   "source": [
    "## Шаг 1 (1 балл)\n",
    "\n",
    "* Возьмите датасет https://disk.yandex.ru/d/v2Hipv7XG4fEDQ, содержащий русскоязычные аудиозаписи\n",
    "\n",
    "* Примените модель [whisper-small](https://huggingface.co/openai/whisper-small) из HF для определения сказанного в аудио.\n",
    "\n",
    "* Выведите результат работы модели для 10 случайных аудио из датасета\n",
    "\n",
    "Не стесняйтесь пользоваться документацией и источниками знаний из интернета!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GBIYfUYn0Ds5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "import json\n",
    "import torchaudio\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим список URL с файлами датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 URL для скачивания.\n"
     ]
    }
   ],
   "source": [
    "# предварительно сохранить файл https://disk.yandex.ru/d/v2Hipv7XG4fEDQ как `urls_normalized.tsv`\n",
    "\n",
    "DATA_ROOT = Path(\"data_russian_speech\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "TSV_PATH = Path(\"./urls_normalized.tsv\")\n",
    "\n",
    "urls = []\n",
    "\n",
    "if TSV_PATH.exists():\n",
    "    with TSV_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in tsv_reader:\n",
    "            urls.append(row[0].strip())\n",
    "    print(f\"Найдено {len(urls)} URL для скачивания.\")\n",
    "else:\n",
    "    print(\"Скачайте файл https://disk.yandex.ru/d/v2Hipv7XG4fEDQ как `urls_normalized.tsv`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачаем аудио-файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79b66465d6f46338e449e00b80589e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download_file(url: str, dest_path: Path, verbose=False):\n",
    "    \"\"\"Загрузка одного файла (с прогресс-баром).\"\"\"\n",
    "    filename = url.split(\"/\")[-1] + \".wav\"\n",
    "    target_file = dest_path / filename\n",
    "\n",
    "    if target_file.is_file():\n",
    "        if verbose:\n",
    "            print(f\"- Уже существует: {filename}\")\n",
    "        return\n",
    "\n",
    "    # Потоковое скачивание, чтобы не грузить много в память\n",
    "    with requests.get(url, stream=True, timeout=30) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"content-length\", 0))\n",
    "        with tqdm(total=total, unit=\"B\", unit_scale=True, desc=filename) as pbar:\n",
    "            with open(target_file, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:  # могут быть пустые - keep-alive\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"+ Загружен: {filename}\")\n",
    "\n",
    "\n",
    "for url in tqdm(urls, total=len(urls)):\n",
    "    try:\n",
    "        download_file(url, DATA_ROOT)\n",
    "    except Exception as e:\n",
    "        print(f\"Х Ошибка загрузки {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции загрузки аудио-файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено: torch.Size([1, 36160]) @ 16000Hz\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "\n",
    "# Очистка памяти, чтобы влезло на Т5 в Google Colab\n",
    "def model_cleanup(model, processor=None):\n",
    "    model.to(\"cpu\")\n",
    "    del model\n",
    "    if processor is not None:\n",
    "        del processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Считывание WAV-файла и получение тензора PyTorch\n",
    "def load_wav_file(filepath):\n",
    "    \"\"\"Считывание WAV-файла и получение тензора PyTorch\"\"\"\n",
    "    with wave.open(filepath, \"rb\") as wav_file:\n",
    "        # Параметры аудиофайла\n",
    "        channels = wav_file.getnchannels()\n",
    "        sample_width = wav_file.getsampwidth()\n",
    "        framerate = wav_file.getframerate()\n",
    "        frames = wav_file.getnframes()\n",
    "\n",
    "        # Считаем аудиоданные\n",
    "        raw_audio = wav_file.readframes(frames)\n",
    "\n",
    "        # Конвертируем в numpy array\n",
    "        if sample_width == 1:\n",
    "            dtype = np.uint8\n",
    "        elif sample_width == 2:\n",
    "            dtype = np.int16\n",
    "        elif sample_width == 4:\n",
    "            dtype = np.int32\n",
    "        else:\n",
    "            raise ValueError(f'Неподдерживаемый \"sample width\": {sample_width}')\n",
    "\n",
    "        audio_data = np.frombuffer(raw_audio, dtype=dtype)\n",
    "\n",
    "        # Reshape, если многоканальное аудио\n",
    "        if channels > 1:\n",
    "            audio_data = audio_data.reshape(-1, channels)\n",
    "\n",
    "        # Нормализация к диапазону [-1, 1]\n",
    "        if dtype == np.uint8:\n",
    "            audio_data = (audio_data.astype(np.float32) - 128) / 128\n",
    "        else:\n",
    "            audio_data = audio_data.astype(np.float32) / np.iinfo(dtype).max\n",
    "\n",
    "        tensor = torch.from_numpy(audio_data)\n",
    "\n",
    "        # Приведение к структуре (channels, samples) для PyTorch\n",
    "        if len(tensor.shape) == 1:\n",
    "            tensor = tensor.unsqueeze(0)  # добавить измерение\n",
    "        else:\n",
    "            tensor = tensor.transpose(\n",
    "                0, 1\n",
    "            )  # переставить измерения (samples, channels) -> (channels, samples)\n",
    "\n",
    "        return tensor, framerate\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# тестовый\n",
    "audio_tensor, sample_rate = load_wav_file(\n",
    "    \"./data_russian_speech/00760e69-35b8-4c65-84f6-c1d0e82907c2.wav\"\n",
    ")\n",
    "audio_tensor = audio_tensor.to(device)\n",
    "\n",
    "print(f\"Загружено: {audio_tensor.shape} @ {sample_rate}Hz\")\n",
    "\n",
    "model_cleanup(audio_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path: str, target_sr: int = 16000):\n",
    "    wav, sr = load_wav_file(path)\n",
    "    # Многоканальное усредним до \"моно\"\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = wav.mean(dim=0, keepdim=True)\n",
    "    # пересэмплируйте имеющиеся аудио в 16 kHz - пример кода ниже, можете его менять\n",
    "    if sr != target_sr:\n",
    "        wav = torchaudio.functional.resample(wav, orig_freq=sr, new_freq=target_sr)\n",
    "        sr = target_sr\n",
    "    return wav.squeeze(0), sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ключи и токены\n",
    "\n",
    "Следующая ячейка инициализирует ключи доступа к OpenRouter и HuggingFace.  \n",
    "Ключи считываются либо из секретов Google Collab (если достпен), либо из локального файла `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yeWbkBn5X_xN"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    # Если в Google Colab, то используем userdata\n",
    "    API_KEY = google.colab.userdata.get(\"OPENROUTER_API_KEY\")\n",
    "    HF_TOKEN = google.colab.userdata.get(\"HF_TOKEN\")\n",
    "except Exception as e:  # если нет usertada, то будет исключение\n",
    "    # Тогда читаем из .env файла в текущей директории /content/host/\n",
    "    load_dotenv()\n",
    "    API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Для теста можно задать ключи вручную\n",
    "if API_KEY is None:\n",
    "    API_KEY = \"---- ВПИШИТЕ СЮДА КЛЮЧ ----\"\n",
    "if HF_TOKEN is None:\n",
    "    HF_TOKEN = \"---- ВПИШИТЕ СЮДА КЛЮЧ ----\"\n",
    "\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = API_KEY\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка модели Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_files(\n",
    "    model,\n",
    "    processor,\n",
    "    wav_files_path: str | Path,\n",
    "    output_path: str | Path,\n",
    "    language=\"ru\",\n",
    "    task=\"transcribe\",\n",
    ") -> list[Path]:\n",
    "    \"\"\"\n",
    "    Функция для обработки аудиофайлов моделью типа Whisper\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для транскрипции\n",
    "    - processor: процессор для обработки аудио\n",
    "    - wav_files_path: путь к папке с wav файлами (str или Path)\n",
    "    - output_path: путь к папке для сохранения результатов (str или Path)\n",
    "    - language: язык для транскрипции (по умолчанию \"ru\")\n",
    "    - task: задача (по умолчанию \"transcribe\")\n",
    "\n",
    "    Возвращает:\n",
    "    - список путей к созданным txt файлам ([Path])\n",
    "    \"\"\"\n",
    "\n",
    "    # Преобразуем пути в Path объекты\n",
    "    wav_path = Path(wav_files_path)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    # Создаем папку для результатов если её нет\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Находим все wav файлы\n",
    "    wav_paths = list(wav_path.rglob(\"*.wav\"))\n",
    "\n",
    "    print(f\"Найдено {len(wav_paths)} аудиофайлов для обработки\")\n",
    "\n",
    "    created_files = []\n",
    "\n",
    "    for i, p in tqdm(enumerate(wav_paths), total=len(wav_paths)):\n",
    "        try:\n",
    "            # Загружаем аудио\n",
    "            wav, sr = load_audio(str(p))\n",
    "\n",
    "            # Обрабатываем аудио через процессор\n",
    "            inputs = processor(wav, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_features = inputs.input_features.to(model.device)\n",
    "\n",
    "            # Создаем attention_mask если его нет\n",
    "            if hasattr(inputs, \"attention_mask\") and inputs.attention_mask is not None:\n",
    "                attention_mask = inputs.attention_mask.to(model.device)\n",
    "            else:\n",
    "                # Создаем маску внимания для всех элементов (все единицы)\n",
    "                attention_mask = torch.ones(\n",
    "                    input_features.shape[:2], dtype=torch.long, device=model.device\n",
    "                )\n",
    "\n",
    "            # Генерация выходных токенов\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                attention_mask=attention_mask,\n",
    "                language=language,\n",
    "                task=task,\n",
    "            )\n",
    "\n",
    "            # Декодирование в текст\n",
    "            transcription = processor.batch_decode(\n",
    "                predicted_ids, skip_special_tokens=True\n",
    "            )[0]\n",
    "\n",
    "            # Сохраняем транскрипцию в файл\n",
    "            txt_filename = (\n",
    "                p.stem + \".txt\"\n",
    "            )  # p.stem дает имя файла без пути и без расширения\n",
    "            txt_path = output_path / txt_filename\n",
    "            txt_path.write_text(transcription, encoding=\"utf-8\")\n",
    "\n",
    "            created_files.append(txt_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {p.name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Все файлы обработаны!\")\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> При наличии токена HF_TOKEN почему-то иногда подключение к HF зависает.\n",
    "> Помогает перезапуск ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ea4e069ad54631ab6a0ae66fb62f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 аудиофайлов для обработки\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e46199c33814209858e0e661dbe7ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы обработаны!\n"
     ]
    }
   ],
   "source": [
    "model_name_whisper = \"openai/whisper-small\"\n",
    "processor_whisper = WhisperProcessor.from_pretrained(model_name_whisper, cache_dir=\"./models\")\n",
    "model_whisper = WhisperForConditionalGeneration.from_pretrained(model_name_whisper, cache_dir=\"./models\").to(device)\n",
    "model_whisper.eval()\n",
    "\n",
    "# Используем функцию для обработки файлов\n",
    "created_files = process_audio_files(\n",
    "    model=model_whisper,\n",
    "    processor=processor_whisper,\n",
    "    wav_files_path=\"data_russian_speech\",  # путь к папке с wav файлами\n",
    "    output_path=\"whisper/txt\",  # папка для сохранения результатов\n",
    "    language=\"ru\",  # язык транскрипции\n",
    "    task=\"transcribe\",  # задача\n",
    ")\n",
    "\n",
    "# Очистка памяти\n",
    "model_cleanup(model_whisper, processor_whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отображение 10 рандомных транскрипций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 случайных транскрипций:\n",
      "==================================================\n",
      "8eec6bf4-818c-4852-8063-0bcc5d2e7175.txt : Угладиатор\n",
      "703e7d9c-b170-4762-b5d3-c4fa8e4be0e8.txt : Николай Каперник\n",
      "d5bd3785-733a-4a95-b3ba-4d80ece002ee.txt : Однажды в Америке\n",
      "163e0da8-750f-45d4-b5d5-8982fb060c12.txt : Новый кинотеатр пародизо\n",
      "ce29f3d2-8c47-4466-a2b5-7bcb73b0eb02.txt : двое\n",
      "5fdd45c8-59c9-4c90-bf81-e426cf597f40.txt : Жулианна Мур\n",
      "2a6d78d6-5b79-4ec1-bd9b-29b59c1960c1.txt : Дай не трехо.\n",
      "fcceeeb4-5bb7-460a-853c-99c3c7bd5aef.txt : Андрей Сахаров\n",
      "53085fa6-1df6-4d46-ae00-4ce2b89ac0ca.txt : Интерстеллер\n",
      "871a6ddc-77b3-45e0-ab4d-2bdcddb78515.txt : Звездной войны. Эпизод 5. Империя наносит ответный удар.\n"
     ]
    }
   ],
   "source": [
    "sample_txt_files = random.sample(created_files, k=min(10, len(created_files)))\n",
    "\n",
    "print(\"10 случайных транскрипций:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for txt_file in sample_txt_files:\n",
    "    transcription = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "    print(f\"{txt_file.name} : {transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rrbQapLh7w5"
   },
   "source": [
    "## Шаг 2 (1 балл)\n",
    "\n",
    "Текст распознается с ошибками.\n",
    "Попробуйте исправить ошибки с помощью готовой (предобученной) модели spell correction.\n",
    "\n",
    "Выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели https://huggingface.co/UrukHan/t5-russian-spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6EJIcfzWL7Ox"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name_t5 = \"UrukHan/t5-russian-spell\"\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(model_name_t5, cache_dir=\"./models\")\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_t5, cache_dir=\"./models\").to(device)\n",
    "t5_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пол Маккартни\n"
     ]
    }
   ],
   "source": [
    "# тестовый\n",
    "input_ids = t5_tokenizer(\"Полмакартни\", return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = t5_model.generate(input_ids)\n",
    "print(t5_tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_files(\n",
    "    model, tokenizer, input_files: list[Path], output_path: Path, input_prefix=None, suffix=\"_corrected\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для исправления текста в файлах с помощью модели\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для исправления текста\n",
    "    - tokenizer: токенизатор для модели\n",
    "    - input_files: список путей к txt файлам для исправления\n",
    "    - output_path: путь к папке для сохранения исправленных файлов\n",
    "    - suffix: суффикс для имен исправленных файлов (по умолчанию \"_corrected\")\n",
    "\n",
    "    Возвращает:\n",
    "    - список путей к созданным исправленным файлам\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = Path(output_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Найдено {len(input_files)} файлов для исправления\")\n",
    "\n",
    "    corrected_files = []\n",
    "\n",
    "    for txt_file in tqdm(input_files, total=len(input_files)):\n",
    "        try:\n",
    "            transcription = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "            if input_prefix:\n",
    "                transcription = input_prefix + transcription\n",
    "\n",
    "            # Токенизируем и генерируем исправленный текст\n",
    "            input_ids = tokenizer(transcription, return_tensors=\"pt\").input_ids.to(\n",
    "                model.device\n",
    "            )\n",
    "            outputs = model.generate(input_ids)\n",
    "            corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "            # Сохраняем исправленный текст в файл\n",
    "            new_filename = Path(txt_file).stem + suffix + \".txt\"\n",
    "            new_path = output_path / new_filename\n",
    "            new_path.write_text(corrected_text, encoding=\"utf-8\")\n",
    "\n",
    "            corrected_files.append(new_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при исправлении файла {txt_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Все файлы исправлены!\")\n",
    "    return corrected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 файлов для исправления\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5227534c5cb34a5d94c12af4e680155d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы исправлены!\n"
     ]
    }
   ],
   "source": [
    "# Используем функцию для исправления файлов\n",
    "corrected_files = correct_text_files(\n",
    "    model=t5_model,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    input_files=created_files,  # список путей к txt файлам для исправления\n",
    "    output_path=\"whisper/t5\",  # папка для сохранения исправленных файлов\n",
    "    suffix=\"\",  # суффикс для имен файлов\n",
    ")\n",
    "\n",
    "model_cleanup(t5_model, t5_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 случайных \"исправлений\" вида            [whisper | whisper+T5]\n",
      "================================================================================\n",
      "37e917e1-1fdf-4064-a74f-57a84bcb28b9.txt | Золотая лихорадка. | Золотая лихорадка\n",
      "d203c652-509b-4c41-bdaf-f374e1c3c87e.txt | Служебный реман | Служебный роман\n",
      "4c0f8f80-99f2-4dba-b54f-1860e07af180.txt | Гарри Поттер и дары смерти, части два. | Гарри Поттер и Дары Смерти (часть 2)\n",
      "6322d6cd-0928-4b4d-b96d-7cf78a86d7e6.txt | Фернандо Баторо | Фернандо Баторо\n",
      "236b63a8-8f37-444d-8340-25324620e985.txt | адвокат делала | Делала адвокат.\n",
      "0b495d2e-a15e-4ee6-8283-316fb821abf2.txt | Унесённый ветром. | Унесённый ветром.\n",
      "2e069c1d-11ba-4a51-84b1-f182b8a2999a.txt | Олеша Юрий Карлович | Олеша Юрий Карлович\n",
      "0a450eae-9d55-4bf0-aba8-a6f2e1162706.txt | Огни большого города | Огни большого города\n",
      "5baa289b-4373-47ff-8203-4462e052510f.txt | Джерард Батлер | Джерард Батлер\n",
      "6b061312-1923-4924-97de-21e31d6f5861.txt | Синявский Андрей Донатович | Синявский Андрей Донатович\n"
     ]
    }
   ],
   "source": [
    "sample_corrected_files = random.sample(corrected_files, k=min(10, len(corrected_files)))\n",
    "\n",
    "print('10 случайных \"исправлений\" вида            [whisper | whisper+T5]')\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for txt_file in sample_corrected_files:\n",
    "    transcription_corrected = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "    transcription = (\n",
    "        (txt_file.parent.parent / \"txt\" / txt_file.name)\n",
    "        .read_text(encoding=\"utf-8\")\n",
    "        .strip()\n",
    "    )\n",
    "    # .read_text(encoding='utf-8').strip()\n",
    "    print(f\"{txt_file.name} | {transcription} | {transcription_corrected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpXtmy6GiDk3"
   },
   "source": [
    "## Шаг 3 (2 балла)\n",
    "\n",
    "Соберите данные для дообучения модели выше. Для дообучения мы предлагаем вам использовать бесплатный api Groq: https://console.groq.com/docs/quickstart\n",
    "\n",
    "Разберитесь с тем как пользоваться api (мы немного поможем вам с этим кодом ниже) и с его помощью соберите датасет (можно в несколько запросов).\n",
    "\n",
    "- **0.5 балла** ставится за сбор датасета размером >1000 строк и сохранение в локальный файл/файлы\n",
    "\n",
    "- **еще 0.5 балла** ставится за [создание huggingface dataset](https://huggingface.co/docs/datasets/create_dataset) (через использование библиотек datasets и huggingface) и [сохранение собранного датасета напрямую в HuggingFace](https://huggingface.co/docs/datasets/upload_dataset)\n",
    "\n",
    "- **еще 1 балл** ставится за сбор датасета размером >1000 строк, на котором путем дообучения получится увеличить качество исправления опечаток в поставленной задаче (см. шаг 6) по сравнению с качеством прогноза той же, но предобученной модели\n",
    "\n",
    "P.S. Если у Вас нет VPN, то можете воспользоваться другой LLM на Ваш выбор (можно, например, этим https://ollama.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка подключения к OpenRouter\n",
    "\n",
    "Все использованные ниже модели бесплатные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет! 😊 Конечно, давай поработаем — с удовольствием помогу тебе сегодня! Расскажи, пожалуйста, что планируем?  \n",
      "\n",
      "Хочешь:  \n",
      "- Решить задачи/вопросы?  \n",
      "- Обсудить идеи/проект?  \n",
      "- Поработать с текстом (речь, статья, код)?  \n",
      "- Что-то другое?  \n",
      "\n",
      "Также могу слушать в формате \"рассказываю — уточняю — вместе анализируем\". Делись деталями, и я постараюсь сделать процесс полезным и веселым 🚀  \n",
      "\n",
      "(Если срочно — напиши \"Горит!\", и я включу турборежим 🔥)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# MODEL_NAME = \"deepseek/deepseek-chat-v3.1:free\"\n",
    "# MODEL_NAME = \"moonshotai/kimi-k2:free\"\n",
    "# MODEL_NAME = \"alibaba/tongyi-deepresearch-30b-a3b:free\"  # быстрый, но не точный\n",
    "# MODEL_NAME = \"qwen/qwen3-235b-a22b:free\"\n",
    "MODEL_NAME = \"meituan/longcat-flash-chat:free\"\n",
    "\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # extra_headers={\n",
    "    #   \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    #   \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "    # },\n",
    "    model=MODEL_NAME,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Привет! Поработаем сегодня?\"}],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "time.sleep(3)  # чтобы следующая ячейка не отвалилась по rate-limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Fyp_fo1dcEWm"
   },
   "outputs": [],
   "source": [
    "# Функйция генерации пар (ошибка -> исправление) для обучения модели\n",
    "def generate_spell_correction_pairs(num_pairs=50):\n",
    "    \"\"\"\n",
    "    Генерирует пары (ошибка -> исправление) для обучения модели spell correction\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "Ты эксперт по русскому языку. Создай {num_pairs} пар (ошибка -> исправление) для обучения модели spell correction.\n",
    "Верни результат в формате JSON с массивом пар.\n",
    "\n",
    "КРИТИЧЕСКИ ВАЖНО: \n",
    "- Отвечай ТОЛЬКО в формате JSON\n",
    "- НЕ добавляй никаких объяснений, рассуждений или комментариев\n",
    "- НЕ пиши \"Вот пары:\" или подобные фразы\n",
    "- Начинай ответ сразу с {{\n",
    "\n",
    "ПРАВИЛА:\n",
    "- Ошибка и исправление должны быть разными\n",
    "- Ошибки должны быть типичными для speech-to-text систем (фонетические ошибки, пропуски букв, замены)\n",
    "- Используй разнообразные типы ошибок: пропуски букв, замены, перестановки, лишние буквы\n",
    "- Включай имена собственные, географические названия, научные термины, короткие фразы, названия фильмов, книг, песен, игр, сериалов, мультфильмов, и т.д.\n",
    "- Длина текстов от 1 до 5 слов\n",
    "- Ошибки должны быть реалистичными для русской речи\n",
    "- Не используй кавычки, эмодзи, спецсимволы, HTML-теги, markdown, latex, математические формулы, химические формулы, биологические формулы, физические формулы, и т.д.\n",
    "\"\"\".format(num_pairs=num_pairs)\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=MODEL_NAME,\n",
    "            temperature=0.6,\n",
    "            max_tokens=10000,\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"spell_correction_pairs\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"pairs\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"error\": {\"type\": \"string\"},\n",
    "                                        \"correction\": {\"type\": \"string\"},\n",
    "                                    },\n",
    "                                    \"required\": [\"error\", \"correction\"],\n",
    "                                    \"additionalProperties\": False,\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"pairs\"],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при генерации: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_generated_pairs(text):\n",
    "    \"\"\"\n",
    "    Парсит сгенерированный текст и извлекает пары (ошибка, исправление)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    current_error = None\n",
    "    current_correction = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"ОШИБКА:\"):\n",
    "            current_error = line.replace(\"ОШИБКА:\", \"\").strip()\n",
    "        elif line.startswith(\"ИСПРАВЛЕНИЕ:\"):\n",
    "            current_correction = line.replace(\"ИСПРАВЛЕНИЕ:\", \"\").strip()\n",
    "            if (\n",
    "                current_error\n",
    "                and current_correction\n",
    "                and current_error != current_correction\n",
    "            ):\n",
    "                pairs.append((current_error, current_correction))\n",
    "                current_error = None\n",
    "                current_correction = None\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def parse_structured_pairs(json_text):\n",
    "    \"\"\"\n",
    "    Парсит JSON ответ и извлекает пары (ошибка, исправление)\n",
    "    \"\"\"\n",
    "\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_text)\n",
    "        pairs = []\n",
    "        for pair in data.get(\"pairs\", []):\n",
    "            if (\n",
    "                \"error\" in pair\n",
    "                and \"correction\" in pair\n",
    "                and pair[\"error\"].lower() != pair[\"correction\"].lower()\n",
    "            ):\n",
    "                pairs.append((pair[\"error\"], pair[\"correction\"]))\n",
    "        return pairs\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Ошибка парсинга JSON: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке данных: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовый запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получено 4 пар:\n",
      "жили были => жили-были\n",
      "супермана => Супермен\n",
      "звездные войны => Звёздные войны\n",
      "темная башня => Тёмная башня\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "json_response = generate_spell_correction_pairs(10)\n",
    "if json_response:\n",
    "    pairs = parse_structured_pairs(json_response)\n",
    "    print(f\"Получено {len(pairs)} пар:\")\n",
    "    for error, correction in pairs[:5]:\n",
    "        print(f\"{error} => {correction}\")\n",
    "\n",
    "time.sleep(5)  # чтобы следующая ячейка не отвалилась по rate-limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем пары"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту ячейку запускать не обязательно, т.к. датасет уже сформирован и загружен на Hugging Face  \n",
    "https://huggingface.co/datasets/psaw77/russian-spell-correction-dataset\n",
    "\n",
    "При желании можно запустить всё, тогда сформируется еще несколько пар и добавится к датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итого собрано 0 пар\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_NEW_GENERATION = False\n",
    "\n",
    "\n",
    "# Генерируем данные батчами, чтобы не превысить лимиты\n",
    "# промежуточные результаты сохраняются в файлы,\n",
    "# чтобы не терять данные от прошлых запусков\n",
    "all_pairs = []\n",
    "\n",
    "if RUN_NEW_GENERATION:\n",
    "    batch_size = 10\n",
    "    total_pairs_needed = 10  # было несколько запусков по 1500 пар\n",
    "    num_batches = (total_pairs_needed // batch_size) + 1\n",
    "\n",
    "    print(f\"Генерируем {total_pairs_needed} пар в {num_batches} батчах...\")\n",
    "\n",
    "    with tqdm(total=num_batches, desc=\"Генерация батчей\") as pbar:\n",
    "        for batch in range(num_batches):\n",
    "            generated_text = generate_spell_correction_pairs(batch_size)\n",
    "            if generated_text:\n",
    "                pairs = parse_structured_pairs(generated_text)\n",
    "                all_pairs.extend(\n",
    "                    pairs\n",
    "                )  # сохраняем текущее состояние в файл для защиты от сбоев\n",
    "                import json\n",
    "\n",
    "                with open(\"all_pairs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(all_pairs, f, ensure_ascii=False, indent=2)\n",
    "                pbar.set_postfix(\n",
    "                    {\"Получено в батче\": len(pairs), \"Всего пар\": len(all_pairs)}\n",
    "                )\n",
    "\n",
    "                # Небольшая пауза между запросами\n",
    "                time.sleep(random.randint(7, 12))\n",
    "            else:\n",
    "                st = random.randint(30, 40)\n",
    "                pbar.set_postfix({\"Статус\": f\"Ошибка в генераци... sleep {st} сек\"})\n",
    "                time.sleep(st)\n",
    "                pbar.set_postfix({\"Статус\": \"Ошибка в генераци... continue\"})\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Останавливаемся, если набрали достаточно пар\n",
    "            if len(all_pairs) >= total_pairs_needed:\n",
    "                break\n",
    "\n",
    "print(f\"Итого собрано {len(all_pairs)} пар\")\n",
    "\n",
    "# Пример того, что собрано в этом запуске\n",
    "random.sample(all_pairs, k=min(10, len(all_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если в этот раз получился бред, а такое бывает, то просто удалить файл `all_pairs.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Собираем сохраненные промежуточные файлы\n",
    "\n",
    "На моем сервере уже сохранены несколько файлов, содержащие 1500+ пар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из промежуточных файлов собрано 1516 пар\n",
      "Датасет сохранен в data_russian_speech/spell_correction_dataset_25.csv\n",
      "После удаления дубликатов: 1326 пар\n",
      "\n",
      "Примеры:\n",
      "                                input                             target\n",
      "0                  Василевский остров                Васильевский остров\n",
      "1                             Матрици                            Матрица\n",
      "2                              Превед                             Привет\n",
      "3                             Айнштан                           Эйнштейн\n",
      "4  Гарри Поттер и философсвкий камень  Гарри Поттер и философский камень\n",
      "5                               Метла                             Металл\n",
      "6                             здарова                       здравствуйте\n",
      "7                        запрограмист                        программист\n",
      "8                         алгебралайн                     алгебраический\n",
      "9                     нано технологии                     нанотехнологии\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_pairs = []\n",
    "\n",
    "# Считываем все промежуточные файлы\n",
    "for file in Path(\".\").glob(\"all_pairs*.json\"):\n",
    "    all_pairs.extend(json.loads(file.read_text(encoding=\"utf-8\")))\n",
    "\n",
    "print(f\"Из промежуточных файлов собрано {len(all_pairs)} пар\")\n",
    "\n",
    "# Делаем из списка пар датафрейм\n",
    "df = pd.DataFrame(all_pairs, columns=[\"input\", \"target\"])\n",
    "\n",
    "# Удаляем дубликаты\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Сохраняем в CSV с автоинкрементом номера файла\n",
    "base_filename = \"spell_correction_dataset\"\n",
    "counter = 1\n",
    "csv_path = DATA_ROOT / f\"{base_filename}_{counter}.csv\"\n",
    "\n",
    "while csv_path.exists():\n",
    "    counter += 1\n",
    "    csv_path = DATA_ROOT / f\"{base_filename}_{counter}.csv\"\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"Датасет сохранен в {csv_path}\")\n",
    "print(f\"После удаления дубликатов: {len(df)} пар\")\n",
    "print(\"\\nПримеры:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем/обновляем датасет на HuggingFace  \n",
    "На момент написания там уже 1600+ строк (пар)  \n",
    "https://huggingface.co/datasets/psaw77/russian-spell-correction-dataset\n",
    "\n",
    "**Порядок действий**:\n",
    "- скачать, если существует,\n",
    "- добавить новые пары,\n",
    "- загрузить обратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login(token=HF_TOKEN) # не нужно, если токен уже в переменных окружения, а он там"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> По непонятной причине обращение к HuggingFace иногда подвисает.  \n",
    "> Обычно выполняется почти моментально.  \n",
    "> Если дольше 5 секунд - вручную остановить и заново запустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Попытка загрузки существующего датасета...\n",
      "Найден существующий датасет с 1637 записями\n",
      "До удаления дубликатов: 2963 записей\n",
      "После удаления дубликатов: 1637 записей\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5e7ffeb937470cb62e743fc1a2aba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace dataset сохранен локально\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a29a1ee2d104109826e3ce1c79cb177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f058ce714584d6aac0a75ba1c25c1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d886b869593478984a66546d6db6960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aba4b8a1fc343b9bbfc9942fb772ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa09350783ad4cc38b969232c239be0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########| 57.9kB / 57.9kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет загружен в HuggingFace Hub!\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"Попытка загрузки существующего датасета...\")\n",
    "\n",
    "    # если датасета нет, то это вызовет исключение\n",
    "    existing_dataset = load_dataset(\"psaw77/russian-spell-correction-dataset\", )\n",
    "    print(f\"Найден существующий датасет с {len(existing_dataset['train'])} записями\")\n",
    "\n",
    "    existing_df = existing_dataset[\"train\"].to_pandas()\n",
    "    new_df = df.copy()  # датафрейм из локальных файлов\n",
    "\n",
    "    # Индексы не нужны. HF их пересоздаст\n",
    "    if \"__index_level_0__\" in existing_df.columns:\n",
    "        existing_df = existing_df.drop(columns=[\"__index_level_0__\"])\n",
    "    if \"__index_level_0__\" in new_df.columns:\n",
    "        new_df = new_df.drop(columns=[\"__index_level_0__\"])\n",
    "\n",
    "    # Объединяем датасеты\n",
    "    combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "    # Удаляем дубликаты\n",
    "    print(f\"До удаления дубликатов: {len(combined_df)} записей\")\n",
    "    combined_df = combined_df.drop_duplicates(subset=[\"input\", \"target\"])\n",
    "    print(f\"После удаления дубликатов: {len(combined_df)} записей\")\n",
    "\n",
    "    dataset = Dataset.from_pandas(combined_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при загрузке существующего датасета: {e}\")\n",
    "    print(\"Создаем новый датасет...\")\n",
    "\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Сохраняем локально - может пригодиться\n",
    "dataset.save_to_disk(\"russian_spell_correction_dataset\")\n",
    "print(\"HuggingFace dataset сохранен локально\")\n",
    "\n",
    "# Отправляем в HuggingFace Hub\n",
    "dataset.push_to_hub(\"psaw77/russian-spell-correction-dataset\")\n",
    "print(\"Датасет загружен в HuggingFace Hub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg9OoCu1iPkG"
   },
   "source": [
    "## Шаг 4 (2 балла)\n",
    "\n",
    "Дообучите модель выше или любую другую модель, которая вам нравится, на собранных данных и протестируйте ее на нескольких ошибочно распознанных whisper-small моделью аудио. Дообучение мы разбирали на семинаре - можете посмотреть, как мы это делали там.\n",
    "\n",
    "Для оценки качества результата выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели.\n",
    "\n",
    "- Вы можете воспользовать структурой, предложенной в ячейке ниже, а можете написать код по-своему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NrE_Ono2OK_J"
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade transformers datasets  # Уже установлено в первой ячейке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель для дообучения - та же, что и в шаге 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "# Модель\n",
    "model_name_4 = \"UrukHan/t5-russian-spell\"\n",
    "t5_ft_tokenizer = AutoTokenizer.from_pretrained(model_name_4, cache_dir=\"./models\")\n",
    "t5_ft_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_4, cache_dir=\"./models\").to(device)\n",
    "t5_ft_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'target', '__index_level_0__'],\n",
       "        num_rows: 1473\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'target', '__index_level_0__'],\n",
       "        num_rows: 164\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# если работает дольше 5 секунд - прервать и повторить\n",
    "# login(token=HF_TOKEN)\n",
    "full_dataset_2 = load_dataset(\"psaw77/russian-spell-correction-dataset\")\n",
    "dataset_2 = full_dataset_2[\"train\"].train_test_split(test_size=0.1)\n",
    "dataset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор `max_length` для токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcJVJREFUeJzt3Xt8z/X///H7e5sd7GjYKXOKYqMU0iiKZYkiPqSUDfH5aZLDR1LOKR8kkkMp0cknoST5yCyHchxaKdJoWLHNaZtDs9levz989v5624HNvN7b3K6Xy/ty6f16Pd+v1+P12ub96P5+vl8vi2EYhgAAAAAAAAATOdi7AAAAAAAAANx8CKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAKACurcuXNKSkrS6dOn7V0KAACogC5evKjU1FQdOXLE3qUAKKcIpQCgBM6ePauZM2dan6elpWnOnDn2K+h/li5dqnbt2snT01MeHh6qWbOmpk6dau+yAABACXzyySc6dOiQ9fmiRYv0119/2a8gSQkJCerfv78CAwPl7Owsf39/hYWFyTAMu9YFoHyyGPzrARSbxWK5pnHr16/XAw88cGOLgV3k5OTI29tb7777rlq3bq3p06frt99+05o1a+xW00svvaQpU6aoc+fO6tmzp6pVqyaLxaLbbrtNwcHBdqsLAIDL0Uddu3/+8586ffq0pk6dqv3796tr1646cOCAAgMD7VLPtm3b1KFDB/n6+mrw4MEKCQmRxWKRt7e3mjdvbpeaAJRvTvYuACiPPv74Y5vnH330kWJiYvItb9iwoZllwUSOjo6aMGGCevfurdzcXHl5eembb76xWz0bN27UlClTNHnyZL300kt2qwMAgKuhj7p2Q4cO1QMPPKA6depIkoYNG2a3QCorK0t9+vTRbbfdprVr18rb29sudQCoWJgpBZSCQYMGac6cOUxbvgn9+eefSkpKUsOGDeXj42O3Oh599FGdOnVKmzdvtlsNAACUBH1U0c6dO6dffvlF1apV06233mq3OpYvX67u3bvrt99+02233Wa3OgBULFxTCrjBNmzYIIvFoiVLlujll19WQECA3N3d9dhjjykpKSnf+O3bt+vhhx+Wt7e3KleurDZt2uQLGsaPHy+LxaITJ07YLN+5c6csFosWLVpkXRYVFaXatWvbjEtKSpKbm5ssFovNdQpq166tTp06ae3atWrSpIlcXV0VEhKiL774Il+df/zxh7p37y5fX19VrlxZ9957b76ZQnnHnvdwcXHRbbfdpsmTJ+drPH/88Ud16NBBXl5e8vDwULt27bRt2zabMQUdi3TpawDjx48v8fnx8PDIt81r2b4k1ahRQ2FhYXJyclJAQIAsFos2bNhQ5PaKU9/PP/+sqKgo1a1bV66urgoICFDfvn118uRJm9du27ZNjRo1Us+ePeXr6ys3Nzc1b95cK1asyLf/1NRU9evXT/7+/nJ1ddWdd96pDz/80GbMoUOHZLFY9MYbb2jGjBmqVauW3Nzc1KZNG/3yyy9FHt/loqKibH4H8h5RUVE247766it17NhRQUFBcnFx0a233qpXX31VOTk5NuMeeOABNWrUKN9+3njjjUJ/n680aNCgfF8dsVgsGjRoUKHHsWjRIpvtf/fdd3JwcNDYsWNtxi1evFgWi0Xz5s0rdFsAgOK5cOGCxo0bp3r16snFxUXBwcF68cUXdeHChXxjP/nkE91zzz2qXLmyqlSpotatW2vt2rWSLr0vFPSelPe4vMc4d+6chg8fruDgYLm4uOj222/XG2+8ka9/ufz1jo6OuuWWWzRgwAClpaVZx+T1Q8uWLSv0GK/scfLehxctWiR3d3e1aNFCt956q6Kjowt8H73S5e/jV2rUqJHN1yKzsrI0duxYNW3aVN7e3nJ3d9f999+v9evX27xu27ZtqlOnjpYvX65bb71Vzs7Oqlmzpl588UX9/fff+fYzd+5chYaGysXFRUFBQYqOjrY5L9L/va/v2rVLLVu2lJubm+rUqaN33nmnyOO73JX95uWPyx0+fFjPPfecbr/9drm5ualq1arq3r27Te8g/d97/s6dO22WnzhxwtSe8++//1aDBg3UoEEDm/N76tQpBQYGqmXLlvn6JKA84ut7gElee+01WSwWjRw5UqmpqZo5c6bCw8MVHx8vNzc3SZf+R7dDhw5q2rSpxo0bJwcHBy1cuFBt27bV999/r3vuuadUahk7dqwyMzMLXJeQkKAnnnhC/+///T9FRkZq4cKF6t69u9asWaOHHnpIkpSSkqKWLVvq/PnzGjx4sKpWraoPP/xQjz32mJYtW6bHH3/cZpsvv/yyGjZsqL///tsazvn5+alfv36SpF9//VX333+/vLy89OKLL6pSpUp699139cADD2jjxo1q0aJFqRz3jTR9+nSlpKSU+nZjYmL0xx9/qE+fPgoICNCvv/6q+fPn69dff9W2bdusDdfJkyc1f/58eXh4aPDgwapevbo++eQTde3aVZ9++qmefPJJSZcanAceeEAHDhzQoEGDVKdOHS1dulRRUVFKS0vTCy+8YLP/jz76SGfOnFF0dLQyMzP11ltvqW3bttqzZ4/8/f2v6RhcXFz0/vvvW58/++yz+cYsWrRIHh4eGjZsmDw8PPTdd99p7NixysjI0LRp00p6+m6Ytm3b6rnnntPkyZPVpUsX3X333Tp27Jief/55hYeH6//9v/9n7xIBoELIzc3VY489ph9++EEDBgxQw4YNtWfPHs2YMUO///67zYcvEyZM0Pjx49WyZUtNnDhRzs7O2r59u7777ju1b99eM2fO1NmzZyVJ+/bt0+uvv27tUSRZAwPDMPTYY49p/fr16tevn5o0aaJvv/1WI0aM0F9//aUZM2bY1Pj444+ra9euunjxorZu3ar58+fr77//zvd1xOt14MABvffee6W6TUnKyMjQ+++/ryeffFL9+/fXmTNntGDBAkVERGjHjh1q0qSJpEu9xh9//KGXX35ZXbt21fDhw7Vz505NmzZNv/zyi7755htrXzJ+/HhNmDBB4eHhGjhwoPbv36958+YpLi5OmzdvVqVKlaz7P336tB555BH16NFDTz75pD7//HMNHDhQzs7O6tu37zUfx+DBg63Xtcr7Sujl4uLitGXLFvXs2VM1atTQoUOHNG/ePD3wwAPau3evKleufJ1nsnS5ubnpww8/VKtWrfTKK6/ozTfflCRFR0crPT1dixYtkqOjo52rBEqBAeC6RUdHG4X9Oa1fv96QZNxyyy1GRkaGdfnnn39uSDLeeustwzAMIzc316hfv74RERFh5ObmWsedP3/eqFOnjvHQQw9Zl40bN86QZBw/ftxmX3FxcYYkY+HChdZlkZGRRq1atazPf/nlF8PBwcHo0KGDIclITEy0rqtVq5YhyVi+fLl1WXp6uhEYGGjcdddd1mVDhgwxJBnff/+9ddmZM2eMOnXqGLVr1zZycnJsjn39+vXWcZmZmYaDg4Px3HPPWZd16dLFcHZ2Ng4ePGhddvToUcPT09No3bq1dVmfPn2MmjVr5jvHkoxx48aV+Py4u7vn2+a1bD9Pamqq4enpaT2nlx9vQYpT3/nz5/O9/j//+Y8hydi0aZNNjZKMDRs22Ly2YcOGRkBAgJGVlWUYhmHMnDnTkGR88skn1nFZWVlGWFiY4eHhYf0dTUxMNCQZbm5uxp9//mkdu337dkOSMXTo0CKPMc9TTz1leHh42Cxzd3c3IiMjbZYVdJz//Oc/jcqVKxuZmZnWZW3atDFCQ0PzjZ02bVqBv88dO3bMN7agv1dJRnR0dKHHsXDhwnzbP3funFGvXj0jNDTUyMzMNDp27Gh4eXkZhw8fLnQ7AID8iuqjPv74Y8PBwcGm5zAMw3jnnXcMScbmzZsNwzCMhIQEw8HBwXj88cetfUiey/uqPAX1KHlWrFhhSDImTZpks/wf//iHYbFYjAMHDliXXdkjGIZhtGzZ0ggJCcm3r6VLlxZ4jIaRv1/Lex++vCfo0aOH0ahRIyM4ODjf++iV8l4/bdq0fOtCQ0ONNm3aWJ9fvHjRuHDhgs2Y06dPG/7+/kbfvn1tapRkREVF2YzN62u+/vprwzAu9UXOzs5G+/btbX4Ws2fPNiQZH3zwgXVZmzZtDEnG9OnTrcsuXLhgNGnSxPDz87P2L0VZu3atIclYtmyZdVlBv1MF9Rpbt241JBkfffSRdVnee35cXJzN2OPHj5vecxqGYYwaNcpwcHAwNm3aZCxdutSQZMycObPI7QDlCV/fA0zSu3dveXp6Wp//4x//UGBgoFavXi1Jio+PV0JCgp566imdPHlSJ06c0IkTJ3Tu3Dm1a9dOmzZtUm5urs02T506ZR134sQJpaenX7WOUaNG6e6771b37t0LXB8UFGQz08nLy0u9e/fWjz/+qOTkZEnS6tWrdc899+i+++6zjvPw8NCAAQN06NAh7d2712ab6enpOnHihI4cOaKpU6cqNzdXbdu2lXTpLnZr165Vly5dVLduXetrAgMD9dRTT+mHH35QRkaGJMnPz0+pqanKysq66nEW9/zkjSlsBllRXn31VXl7e2vw4MHFet211Jc3i06SMjMzdeLECd17772SpN27d9uMbd68udq0aWPz2ueee07JycnWsatXr1ZAQIB15pQkVapUSYMHD9bZs2e1ceNGm2126dJFt9xyi/X5PffcoxYtWlh/b68mMzNTrq6uVx13+XGeOXNGJ06c0P3336/z58/rt99+sxmbk5Njc95OnDih8+fPF7jd7OzsfGML+xnnnd+TJ0/m+1srSOXKlbVo0SLt27dPrVu31jfffKMZM2aoZs2aV30tAODaLF26VA0bNlSDBg1s/i3P6yPyvmK2YsUK5ebmauzYsXJwsP1fnGu921+e1atXy9HRMd/7+vDhw2UYhv773//aLD9//rxOnDih5ORkLV++XD/99JPatWuXb7t5729XfoXtWuzatUtLly7V5MmT8x1fUfJqu/xx5Ve+HB0d5ezsLOnSzLRTp07p4sWLatasWb5eQ5JGjBhh83zo0KFydHS0XsZh3bp1ysrK0pAhQ2xq7d+/f4E3hnFyctI///lP63NnZ2f985//VGpqqnbt2nXVY8x7X79av3F5r5Gdna2TJ0+qXr168vHxKfA48/rXvMepU6cK3faN7DnHjx+v0NBQRUZG6rnnnlObNm2K3XMCZRlf3wNMUr9+fZvnFotF9erVs36PPSEhQZIUGRlZ6DbS09NVpUoV6/Pbb7+9WDX88MMP+vrrrxUbG6sjR44UOKZevXr5mre8i1keOnRIAQEBOnz4cIFfqcub/n748GGb6/506dLF+t8ODg4aPXq0unXrJkk6fvy4zp8/X+CxNGzYULm5uUpKSlJoaKhatmypKVOmaPTo0Ro8ePBVm49rPT/nzp1T9erVrc+Dg4M1fPjwfF9lK0hiYqLeffddzZs375rCl+LWd+rUKU2YMEGfffaZUlNTbdZd2fA0aNAg3+vzfiaHDh1SixYtdPjwYdWvXz9fQ3v5z+5yV/7eSpd+Hz7//POr1i5daryu5e48v/76q0aPHq3vvvvOGkLmufI4f/vtN5ufV1HWrl17zWMXLFigBQsWSLrUELdo0UJvvvmmmjVrVuhrWrVqpYEDB2rOnDmKiIgo1tcMAABXl5CQoH379hX6b3nee+PBgwfl4OCgkJCQ697n4cOHFRQUZPNholT4e+W0adNsvmr+8MMPa8qUKfm2e/l7hIeHhx599FHNmDHjmr4O/9JLL+n+++9Xp06dirwG4pXGjRuncePG5Vt+5T4//PBDTZ8+Xb/99puys7Oty/Pu+idd6l0dHBzy9Qbe3t4KDAy09rR55+fKPsfZ2Vl169bNd/6CgoLk7u5us+zy3jPvw7jC5F3P6Wr9xt9//63Jkydr4cKF+uuvv2yuD1ZQiBQeHl7k9i53I3tOZ2dnffDBB2revLlcXV21cOHCYgetQFlGKAWUEXkzM6ZNm2b97v6Vrrw44vLly+Xl5WV9/vvvvys6OrrQfYwcOVIRERFq27atzYUXb7Q33nhDd955p7KzsxUXF6dJkybJycmpwCapKI899pj69u2br/krzLWeH1dXV3399deSLn2K+cEHH2jIkCEKDAxUjx49itzHK6+8ovr16ysyMlLff/99sY7nWurr0aOHtmzZohEjRqhJkyby8PBQbm6uHn74YZvZPJd/+leWHDp0qMBg63JpaWlq06aNvLy8NHHiRN16661ydXXV7t27NXLkyHyzlmrXrp3vmhpLly7V/Pnz8227RYsWmjRpks2y2bNn66uvvso3tnPnzho0aJAMw1BiYqImTpyoTp06WQPjgly4cMF6YfuDBw/q/PnzZe6aFABQnuXm5qpx48bW6+lcKTg42OSK8nvmmWfUu3dv5ebm6o8//tCrr76qTp06ad26dTbhwdixY3X//fcrOztbu3bt0sSJE5WWlnbV2cdr167VunXrtHXr1mLXNmDAgHyz4/v372/z/JNPPlFUVJS6dOmiESNGyM/PT46Ojpo8ebIOHjxoHZfXa5S1QCQvDCvoZjiXe/7557Vw4UINGTJEYWFh8vb2lsViUc+ePQucIT1nzhybuwxmZGRYP1S90o3uOb/99ltJl2aFJSQk2ISFQHlHKAWY5Mr/sTUMQwcOHNAdd9whSdZb/Hp5eV3zJzOtW7dWtWrVrM99fHwKHbtixQpt3bq1wOnJlztw4IAMw7BpOH7//XdJ//dmX6tWLe3fvz/fa/O+ZlWrVi2b5U2bNrXe5aVDhw7666+/NGXKFI0ZM0bVq1dX5cqVC92eg4ODTcO5YMECjR07VgcPHrQ2EHkXYL/StZ4fR0dHm3PesWNH+fr6as2aNUU2CD/++KM+++wzrVixokQXmrxafadPn1ZsbKwmTJhgc5e3gkKSOnXqFPkzufxn9/PPPys3N9dmtlRhP7uC9vX7779ftfGTLs2CO3LkiM1XBQuyYcMGnTx5Ul988YVat25tXZ6YmFjgeHd393x/I/Hx8QWOrVatWr6xBd2RULp0J8XLx3p4eKhXr1768ccfC6193Lhx2rdvn9544w2NHDlSL730kmbNmlXoeABA8dx6663Wr8MVFYbceuutys3N1d69ewv9cO9a1apVS+vWrdOZM2dsZksV9l5Zt25dm/cPb29vPfXUU9q2bZvCwsKsyxs3bmwd16FDBx05ckQffvihLl68WGgthmHopZde0uOPP37VGUMFqV+/fr73wStnJS1btkx169bVF198YXOOr/zwsE6dOsrNzVVCQoJ11ph0Kaw5duyY9Y63eedn//79NpdmyMrKUmJiYr56jh49qnPnztnUdWXvWZSdO3cqICBANWrUKHLcsmXLFBkZqenTp1uXZWZmFvp1ynvuucdmtvSVd9i73I3sOX/++WdNnDhRffr0UXx8vJ599lnt2bPnmmaiA+UB15QCTJJ3F7M8y5Yt07Fjx9ShQwdJl4KbW2+9VW+88Yb1zjCXO378eIn3nZOTo5dffllPPfXUVRu1o0eP6ssvv7Q+z8jI0EcffaQmTZooICBAkvTII49ox44dNp/YnTt3TvPnz1ft2rWvOnX+77//1sWLF3Xx4kU5Ojqqffv2+uqrr2xuyZuSkqLFixfrvvvus/nkSbrU7LRt21bh4eHFmlp9rfKmc18taHrppZfUqlUrPfbYY6Vew+X7v3x6uSTNnDkz39i8n8mWLVusyzIzMzVv3jwFBASoadOm1nHJyclasmSJddzFixf19ttvy8PDw+aaVNKlAOevv/6yPt+xY4e2b99u/b0tytKlSyVdmoFU3OPMysrS3Llzr7qPGykv9Czs92D79u164403NGTIEA0fPlwjRozQ7Nmz812XCwBQcj169NBff/1V4F3n/v77b507d07SpUsFODg4aOLEiflmvVz5Pno1jzzyiHJycjR79myb5TNmzJDFYrnqe+Dff/8t6dJs2qLkfUBUVNj22Wef6eeff9bkyZOvsfriK+h9ePv27flmZj3yyCOS8vchb731lnJycqyhVHh4uJydnTVr1iybbS5YsEDp6enq2LGjzesvXryod9991/o8KytL7777rqpXr27tXwpz8uRJrV+//pp6MUdHx3y/C2+//Xa+a2yZ6Wo9Z3Z2tqKiohQUFKS33npLixYtUkpKioYOHWpmmcANxUwpwCS+vr6677771KdPH6WkpGjmzJmqV6+edQq1g4OD3n//fXXo0EGhoaHq06ePbrnlFv31119av369vLy8rNN9i+vPP/+Us7PzNV2c+rbbblO/fv0UFxcnf39/ffDBB0pJSdHChQutY1566SX95z//UYcOHTR48GD5+vrqww8/VGJiopYvX57vekUxMTH6888/rV/f+/TTT/XYY49ZL6o5adIkxcTE6L777tNzzz0nJycnvfvuu7pw4YKmTp1aomMujpycHK1Zs0bSpanUCxcu1Llz52yuhVWQtWvXavPmzTesLi8vL7Vu3VpTp05Vdna2brnlFq1du7bAGUQvvviiPv30U+vPpFq1avrkk0+0d+9effrpp3JyuvTP/YABA/Tuu+8qKipKu3btUu3atbVs2TJt3rxZM2fOzHf9jHr16um+++7TwIEDdeHCBc2cOVNVq1bViy++WGTtc+bM0ejRo1W9enUdPHjQZvr/xYsX9ccffygmJkYPPfSQWrZsqSpVqigyMlKDBw+WxWLRxx9/XOz/ibheR44c0Zo1a6xf33vttddUq1Yt3XXXXflmjGVmZioyMlL169fXa6+9JunSrci//vpr9enTR3v27Mn3STQAoPieeeYZff755/p//+//af369WrVqpVycnL022+/6fPPP9e3336rZs2aqV69enrllVf06quv6v7771fXrl3l4uKiuLg4BQUFFSvUefTRR/Xggw/qlVde0aFDh3TnnXdq7dq1+uqrrzRkyBDr7PY8P//8sz755BMZhqGDBw9q1qxZqlGjRr5rEsbHx8vDw0MXL17Url279NFHH6lz585Ffgi2du1a9e/fv9jXES2OTp066YsvvtDjjz+ujh07KjExUe+8845CQkJsPigNDQ1Vv379NH/+fJ0+fVoPPPCAdu/erQ8++EAdOnSwhlbVq1fXqFGjNGHCBD388MN67LHHtH//fs2dO1fNmzfX008/bbP/oKAgTZkyRYcOHdJtt92mJUuWKD4+XvPnz1elSpUKrXvr1q166aWX9Pfff6t69er65JNPrOvyZlp98sknevzxx+Xu7q5OnTrp448/lre3t0JCQrR161atW7dOVatWLc3TWaTi9pyTJk1SfHy8YmNj5enpqTvuuENjx47V6NGj9Y9//MN6zoFyzfT7/QEVUFG3Ms67DfB//vMfY9SoUYafn5/h5uZmdOzYscBbx//4449G165djapVqxouLi5GrVq1jB49ehixsbHWMcW9/awk44UXXrAZW9At7mvVqmV07NjR+Pbbb4077rjDcHFxMRo0aFDgLYwPHjxo/OMf/zB8fHwMV1dX45577jFWrVpV4LHnPZycnIxatWoZgwcPNk6fPm0zdvfu3UZERITh4eFhVK5c2XjwwQeNLVu2FHhOr6TrvD3v5TV6eHgYd999t/Hxxx9fdfudO3cu8HgLur305YpT359//mk8/vjjho+Pj+Ht7W10797dOHr0aIG3DM77mXh7exuurq5G8+bNjRUrVuTbf0pKitGnTx+jWrVqhrOzs9G4cWObfRqG7a2kp0+fbgQHBxsuLi7G/fffb/z0009FHp9hGDbntLDH5bej3rx5s3Hvvfcabm5uRlBQkPHiiy8a3377bb7z2aZNGyM0NDTf/qZNm1bo7/OVCvp7vbwui8ViBAQEGF27djX27dtnGEb+v5ehQ4cajo6Oxvbt2222s3PnTsPJyckYOHDgVc8RAOCSovoowzCMrKwsY8qUKUZoaKjh4uJiVKlSxWjatKkxYcIEIz093WbsBx98YNx1113WcW3atDFiYmLybfNq79lnzpwxhg4dagQFBRmVKlUy6tevb0ybNs3Izc21GXe194/L91VUPxQZGWnUqlXL+pq892E3Nzfjr7/+stlnrVq1jMjIyELP1+WvnzZtWr51oaGhNu/Bubm5xuuvv27UqlXLcHFxMe666y5j1apV+WoyDMPIzs42Jk6caNSpU8eoVKmSERwcbLz44ovG+fPn8+1n9uzZRoMGDYxKlSoZ/v7+xsCBA/P1f3nv6zt37jTCwsIMV1dXo1atWsbs2bOLPD7DyN/DFfbIe+8+ffq0tf/x8PAwIiIijN9++y3f+cx7z4+Li7PZ3/Hjx03tOXft2mU4OTkZzz//vM22L168aDRv3twICgrKdz6B8shiGCZ/FA3cZDZs2KAHH3xQS5cu1T/+8Q97l1Ok2rVrq1GjRlq1apW9S4GdHTp0SHXq1NG0adP0r3/9q9ivt1gsWr9+vfVaYldatGiRFi1aZL1IOAAAuPk88MADOnHihH755ZdivzYqKkqSirx5j8ViUWJi4jVdmwqAfXBNKQAAAAAAAJiOa0oBAEpdr1695O/vX+j6W2+9tdC7JgIAAFxNy5YtrzqmV69e8vDwMKEaACVFKAUAKHWXX2y0IPfff7/uv/9+k6oBAAAVzYABA6465mr9CAD745pSAAAAAAAAMB3XlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI4LnUvKzc3V0aNH5enpKYvFYu9yAADATcYwDJ05c0ZBQUFycLj+zwzpbQAAgD1da29DKCXp6NGjCg4OtncZAADgJpeUlKQaNWpc93bobQAAQFlwtd6GUEqSp6enpEsny8vLy87VAACAm01GRoaCg4OtPcn1orcBAAD2dK29DaGUZJ3W7uXlReMGAADsprS+akdvAwAAyoKr9TZc6BwAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDquKQUAuCEMw9DFixeVk5Nj71IAu3N0dJSTk1OpXTMKAGA+ehvg/5RWb0MoBQAodVlZWTp27JjOnz9v71KAMqNy5coKDAyUs7OzvUsBABQTvQ2QX2n0NoRSAIBSlZubq8TERDk6OiooKEjOzs7MDsFNzTAMZWVl6fjx40pMTFT9+vXl4MAVFACgvKC3AWyVZm9DKAUAKFVZWVnKzc1VcHCwKleubO9ygDLBzc1NlSpV0uHDh5WVlSVXV1d7lwQAuEb0NkB+pdXb8DEdAOCGYCYIYIu/CQAo3/h3HLBVGn8T/FUBAAAAAADAdIRSAAAAAAAAMB3XlAIAmKbfojjT9rUgqnmxxkdFRSktLU0rVqywLjt+/LgefPBBubu7a+3atfL29i7lKgEAQHlWlnsbif4GZR8zpQAAKMDx48fVtm1bubm50bABAIAKgf4GZQ2hFAAAVzhx4oTatWsnFxcXxcTE2DRsR44cUefOneXh4SEvLy/16NFDKSkpNq8/dOiQLBZLvkdaWpokafz48WrSpIl1fFZWlurVq2czJioqSl26dLHZrsVisfmkMykpST169JCPj498fX3VuXNnHTp0yOY1H3zwgUJDQ+Xi4qLAwEANGjRIklS7du0Ca7RYLFq0aJF1f3kPLy8vPfTQQzp48KB126dPn1bv3r1VpUoVVa5cWR06dFBCQkKR5zYtLU3//Oc/5e/vL1dXVzVq1EirVq3Kd5xXPuLj463rly9fbj2m2rVra/r06Tavv/zY3N3d1bJlS+3cubPIugAAqOjobxZZ90d/U3YQSgEAcJmTJ08qPDxcTk5OiomJkY+Pj3Vdbm6uOnfurFOnTmnjxo2KiYnRH3/8oSeeeMJmG4ZhSJLWrVunY8eOafny5UXuc/bs2fkav6vJzs5WRESEPD099f3332vz5s3y8PDQww8/rKysLEnSvHnzFB0drQEDBmjPnj1auXKl6tWrJ0mKi4vTsWPHdOzYMdWoUUMzZ860Pr/8eBYuXKhjx45p06ZNSk1N1csvv2xdFxUVpZ07d2rlypXaunWrDMPQI488ouzs7AJrzs3NVYcOHbR582Z98skn2rt3r/7973/L0dEx37nL2++OHTtstrFr1y716NFDPXv21J49ezR+/HiNGTPG2mjmmThxoo4dO6adO3fK3d1d0dHRxTq/AABUJPQ39DdlFdeUAgDgf06fPq3w8HDt3btXTZs2lZeXl8362NhY7dmzR4mJiQoODpYkffTRRwoNDVVcXJyaN790rYe8piUgIEABAQHy9fUtdJ+nTp3SpEmTNHLkSI0ZM8a63M3NTceOHSv0dUuWLFFubq7ef/99WSwWSZcaHR8fH23YsEHt27fXpEmTNHz4cL3wwgvW1+XVWL16desyR0dHeXt7KyAgIN9+fHx8FBAQIDc3N3l6elo/VU1ISNDKlSu1efNmtWzZUpL06aefKjg4WCtWrFD37t3zbWvdunXasWOH9u3bp9tuu02SVLduXZsxeeeuevXqCggIUGZmps36N998U+3atbOeq9tuu0179+7VtGnTFBUVZR3n6empgIAA+fj4qEqVKtZzBADAzYb+hv6mLGOmFAAA/7Np0ybl5uYqPj5eBw4c0NSpU23W79u3T8HBwdaGTZJCQkLk4+Ojffv2WZdlZGRIktzd3a+6z4kTJ+rBBx/UfffdZ7O8UaNG2rZtmxITEwt83U8//aQDBw7I09NTHh4e8vDwkK+vrzIzM3Xw4EGlpqbq6NGjateu3TUff0GefPJJeXh4qEqVKjpz5owmT54s6dK5cHJyUosWLaxjq1atqttvv93mXFwuPj5eNWrUsDZsBbnaudu3b59atWpls6xVq1ZKSEhQTk6OddnIkSPl4eEhd3d37dixQ3PmzLm2AwYAoIKhv8mP/qbsIJQCAOB/6tatq9jYWIWEhGju3LkaP368fv7552Jv5+jRo3JwcCjwk7nLJSQk6P3339eUKVPyrevbt6+aN2+uunXrWpuyy509e1ZNmzZVfHy8zeP333/XU089JTc3t2LXXZAZM2YoPj5eO3bsUEBAgM2ndcV1LTUdPXpUkhQUFFTi/UjSiBEjFB8fr927d+v+++9Xjx49bJo6AABuFvQ3+dHflB2EUgAA/E/jxo1VrVo1SVL37t3VtWtX9e7d23oNg4YNGyopKUlJSUnW1+zdu1dpaWkKCQmxLouLi1ODBg3k6upa5P5GjhypZ5991nodhMu5ublp3bp1Sk5OtjZkl7v77ruVkJAgPz8/1atXz+bh7e0tT09P1a5dW7GxsSU9HZIuTdGvV6+emjVrpueff17ffPONsrOz1bBhQ128eFHbt2+3jj158qT2799vcy4ud8cdd+jPP//U77//Xuj+4uLi5OnpqVtvvbXA9Q0bNtTmzZttlm3evFm33XabzbUbqlWrpnr16unOO+/UyJEjFR8fX+insgAAVGT0N/nR35QdhFIAABRizpw5Sk1N1YQJEyRJ4eHhaty4sXr16qXdu3drx44d6t27t9q0aaNmzZopKytLH3/8sd5880316dOnyG0fOHBAGzZs0NixY4sc5+/vb23GLterVy9Vq1ZNnTt31vfff6/ExERt2LBBgwcP1p9//inp0l1wpk+frlmzZikhIUG7d+/W22+/XaxzkJaWpuTkZO3fv18LFixQ3bp1ValSJdWvX1+dO3dW//799cMPP+inn37S008/rVtuuUWdO3cucFtt2rRR69at1a1bN8XExCgxMVH//e9/tWbNGuXm5mrlypV6+eWX1bt3b5sG7HLDhw9XbGysXn31Vf3+++/68MMPNXv2bP3rX/+yGXfmzBklJyfrjz/+0OzZs+Xp6albbrmlWMcOAEBFRH9Df1OWEEoBAFAIX19fvffee5oyZYq2b98ui8Wir776SlWqVFHr1q0VHh6uunXrasmSJZJkc7eUYcOGFbntc+fO6ZVXXinyIqFFqVy5sjZt2qSaNWuqa9euatiwofr166fMzEzrBUwjIyM1c+ZMzZ07V6GhoerUqdNVb2l8pT59+igwMFDNmzfX6dOntWzZMuu6hQsXqmnTpurUqZPCwsJkGIZWr16tSpUqFbq95cuXq3nz5nryyScVEhKiF198UTk5OTp9+rSee+45RUZG5rsF8uXuvvtuff755/rss8/UqFEjjR07VhMnTsw37X7s2LEKDAxUo0aNtHv3bq1YsaLUpvwDAFCe0d/Q35QlFiPv3oQ3sYyMDHl7eys9PT3fnQgAAMWTmZmpxMRE1alT56rTu4GbSVF/G6Xdi9DbAEDpobcBClYavY3TjS4S/6fforhC1y2Iam5iJQAAAAAAAPbF1/cAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOid7FwAAuIksfsK8fT21pFjDo6KilJaWphUrVliXHT9+XA8++KDc3d21du1aeXt7l3KRAACgXCvDvY1Ef4Oyj5lSAAAU4Pjx42rbtq3c3Nxo2AAAQIVAf4OyhlAKAIArnDhxQu3atZOLi4tiYmJsGrYjR46oc+fO8vDwkJeXl3r06KGUlBSb1x86dEgWiyXfIy0tTZI0fvx4NWnSxDo+KytL9erVsxkTFRWlLl262GzXYrHYfNKZlJSkHj16yMfHR76+vurcubMOHTpk85oPPvhAoaGhcnFxUWBgoAYNGiRJql27doE1WiwWLVq0yLq/vIeXl5ceeughHTx40Lrt06dPq3fv3qpSpYoqV66sDh06KCEhodDzei37vNr5vfLc7d69Wz4+Pnr//fety9LS0vTss8+qevXq8vLyUtu2bfXTTz8Vug1J2rBhg835l6Tly5dbz13t2rU1ffr0Qo/H3d1dLVu21M6dOws9fgAA7In+ZpF1f/Q3Zae/IZQCAOAyJ0+eVHh4uJycnBQTEyMfHx/rutzcXHXu3FmnTp3Sxo0bFRMToz/++ENPPGE7dd8wDEnSunXrdOzYMS1fvrzIfc6ePTtf43c12dnZioiIkKenp77//ntt3rxZHh4eevjhh5WVlSVJmjdvnqKjozVgwADt2bNHK1euVL169SRJcXFxOnbsmI4dO6YaNWpo5syZ1ueXH8/ChQt17Ngxbdq0SampqXr55Zet66KiorRz506tXLlSW7dulWEYeuSRR5SdnV1gzVfb57We3zy//fabIiIiNHr0aD377LPW5d27d1dqaqr++9//ateuXbr77rvVrl07nTp16prP765du9SjRw/17NlTe/bs0fjx4zVmzBhrc5ln4sSJOnbsmHbu3Cl3d3dFR0df8z4AADAL/Q39jVQ2+xuuKQUAwP+cPn1a4eHh2rt3r5o2bSovLy+b9bGxsdqzZ48SExMVHBwsSfroo48UGhqquLg4NW/eXJKsTUtAQIACAgLk6+tb6D5PnTqlSZMmaeTIkRozZox1uZubm44dO1bo65YsWaLc3Fy9//77slgski41WD4+PtqwYYPat2+vSZMmafjw4XrhhResr8ursXr16tZljo6O8vb2VkBAQL79+Pj4KCAgQG5ubvL09LR+qpqQkKCVK1dq8+bNatmypSTp008/VXBwsFasWKHu3bvn29bV9hkTE3NN51eSDh8+rIceekgDBgzQv/71L+vyH374QTt27FBqaqpcXFwkSW+88YZWrFihZcuWacCAAYWe08u9+eabateunfVnctttt2nv3r2aNm2aoqKirOM8PT0VEBAgHx8fValSxfqzAACgrKC/ob/JUxb7G2ZKAQDwP5s2bVJubq7i4+N14MABTZ061Wb9vn37FBwcbG0oJCkkJEQ+Pj7at2+fdVlGRoYkyd3d/ar7nDhxoh588EHdd999NssbNWqkbdu2KTExscDX/fTTTzpw4IA8PT3l4eEhDw8P+fr6KjMzUwcPHlRqaqqOHj2qdu3aXfPxF+TJJ5+Uh4eHqlSpojNnzmjy5MmSLp0LJycntWjRwjq2atWquv32223ORXFc6/lNS0tTeHi4/vzzT0VERNhs46efftLZs2dVtWpV63nx8PBQYmKizdT8PXv22Kzv0KFDvlpatWpls6xVq1ZKSEhQTk6OddnIkSPl4eEhd3d37dixQ3PmzCnRsQMAcKPQ3+RHf/N/7N3fMFMKAID/qVu3rmJjY1WtWjXNnTtXTz/9tDp27Kg77rijWNs5evSoHBwcCvxk7nIJCQl6//33FR8frz///NNmXd++ffXll1+qbt26BTZ/Z8+eVdOmTfXpp5/mW1e9enU5OJTO504zZsxQeHi40tLS9MorrygqKkpff/11qWy7pA4fPqxevXrp6aefVt++ffXzzz+rcuXKki6dl8DAQG3YsCHf6y7/qsLtt9+ulStXWp9v375dTz/9dLFrGTFihKKionTu3Dm98cYb6tGjh3bu3ClHR8dibwsAgBuB/iY/+puimdnfEEoBAPA/jRs3VrVq1SRd+t7+F198od69e2vHjh1ydnZWw4YNlZSUpKSkJOunXXv37lVaWppCQkKs24mLi1ODBg3k6upa5P5GjhypZ599VvXq1cvXtLm5uWndunVKSUnRmTNnJEn169e3rr/77ru1ZMkS+fn55ZuGn6d27dqKjY3Vgw8+WPyT8T8BAQHW6zQ8//zzeuyxx5Sdna2GDRvq4sWL2r59u3V6+8mTJ7V//36bc1Ec13p+69ata732wVdffaVRo0bprbfeknTpvCQnJ8vJyUm1a9cudF/Ozs7W45KU7/w3bNhQmzdvtlm2efNm3XbbbTYNWbVq1azbGTlypBo3bqzExESbbQMAYE/0N/nR3/wfe/c3fH0PAIBCzJkzR6mpqZowYYIkKTw8XI0bN1avXr20e/du7dixQ71791abNm3UrFkzZWVl6eOPP9abb76pPn36FLntAwcOaMOGDRo7dmyR4/z9/VWvXr18TUCvXr1UrVo1de7cWd9//70SExO1YcMGDR482NqAjB8/XtOnT9esWbOUkJCg3bt36+233y7WOUhLS1NycrL279+vBQsWqG7duqpUqZLq16+vzp07q3///vrhhx/0008/6emnn9Ytt9yizp07F2sfea52fvN4enrKyclJTk5OWrRokd599119//331m2EhYWpS5cuWrt2rQ4dOqQtW7bolVdeKdadY4YPH67Y2Fi9+uqr+v333/Xhhx9q9uzZNtd3kKQzZ84oOTlZf/zxh2bPni1PT0/dcsstJTp+AADMQH9Df1OW+htCKQAACuHr66v33ntPU6ZM0fbt22WxWPTVV1+pSpUqat26tcLDw1W3bl0tWbJEkmzuYjJs2LAit33u3Dm98sorRV4ktCiVK1fWpk2bVLNmTXXt2lUNGzZUv379lJmZaf1kMTIyUjNnztTcuXMVGhqqTp06FXlL44L06dNHgYGBat68uU6fPq1ly5ZZ1y1cuFBNmzZVp06dFBYWJsMwtHr1alWqVKlEx3S181uQO+64Q6+88or69u2r8+fPy2KxaPXq1WrdurX69Omj2267TT179tThw4fl7+9/zbXcfffd+vzzz/XZZ5+pUaNGGjt2rCZOnGhzEVBJGjt2rAIDA9WoUSPt3r1bK1askJubW4mOHwAAM9Df0N+Upf7GYuTd1/EmlpGRIW9vb6Wnpxc6RbA09FsUV+i6BVHNC10HAOVJZmamEhMTVadOnatO7wZuJkX9bZR2L2JWbwMANwN6G6BgpdHbMFMKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgDcENzcFbDF3wQAlG/8Ow7YKo2/CUIpAECpqlSpkiTp/Pnzdq4EKFvy/iby/kYAAOUDvQ1QsNLobZxKqxgAACTJ0dFRPj4+Sk1NlSRVrlxZFovFzlUB9mMYhs6fP6/U1FT5+PjI0dHR3iUBAIqB3gawVZq9DaEUAKDUBQQESJK1eQMg+fj4WP82AADlC70NkF9p9DaEUgCAUmexWBQYGCg/Pz9lZ2fbuxzA7ipVqsQMKQAox+htAFul1dsQSgEAbhhHR0f+RxwAAFQY9DZA6bLrhc5r164ti8WS7xEdHS1JyszMVHR0tKpWrSoPDw9169ZNKSkpNts4cuSIOnbsqMqVK8vPz08jRozQxYsX7XE4AAAAAAAAuEZ2DaXi4uJ07Ngx6yMmJkaS1L17d0nS0KFD9fXXX2vp0qXauHGjjh49qq5du1pfn5OTo44dOyorK0tbtmzRhx9+qEWLFmns2LF2OR4AAAAAAABcG7uGUtWrV1dAQID1sWrVKt16661q06aN0tPTtWDBAr355ptq27atmjZtqoULF2rLli3atm2bJGnt2rXau3evPvnkEzVp0kQdOnTQq6++qjlz5igrK8uehwYAAAAAAIAi2DWUulxWVpY++eQT9e3bVxaLRbt27VJ2drbCw8OtYxo0aKCaNWtq69atkqStW7eqcePG8vf3t46JiIhQRkaGfv3110L3deHCBWVkZNg8AAAAyit6GwAAUB6VmVBqxYoVSktLU1RUlCQpOTlZzs7O8vHxsRnn7++v5ORk65jLA6m89XnrCjN58mR5e3tbH8HBwaV3IAAAACajtwEAAOVRmQmlFixYoA4dOigoKOiG72vUqFFKT0+3PpKSkm74PgEAAG4UehsAAFAeOdm7AEk6fPiw1q1bpy+++MK6LCAgQFlZWUpLS7OZLZWSkqKAgADrmB07dthsK+/ufHljCuLi4iIXF5dSPAIAAAD7obcBAADlUZmYKbVw4UL5+fmpY8eO1mVNmzZVpUqVFBsba122f/9+HTlyRGFhYZKksLAw7dmzR6mpqdYxMTEx8vLyUkhIiHkHAAAAAAAAgGKx+0yp3NxcLVy4UJGRkXJy+r9yvL291a9fPw0bNky+vr7y8vLS888/r7CwMN17772SpPbt2yskJETPPPOMpk6dquTkZI0ePVrR0dF8WggAAAAAAFCG2T2UWrdunY4cOaK+ffvmWzdjxgw5ODioW7duunDhgiIiIjR37lzrekdHR61atUoDBw5UWFiY3N3dFRkZqYkTJ5p5CAAAAAAAACgmu4dS7du3l2EYBa5zdXXVnDlzNGfOnEJfX6tWLa1evfpGlQcAAAAAAIAboExcUwoAAAAAAAA3F0IpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDp7B5K/fXXX3r66adVtWpVubm5qXHjxtq5c6d1vWEYGjt2rAIDA+Xm5qbw8HAlJCTYbOPUqVPq1auXvLy85OPjo379+uns2bNmHwoAAAAAAACukV1DqdOnT6tVq1aqVKmS/vvf/2rv3r2aPn26qlSpYh0zdepUzZo1S++88462b98ud3d3RUREKDMz0zqmV69e+vXXXxUTE6NVq1Zp06ZNGjBggD0OCQAAAAAAANfAyZ47nzJlioKDg7Vw4ULrsjp16lj/2zAMzZw5U6NHj1bnzp0lSR999JH8/f21YsUK9ezZU/v27dOaNWsUFxenZs2aSZLefvttPfLII3rjjTcUFBRk7kEBAAAAAADgquw6U2rlypVq1qyZunfvLj8/P91111167733rOsTExOVnJys8PBw6zJvb2+1aNFCW7dulSRt3bpVPj4+1kBKksLDw+Xg4KDt27ebdzAAAAAAAAC4ZnYNpf744w/NmzdP9evX17fffquBAwdq8ODB+vDDDyVJycnJkiR/f3+b1/n7+1vXJScny8/Pz2a9k5OTfH19rWOudOHCBWVkZNg8AAAAyit6GwAAUB7ZNZTKzc3V3Xffrddff1133XWXBgwYoP79++udd965ofudPHmyvL29rY/g4OAbuj8AAIAbid4GAACUR3YNpQIDAxUSEmKzrGHDhjpy5IgkKSAgQJKUkpJiMyYlJcW6LiAgQKmpqTbrL168qFOnTlnHXGnUqFFKT0+3PpKSkkrleAAAAOyB3gYAAJRHdg2lWrVqpf3799ss+/3331WrVi1Jly56HhAQoNjYWOv6jIwMbd++XWFhYZKksLAwpaWladeuXdYx3333nXJzc9WiRYsC9+vi4iIvLy+bBwAAQHlFbwMAAMoju959b+jQoWrZsqVef/119ejRQzt27ND8+fM1f/58SZLFYtGQIUM0adIk1a9fX3Xq1NGYMWMUFBSkLl26SLo0s+rhhx+2fu0vOztbgwYNUs+ePbnzHgAAAAAAQBll11CqefPm+vLLLzVq1ChNnDhRderU0cyZM9WrVy/rmBdffFHnzp3TgAEDlJaWpvvuu09r1qyRq6urdcynn36qQYMGqV27dnJwcFC3bt00a9YsexwSAAAAAAAAroHFMAzD3kXYW0ZGhry9vZWenn5Dp7v3WxRX6LoFUc1v2H4BAEDZVtq9iFm9DQAAQEGutRex6zWlAAAAAAAAcHMilAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKazayg1fvx4WSwWm0eDBg2s6zMzMxUdHa2qVavKw8ND3bp1U0pKis02jhw5oo4dO6py5cry8/PTiBEjdPHiRbMPBQAAAAAAAMXgZO8CQkNDtW7dOutzJ6f/K2no0KH65ptvtHTpUnl7e2vQoEHq2rWrNm/eLEnKyclRx44dFRAQoC1btujYsWPq3bu3KlWqpNdff930YwEAAAAAAMC1sXso5eTkpICAgHzL09PTtWDBAi1evFht27aVJC1cuFANGzbUtm3bdO+992rt2rXau3ev1q1bJ39/fzVp0kSvvvqqRo4cqfHjx8vZ2dnswwEAAAAAAMA1sPs1pRISEhQUFKS6deuqV69eOnLkiCRp165dys7OVnh4uHVsgwYNVLNmTW3dulWStHXrVjVu3Fj+/v7WMREREcrIyNCvv/5a6D4vXLigjIwMmwcAAEB5RW8DAADKI7uGUi1atNCiRYu0Zs0azZs3T4mJibr//vt15swZJScny9nZWT4+Pjav8ff3V3JysiQpOTnZJpDKW5+3rjCTJ0+Wt7e39REcHFy6BwYAAGAiehsAAFAe2TWU6tChg7p376477rhDERERWr16tdLS0vT555/f0P2OGjVK6enp1kdSUtIN3R8AAMCNRG8DAADKI7tfU+pyPj4+uu2223TgwAE99NBDysrKUlpams1sqZSUFOs1qAICArRjxw6bbeTdna+g61TlcXFxkYuLS+kfAAAAgB3Q2wAAgPLI7teUutzZs2d18OBBBQYGqmnTpqpUqZJiY2Ot6/fv368jR44oLCxMkhQWFqY9e/YoNTXVOiYmJkZeXl4KCQkxvX4AAAAAAABcG7vOlPrXv/6lRx99VLVq1dLRo0c1btw4OTo66sknn5S3t7f69eunYcOGydfXV15eXnr++ecVFhame++9V5LUvn17hYSE6JlnntHUqVOVnJys0aNHKzo6mk8LS0m/RXGFrlsQ1dzESgAAAAAAQEVi11Dqzz//1JNPPqmTJ0+qevXquu+++7Rt2zZVr15dkjRjxgw5ODioW7duunDhgiIiIjR37lzr6x0dHbVq1SoNHDhQYWFhcnd3V2RkpCZOnGivQwIAAAAAAMA1sGso9dlnnxW53tXVVXPmzNGcOXMKHVOrVi2tXr26tEsDAAAAAADADVSmrikFAAAAAACAmwOhFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdE72LgAotsVPXP82nlpy/dsAAAAAAAAlxkwpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpnEr6wnPnzmnjxo06cuSIsrKybNYNHjz4ugsDAAAAAABAxVWiUOrHH3/UI488ovPnz+vcuXPy9fXViRMnVLlyZfn5+RFKAQAAAAAAoEgl+vre0KFD9eijj+r06dNyc3PTtm3bdPjwYTVt2lRvvPFGadcIAAAAAACACqZEoVR8fLyGDx8uBwcHOTo66sKFCwoODtbUqVP18ssvl3aNAAAAAAAAqGBKFEpVqlRJDg6XXurn56cjR45Ikry9vZWUlFR61QEAAAAAAKBCKtE1pe666y7FxcWpfv36atOmjcaOHasTJ07o448/VqNGjUq7RgAAAAAAAFQwJZop9frrryswMFCS9Nprr6lKlSoaOHCgjh8/rvnz55dqgQAAAAAAAKh4SjRTqlmzZtb/9vPz05o1a0qtIAAAAAAAAFR8JZop1bZtW6WlpZVyKQAAAAAAALhZlCiU2rBhg7Kyskq7FgAAAAAAANwkShRKSZLFYinNOgAAAAAAAHATKdE1pSTp8ccfl7Ozc4HrvvvuuxIXBAAAAAAAgIqvxKFUWFiYPDw8SrMWAAAAAAAA3CRKFEpZLBaNGDFCfn5+pV0PAAAAAAAAbgIluqaUYRilXQcAAAAAAABuIiUKpcaNG8dX9wAAAAAAAFBiJfr63rhx4yRJx48f1/79+yVJt99+u6pXr156lQEAAAAAAKDCKtFMqfPnz6tv374KCgpS69at1bp1awUFBalfv346f/58adcIAAAAAACACqZEodTQoUO1ceNGrVy5UmlpaUpLS9NXX32ljRs3avjw4aVdIwAAAAAAACqYEn19b/ny5Vq2bJkeeOAB67JHHnlEbm5u6tGjh+bNm1da9QEAAAAAAKACKvHX9/z9/fMt9/PzK/HX9/7973/LYrFoyJAh1mWZmZmKjo5W1apV5eHhoW7duiklJcXmdUeOHFHHjh1VuXJl+fn5acSIEbp48WKJagAAAAAAAIA5ShRKhYWFady4ccrMzLQu+/vvvzVhwgSFhYUVe3txcXF69913dccdd9gsHzp0qL7++mstXbpUGzdu1NGjR9W1a1fr+pycHHXs2FFZWVnasmWLPvzwQy1atEhjx44tyWEBAAAAAADAJCX6+t7MmTP18MMPq0aNGrrzzjslST/99JNcXV317bffFmtbZ8+eVa9evfTee+9p0qRJ1uXp6elasGCBFi9erLZt20qSFi5cqIYNG2rbtm269957tXbtWu3du1fr1q2Tv7+/mjRpoldffVUjR47U+PHj5ezsXJLDAwAAAAAAwA1WoplSjRs3VkJCgiZPnqwmTZqoSZMm+ve//62EhASFhoYWa1vR0dHq2LGjwsPDbZbv2rVL2dnZNssbNGigmjVrauvWrZKkrVu3qnHjxjZfJYyIiFBGRoZ+/fXXQvd54cIFZWRk2DwAAADKK3obAABQHpVoptSmTZvUsmVL9e/f/7p2/tlnn2n37t2Ki4vLty45OVnOzs7y8fGxWe7v76/k5GTrmCuvbZX3PG9MQSZPnqwJEyZcV+0AAABlBb0NAAAoj0o0U+rBBx/UqVOnrmvHSUlJeuGFF/Tpp5/K1dX1urZVXKNGjVJ6err1kZSUZOr+AQAAShO9DQAAKI9KNFPKMIzr3vGuXbuUmpqqu+++27osJydHmzZt0uzZs/Xtt98qKytLaWlpNrOlUlJSFBAQIEkKCAjQjh07bLabd3e+vDEFcXFxkYuLy3UfAwAAQFlAbwMAAMqjEoVS0qXrOVWpUqXAda1bt77q69u1a6c9e/bYLOvTp48aNGigkSNHKjg4WJUqVVJsbKy6desmSdq/f7+OHDlivcNfWFiYXnvtNaWmpsrPz0+SFBMTIy8vL4WEhJT00AAAAAAAAHCDlTiUevzxxwtcbrFYlJOTc9XXe3p6qlGjRjbL3N3dVbVqVevyfv36adiwYfL19ZWXl5eef/55hYWF6d5775UktW/fXiEhIXrmmWc0depUJScna/To0YqOjubTQgAAAAAAgDKsxKFUcnKydXbSjTJjxgw5ODioW7duunDhgiIiIjR37lzrekdHR61atUoDBw5UWFiY3N3dFRkZqYkTJ97QugAAAAAAAHB9ShRKWSyW0q5DkrRhwwab566urpozZ47mzJlT6Gtq1aql1atX35B6AAAAAAAAcGOU6O57pXGhcwAAAAAAANy8SjRTKjc3t7TrAAAAAAAAwE2kRDOlJk+erA8++CDf8g8++EBTpky57qIAAAAAAABQsZUolHr33XfVoEGDfMtDQ0P1zjvvXHdRAAAAAAAAqNhKFEolJycrMDAw3/Lq1avr2LFj110UAAAAAAAAKrYShVLBwcHavHlzvuWbN29WUFDQdRcFAAAAAACAiq1EFzrv37+/hgwZouzsbLVt21aSFBsbqxdffFHDhw8v1QIBAAAAAABQ8ZQolBoxYoROnjyp5557TllZWZIkV1dXjRw5UqNGjSrVAgEAAAAAAFDxlCiUslgsmjJlisaMGaN9+/bJzc1N9evXl4uLS2nXBwAAAAAAgAqoRKFUHg8PDzVv3ry0agEAAAAAAMBNosSh1M6dO/X555/ryJEj1q/w5fniiy+uuzAAAAAAAABUXCW6+95nn32mli1bat++ffryyy+VnZ2tX3/9Vd999528vb1Lu0YAAAAAAABUMCUKpV5//XXNmDFDX3/9tZydnfXWW2/pt99+U48ePVSzZs3SrhEAAAAAAAAVTIlCqYMHD6pjx46SJGdnZ507d04Wi0VDhw7V/PnzS7VAAAAAAAAAVDwlCqWqVKmiM2fOSJJuueUW/fLLL5KktLQ0nT9/vvSqAwAAAAAAQIVUogudt27dWjExMWrcuLG6d++uF154Qd99951iYmLUrl270q4RAAAAAAAAFUyJQqnZs2crMzNTkvTKK6+oUqVK2rJli7p166bRo0eXaoEAAAAAAACoeIoVSmVkZFx6kZOTPDw8rM+fe+45Pffcc6VfHQAAAAAAACqkYoVSPj4+slgsVx2Xk5NT4oIAAAAAAABQ8RUrlFq/fr3Nc8Mw9Mgjj+j999/XLbfcUqqFAQAAAAAAoOIqVijVpk2bfMscHR117733qm7duqVWFAAAAAAAACo2B3sXAAAAAAAAgJvPdYVSSUlJOn/+vKpWrVpa9QAAAAAAAOAmUKyv782aNcv63ydOnNB//vMftW3bVt7e3qVeGAAAAAAAACquYoVSM2bMkCRZLBZVq1ZNjz76qEaPHn1DCgMAAAAAAEDFVaxQKjEx8UbVAQAAAAAAgJsIFzoHAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDonexcA3LQWP3H923hqyfVvAwAAAAAAO2CmFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdE723Pm8efM0b948HTp0SJIUGhqqsWPHqkOHDpKkzMxMDR8+XJ999pkuXLigiIgIzZ07V/7+/tZtHDlyRAMHDtT69evl4eGhyMhITZ48WU5Odj20smvxE8Ua/nxKms3zt/0nlWIxAAAAAADgZmXXmVI1atTQv//9b+3atUs7d+5U27Zt1blzZ/3666+SpKFDh+rrr7/W0qVLtXHjRh09elRdu3a1vj4nJ0cdO3ZUVlaWtmzZog8//FCLFi3S2LFj7XVIAAAAAAAAuAZ2nU706KOP2jx/7bXXNG/ePG3btk01atTQggULtHjxYrVt21aStHDhQjVs2FDbtm3Tvffeq7Vr12rv3r1at26d/P391aRJE7366qsaOXKkxo8fL2dnZ3scFgAAAAAAAK6izFxTKicnR5999pnOnTunsLAw7dq1S9nZ2QoPD7eOadCggWrWrKmtW7dKkrZu3arGjRvbfJ0vIiJCGRkZ1tlWAAAAAAAAKHvsfuGlPXv2KCwsTJmZmfLw8NCXX36pkJAQxcfHy9nZWT4+Pjbj/f39lZycLElKTk62CaTy1uetK8yFCxd04cIF6/OMjIxSOhoAAADz0dsAAIDyyO4zpW6//XbFx8dr+/btGjhwoCIjI7V3794bus/JkyfL29vb+ggODr6h+wMAALiR6G0AAEB5ZPdQytnZWfXq1VPTpk01efJk3XnnnXrrrbcUEBCgrKwspaWl2YxPSUlRQECAJCkgIEApKSn51uetK8yoUaOUnp5ufSQlJZXuQQEAAJiI3gYAAJRHdg+lrpSbm6sLFy6oadOmqlSpkmJjY63r9u/fryNHjigsLEySFBYWpj179ig1NdU6JiYmRl5eXgoJCSl0Hy4uLvLy8rJ5AAAAlFf0NgAAoDyy6zWlRo0apQ4dOqhmzZo6c+aMFi9erA0bNujbb7+Vt7e3+vXrp2HDhsnX11deXl56/vnnFRYWpnvvvVeS1L59e4WEhOiZZ57R1KlTlZycrNGjRys6OlouLi72PDQAAAAAAAAUwa6hVGpqqnr37q1jx47J29tbd9xxh7799ls99NBDkqQZM2bIwcFB3bp104ULFxQREaG5c+daX+/o6KhVq1Zp4MCBCgsLk7u7uyIjIzVx4kR7HRIAAAAAAACugV1DqQULFhS53tXVVXPmzNGcOXMKHVOrVi2tXr26tEsDAAAAAADADVTmrikFAAAAAACAio9QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmM6uodTkyZPVvHlzeXp6ys/PT126dNH+/fttxmRmZio6OlpVq1aVh4eHunXrppSUFJsxR44cUceOHVW5cmX5+flpxIgRunjxopmHAgAAAAAAgGKwayi1ceNGRUdHa9u2bYqJiVF2drbat2+vc+fOWccMHTpUX3/9tZYuXaqNGzfq6NGj6tq1q3V9Tk6OOnbsqKysLG3ZskUffvihFi1apLFjx9rjkAAAAAAAAHANnOy58zVr1tg8X7Rokfz8/LRr1y61bt1a6enpWrBggRYvXqy2bdtKkhYuXKiGDRtq27Ztuvfee7V27Vrt3btX69atk7+/v5o0aaJXX31VI0eO1Pjx4+Xs7GyPQwMAAAAAAEARytQ1pdLT0yVJvr6+kqRdu3YpOztb4eHh1jENGjRQzZo1tXXrVknS1q1b1bhxY/n7+1vHREREKCMjQ7/++muB+7lw4YIyMjJsHgAAAOUVvQ0AACiPykwolZubqyFDhqhVq1Zq1KiRJCk5OVnOzs7y8fGxGevv76/k5GTrmMsDqbz1eesKMnnyZHl7e1sfwcHBpXw0AAAA5qG3AQAA5VGZCaWio6P1yy+/6LPPPrvh+xo1apTS09Otj6SkpBu+TwAAgBuF3gYAAJRHdr2mVJ5BgwZp1apV2rRpk2rUqGFdHhAQoKysLKWlpdnMlkpJSVFAQIB1zI4dO2y2l3d3vrwxV3JxcZGLi0spHwUAAIB90NsAAIDyyK4zpQzD0KBBg/Tll1/qu+++U506dWzWN23aVJUqVVJsbKx12f79+3XkyBGFhYVJksLCwrRnzx6lpqZax8TExMjLy0shISHmHAgAAAAAAACKxa4zpaKjo7V48WJ99dVX8vT0tF4DytvbW25ubvL29la/fv00bNgw+fr6ysvLS88//7zCwsJ07733SpLat2+vkJAQPfPMM5o6daqSk5M1evRoRUdH84khAAAAAABAGWXXUGrevHmSpAceeMBm+cKFCxUVFSVJmjFjhhwcHNStWzdduHBBERERmjt3rnWso6OjVq1apYEDByosLEzu7u6KjIzUxIkTzToMAAAAAAAAFJNdQynDMK46xtXVVXPmzNGcOXMKHVOrVi2tXr26NEsDAAAAAADADVRm7r4HAAAAAACAmwehFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTOdm7AAB2tPiJ69/GU0uufxsAAAAAgJsOM6UAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKbjmlKocOKT0opc3yTYx5Q6AAAAAABA4ZgpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATGfXUGrTpk169NFHFRQUJIvFohUrVtisNwxDY8eOVWBgoNzc3BQeHq6EhASbMadOnVKvXr3k5eUlHx8f9evXT2fPnjXxKAAAAAAAAFBcdg2lzp07pzvvvFNz5swpcP3UqVM1a9YsvfPOO9q+fbvc3d0VERGhzMxM65hevXrp119/VUxMjFatWqVNmzZpwIABZh0CAAAAAAAASsDJnjvv0KGDOnToUOA6wzA0c+ZMjR49Wp07d5YkffTRR/L399eKFSvUs2dP7du3T2vWrFFcXJyaNWsmSXr77bf1yCOP6I033lBQUJBpxwIAAAAAAIBrV2avKZWYmKjk5GSFh4dbl3l7e6tFixbaunWrJGnr1q3y8fGxBlKSFB4eLgcHB23fvr3QbV+4cEEZGRk2DwAAgPKK3gYAAJRHZTaUSk5OliT5+/vbLPf397euS05Olp+fn816Jycn+fr6WscUZPLkyfL29rY+goODS7l6AAAA89DbAACA8qjMhlI30qhRo5Senm59JCUl2bskAACAEqO3AQAA5ZFdrylVlICAAElSSkqKAgMDrctTUlLUpEkT65jU1FSb1128eFGnTp2yvr4gLi4ucnFxKf2iAQAA7IDeBgAAlEdldqZUnTp1FBAQoNjYWOuyjIwMbd++XWFhYZKksLAwpaWladeuXdYx3333nXJzc9WiRQvTawYAAAAAAMC1setMqbNnz+rAgQPW54mJiYqPj5evr69q1qypIUOGaNKkSapfv77q1KmjMWPGKCgoSF26dJEkNWzYUA8//LD69++vd955R9nZ2Ro0aJB69uzJnfcAAAAAAADKMLuGUjt37tSDDz5ofT5s2DBJUmRkpBYtWqQXX3xR586d04ABA5SWlqb77rtPa9askaurq/U1n376qQYNGqR27drJwcFB3bp106xZs0w/FgAAAAAAAFw7u4ZSDzzwgAzDKHS9xWLRxIkTNXHixELH+Pr6avHixTeiPAAAAAAAANwgZfaaUgAAAAAAAKi4CKUAAAAAAABgOrt+fQ8AAADlV79FcYWuWxDV3MRKAABAecRMKQAAAAAAAJiOmVIAyr/FT1z/Np5acv3bAAAAAABcM2ZKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0znZu4CbyfMpowtfudjn6ht4akmp1QIAAAAAAGBPzJQCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOa0oBAADgptdvUVyR6xdENTepEgAAbh7MlAIAAAAAAIDpmCkFAAAAlHeLn7j+bXCnZwCAyZgpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwnZO9CwAgxSelFbm+SbCPKXUAAAAAAGAWZkoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTcaFzAAAAABXD4ieufxtPLbn+bQAArgmhFACUFdfbSNNEAwAAAChHCKUAAABw8/rfBwLPp6RdZZxP4ev4UAAAgBLhmlIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0TvYuAAAAAABwmcVPXP82nlpy/dsAgBuMUApAicQnpUmS3l4UV+D6BVHNTawGZcr1NtI00QBwQ+W9h18p7z2d93AAgFn4+h4AAAAAAABMx0wpAAAAlMjzKaMLX7nY5+obYGYkAAA3NUIpAAAAAEDp49pYAK6iwoRSc+bM0bRp05ScnKw777xTb7/9tu655x57lwUAsAeuawUAAMoKwjmgUBXimlJLlizRsGHDNG7cOO3evVt33nmnIiIilJqaau/SAAAAAAAAUIAKMVPqzTffVP/+/dWnTx9J0jvvvKNvvvlGH3zwgV566SU7VwcAQAkx4wsArqrfZXcCfj4lzWZdk2Afc4sBABRLuQ+lsrKytGvXLo0aNcq6zMHBQeHh4dq6dasdKwNgD4Xd5joPzSkAACir8gK2K8O1PPQxQCngQ78ypdyHUidOnFBOTo78/f1tlvv7++u3334r8DUXLlzQhQsXrM/T09MlSRkZGTeuUElnMy8Wui7jfPbVN1Aa9V3Lfi5zZc1Zf5+9rJwbe74KdZVjKOo8S/871/aq/XKXHcc11Vzgius8jmL+Plwur+bLfycuZ+rvR1k4l6XhOn4eksrGMUhl4zjKQg2loaIch719HnX92+ix6Pq3UYS8fzMNwyjR62/q3uZ6/a/OEr9/SGXqOK5FYcea955utx6vhC7vRa48tmv6PbySHY8/71gK+xkV63jKws/xet/HpLJxHNeropyHcvB+ek0qSn91vT+PMtLbWIySdj9lxNGjR3XLLbdoy5YtCgsLsy5/8cUXtXHjRm3fvj3fa8aPH68JEyaYWSYAAMBVJSUlqUaNGsV+Hb0NAAAoi67W25T7UCorK0uVK1fWsmXL1KVLF+vyyMhIpaWl6auvvsr3mis/TczNzdWpU6dUtWpVWSwWM8ouFzIyMhQcHKykpCR5eXnZu5wKi/NsHs61OTjP5uFcm8OM82wYhs6cOaOgoCA5OBT/PjT0NqWLv63yiZ9b+cXPrvziZ1c+laXeptx/fc/Z2VlNmzZVbGysNZTKzc1VbGysBg0aVOBrXFxc5OLiYrPMx8fnBldafnl5efEPjAk4z+bhXJuD82wezrU5bvR59vb2LvFr6W1uDP62yid+buUXP7vyi59d+VQWeptyH0pJ0rBhwxQZGalmzZrpnnvu0cyZM3Xu3Dnr3fgAAAAAAABQtlSIUOqJJ57Q8ePHNXbsWCUnJ6tJkyZas2ZNvoufAwAAAAAAoGyoEKGUJA0aNKjQr+uhZFxcXDRu3Lh8XwdA6eI8m4dzbQ7Os3k41+bgPN98+JmXT/zcyi9+duUXP7vyqSz93Mr9hc4BAAAAAABQ/hT/9i4AAAAAAADAdSKUAgAAAAAAgOkIpQAAAAAAAGA6QinYmDx5spo3by5PT0/5+fmpS5cu2r9/v73Luin8+9//lsVi0ZAhQ+xdSoXz119/6emnn1bVqlXl5uamxo0ba+fOnfYuq8LJycnRmDFjVKdOHbm5uenWW2/Vq6++Ki5deH02bdqkRx99VEFBQbJYLFqxYoXNesMwNHbsWAUGBsrNzU3h4eFKSEiwT7HlXFHnOjs7WyNHjlTjxo3l7u6uoKAg9e7dW0ePHrVfwSh19EEVAz1V+UKfVv7Q85Uf5aGPJJSCjY0bNyo6Olrbtm1TTEyMsrOz1b59e507d87epVVocXFxevfdd3XHHXfYu5QK5/Tp02rVqpUqVaqk//73v9q7d6+mT5+uKlWq2Lu0CmfKlCmaN2+eZs+erX379mnKlCmaOnWq3n77bXuXVq6dO3dOd955p+bMmVPg+qlTp2rWrFl65513tH37drm7uysiIkKZmZkmV1r+FXWuz58/r927d2vMmDHavXu3vvjiC+3fv1+PPfaYHSrFjUIfVP7RU5Uv9GnlEz1f+VEe+kjuvociHT9+XH5+ftq4caNat25t73IqpLNnz+ruu+/W3LlzNWnSJDVp0kQzZ860d1kVxksvvaTNmzfr+++/t3cpFV6nTp3k7++vBQsWWJd169ZNbm5u+uSTT+xYWcVhsVj05ZdfqkuXLpIufboVFBSk4cOH61//+pckKT09Xf7+/lq0aJF69uxpx2rLtyvPdUHi4uJ0zz336PDhw6pZs6Z5xcE09EHlCz1V+UOfVj7R85VPZbWPZKYUipSeni5J8vX1tXMlFVd0dLQ6duyo8PBwe5dSIa1cuVLNmjVT9+7d5efnp7vuukvvvfeevcuqkFq2bKnY2Fj9/vvvkqSffvpJP/zwgzp06GDnyiquxMREJScn2/z74e3trRYtWmjr1q12rOzmkJ6eLovFIh8fH3uXghuEPqh8oacqf+jTyid6voqhrPSRTqbtCeVObm6uhgwZolatWqlRo0b2LqdC+uyzz7R7927FxcXZu5QK648//tC8efM0bNgwvfzyy4qLi9PgwYPl7OysyMhIe5dXobz00kvKyMhQgwYN5OjoqJycHL322mvq1auXvUursJKTkyVJ/v7+Nsv9/f2t63BjZGZmauTIkXryySfl5eVl73JwA9AHlS/0VOUTfVr5RM9XMZSVPpJQCoWKjo7WL7/8oh9++MHepVRISUlJeuGFFxQTEyNXV1d7l1Nh5ebmqlmzZnr99dclSXfddZd++eUXvfPOOzQ7pezzzz/Xp59+qsWLFys0NFTx8fEaMmSIgoKCONeoULKzs9WjRw8ZhqF58+bZuxzcIPRB5Qc9VflFn1Y+0fOhNPH1PRRo0KBBWrVqldavX68aNWrYu5wKadeuXUpNTdXdd98tJycnOTk5aePGjZo1a5acnJyUk5Nj7xIrhMDAQIWEhNgsa9iwoY4cOWKniiquESNG6KWXXlLPnj3VuHFjPfPMMxo6dKgmT55s79IqrICAAElSSkqKzfKUlBTrOpSuvEDq8OHDiomJYZZUBUUfVL7QU5Vf9GnlEz1fxVBW+khCKdgwDEODBg3Sl19+qe+++0516tSxd0kVVrt27bRnzx7Fx8dbH82aNVOvXr0UHx8vR0dHe5dYIbRq1Srf7bx///131apVy04VVVznz5+Xg4Pt24qjo6Nyc3PtVFHFV6dOHQUEBCg2Nta6LCMjQ9u3b1dYWJgdK6uY8gKphIQErVu3TlWrVrV3SShl9EHlEz1V+UWfVj7R81UMZaWP5Ot7sBEdHa3Fixfrq6++kqenp/W7pN7e3nJzc7NzdRWLp6dnvmtUuLu7q2rVqly7ohQNHTpULVu21Ouvv64ePXpox44dmj9/vubPn2/v0iqcRx99VK+99ppq1qyp0NBQ/fjjj3rzzTfVt29fe5dWrp09e1YHDhywPk9MTFR8fLx8fX1Vs2ZNDRkyRJMmTVL9+vVVp04djRkzRkFBQUXeNQ4FK+pcBwYG6h//+Id2796tVatWKScnx/oe6evrK2dnZ3uVjVJEH1Q+0VOVX/Rp5RM9X/lRLvpIA7iMpAIfCxcutHdpN4U2bdoYL7zwgr3LqHC+/vpro1GjRoaLi4vRoEEDY/78+fYuqULKyMgwXnjhBaNmzZqGq6urUbduXeOVV14xLly4YO/SyrX169cX+O9yZGSkYRiGkZuba4wZM8bw9/c3XFxcjHbt2hn79++3b9HlVFHnOjExsdD3yPXr19u7dJQS+qCKg56q/KBPK3/o+cqP8tBHWgzDMG548gUAAAAAAABchmtKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgDKvKioKHXp0sVm2fHjx9WoUSO1aNFC6enp9ikMAACgBOhtAOASQikA5c7x48fVtm1bubm5ae3atfL29rZ3SQAAACVGbwPgZkUoBaBcOXHihNq1aycXFxfFxMRYm7YjR46oc+fO8vDwkJeXl3r06KGUlBSb1x46dEgWiyXfIy0tTZI0fvx4NWnSxDo+KytL9erVsxlT0CebFotFK1assD5PSkpSjx495OPjI19fX3Xu3FmHDh2yec0HH3yg0NBQubi4KDAwUIMGDZIk1a5du8AaLRaLFi1aZN1f3sPLy0sPPfSQDh48aN326dOn1bt3b1WpUkWVK1dWhw4dlJCQULITDgAAbih6G3ob4GZGKAWg3Dh58qTCw8Pl5OSkmJgY+fj4SJJyc3PVuXNnnTp1Shs3blRMTIz++OMPPfHEEzavNwxDkrRu3TodO3ZMy5cvL3J/s2fPztf8XU12drYiIiLk6emp77//Xps3b5aHh4cefvhhZWVlSZLmzZun6OhoDRgwQHv27NHKlStVr149SVJcXJyOHTumY8eOqUaNGpo5c6b1+eXHs3DhQh07dkybNm1SamqqXn75Zeu6qKgo7dy5UytXrtTWrVtlGIYeeeQRZWdnF+tYAADAjUVvQ28D3Oyc7F0AAFyL06dPKzw8XHv37lXTpk3l5eVlXRcbG6s9e/YoMTFRwcHBkqSPPvpIoaGhiouLU/PmzSXJ2rgEBAQoICBAvr6+he7v1KlTmjRpkkaOHKkxY8ZYl7u5uenYsWOFvm7JkiXKzc3V+++/L4vFIulSk+Xj46MNGzaoffv2mjRpkoYPH64XXnjB+rq8GqtXr25d5ujoKG9vbwUEBOTbj4+PjwICAuTm5iZPT0/rp6oJCQlauXKlNm/erJYtW0qSPv30UwUHB2vFihXq3r17obUDAADz0NvYorcBbk7MlAJQLmzatEm5ubmKj4/XgQMHNHXqVOu6ffv2KTg42Nq0SVJISIh8fHy0b98+67KMjAxJkru7+1X3N3HiRD344IO67777bJY3atRI27ZtU2JiYoGv++mnn3TgwAF5enrKw8NDHh4e8vX1VWZmpg4ePKjU1FQdPXpU7dq1K9bxX+nJJ5+Uh4eHqlSpojNnzmjy5MmSLp0LJycntWjRwjq2atWquv32223OBQAAsC96G1v0NsDNiZlSAMqFunXrKjY2VtWqVdPcuXP19NNPq2PHjrrjjjuueRtHjx6Vg4NDgZ/OXS4hIUHvv/++4uPj9eeff9qs69u3r7788kvVrVu3wAbw7Nmzatq0qT799NN866pXry4Hh9L5LGDGjBkKDw9XWlqaXnnlFUVFRenrr78ulW0DAIAbj97GFr0NcHNiphSAcqFx48aqVq2aJKl79+7q2rWrevfuraysLDVs2FBJSUlKSkqyjt+7d6/S0tIUEhJiXRYXF6cGDRrI1dW1yH2NHDlSzz77rPVaCJdzc3PTunXrlJycrPj4eMXHx9usv/vuu5WQkCA/Pz/Vq1fP5uHt7S1PT0/Vrl1bsbGx13E2Lk3Tr1evnpo1a6bnn39e33zzjbKzs9WwYUNdvHhR27dvt449efKk9u/fb3MuAACAfdHb2KK3AW5OhFIAyqU5c+YoNTVVEyZMUHh4uBo3bqxevXpp9+7d2rFjh3r37q02bdqoWbNmysrK0scff6w333xTffr0KXK7Bw4c0IYNGzR27Ngix/n7+1sbssv16tVL1apVU+fOnfX9998rMTFRGzZs0ODBg62fTI4fP17Tp0/XrFmzlJCQoN27d+vtt98u1vGnpaUpOTlZ+/fv14IFC1S3bl1VqlRJ9evXV+fOndW/f3/98MMP+umnn/T000/rlltuUefOnYu1DwAAYB56G3ob4GZEKAWgXPL19dV7772nKVOmaMeOHfrqq69UpUoVtW7dWuHh4apbt66WLFkiSdqzZ4/Gjx+vMWPGaNiwYUVu99y5c3rllVeKvFBoUSpXrqxNmzapZs2a6tq1qxo2bKh+/fopMzPTegHTyMhIzZw5U3PnzlVoaKg6depU7Nsa9+nTR4GBgWrevLlOnz6tZcuWWdctXLhQTZs2VadOnRQWFibDMLR69WpVqlSpRMcEAABuPHobehvgZmQx8u4jCgAAAAAAAJiEmVIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0/x8q9OVhLsxPBQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Подсчет количества слов и токенов с использованием токенизатора\n",
    "train_word_counts = [len(example[\"input\"].split()) for example in dataset_2[\"train\"]]\n",
    "train_token_counts = [\n",
    "    len(t5_ft_tokenizer.tokenize(example[\"input\"])) for example in dataset_2[\"train\"]\n",
    "]\n",
    "\n",
    "test_word_counts = [len(example[\"input\"].split()) for example in dataset_2[\"test\"]]\n",
    "test_token_counts = [\n",
    "    len(t5_ft_tokenizer.tokenize(example[\"input\"])) for example in dataset_2[\"test\"]\n",
    "]\n",
    "\n",
    "# Визуализация результатов\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Гистограмма для тренировочного набора данных\n",
    "axes[0].hist(train_word_counts, bins=30, alpha=0.7, label=\"Количество слов\")\n",
    "axes[0].hist(train_token_counts, bins=30, alpha=0.7, label=\"Количество токенов\")\n",
    "axes[0].set_title(\"Тренировочный набор данных\")\n",
    "axes[0].set_xlabel(\"Количество\")\n",
    "axes[0].set_ylabel(\"Частота\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Гистограмма для тестового набора данных\n",
    "axes[1].hist(test_word_counts, bins=30, alpha=0.7, label=\"Количество слов\")\n",
    "axes[1].hist(test_token_counts, bins=30, alpha=0.7, label=\"Количество токенов\")\n",
    "axes[1].set_title(\"Тестовый набор данных\")\n",
    "axes[1].set_xlabel(\"Количество\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Пусть будет 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0a235fb0804221b8a323562f7a360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8a3098c3d941ada547694c05f0f1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1473\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация\n",
    "def preprocess_batch_t5(batch):\n",
    "    model_inputs = t5_ft_tokenizer(\n",
    "        batch[\"input\"], truncation=True, max_length=MAX_LENGTH, padding=\"max_length\"\n",
    "    )\n",
    "    with t5_ft_tokenizer.as_target_tokenizer():\n",
    "        labels = t5_ft_tokenizer(\n",
    "            batch[\"target\"],\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "dataset_2_tok = dataset_2.map(\n",
    "    preprocess_batch_t5,\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"target\", \"__index_level_0__\"],\n",
    ")\n",
    "\n",
    "dataset_2_tok[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3632050487.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 00:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=t5_ft_tokenizer, model=t5_ft_model, padding=True\n",
    ")\n",
    "\n",
    "output_dir = \"./models/t5-russian-spell-ft\"\n",
    "\n",
    "# Аргументы обучения\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,  # для fine-tuning больше 3-х не нужно\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    save_strategy=\"no\",  # не сохранять чекпоинты\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),  # ускорение на GPU\n",
    "    gradient_accumulation_steps=1,\n",
    "    report_to=[],  # без репортинга\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=t5_ft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_2_tok[\"train\"],\n",
    "    eval_dataset=dataset_2_tok[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=t5_ft_tokenizer,\n",
    ")\n",
    "\n",
    "# Запускаем обучение\n",
    "trainer.train()\n",
    "\n",
    "# Сохраняем дообученную модель\n",
    "trainer.save_model(output_dir)\n",
    "t5_ft_tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Очистка памяти\n",
    "model_cleanup(t5_ft_model, t5_ft_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnPx1UTMf6lQ"
   },
   "source": [
    "Примените дообученную модель. Как раз здесь для оценки качества результата выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-uVrL7hHgr-8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Загружаем дообученную модель\n",
    "ft_path = output_dir\n",
    "inf_tokenizer = AutoTokenizer.from_pretrained(ft_path)\n",
    "inf_model = AutoModelForSeq2SeqLM.from_pretrained(ft_path).to(device)\n",
    "inf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 примеров: Whisper -> Fine-tuned T5\n",
      "============================================================\n",
      "Файл         : 8eec6bf4-818c-4852-8063-0bcc5d2e7175.txt\n",
      "Whisper      : Угладиатор\n",
      "T5 original  : Угрожитель.\n",
      "T5 fine-tuned: Угладиатор\n",
      "------------------------------------------------------------\n",
      "Файл         : 703e7d9c-b170-4762-b5d3-c4fa8e4be0e8.txt\n",
      "Whisper      : Николай Каперник\n",
      "T5 original  : Николай Каперник\n",
      "T5 fine-tuned: Николай Каперник\n",
      "------------------------------------------------------------\n",
      "Файл         : d5bd3785-733a-4a95-b3ba-4d80ece002ee.txt\n",
      "Whisper      : Однажды в Америке\n",
      "T5 original  : В Америке.\n",
      "T5 fine-tuned: Однажды в Америке\n",
      "------------------------------------------------------------\n",
      "Файл         : 163e0da8-750f-45d4-b5d5-8982fb060c12.txt\n",
      "Whisper      : Новый кинотеатр пародизо\n",
      "T5 original  : Новый кинотеатр пародии\n",
      "T5 fine-tuned: Новый кинотеатр пародии\n",
      "------------------------------------------------------------\n",
      "Файл         : ce29f3d2-8c47-4466-a2b5-7bcb73b0eb02.txt\n",
      "Whisper      : двое\n",
      "T5 original  : Двое детей.\n",
      "T5 fine-tuned: двое\n",
      "------------------------------------------------------------\n",
      "Файл         : 5fdd45c8-59c9-4c90-bf81-e426cf597f40.txt\n",
      "Whisper      : Жулианна Мур\n",
      "T5 original  : Жулианна Мур\n",
      "T5 fine-tuned: Жулианна Мур\n",
      "------------------------------------------------------------\n",
      "Файл         : 2a6d78d6-5b79-4ec1-bd9b-29b59c1960c1.txt\n",
      "Whisper      : Дай не трехо.\n",
      "T5 original  : Дай не трех.\n",
      "T5 fine-tuned: Дай не трех\n",
      "------------------------------------------------------------\n",
      "Файл         : fcceeeb4-5bb7-460a-853c-99c3c7bd5aef.txt\n",
      "Whisper      : Андрей Сахаров\n",
      "T5 original  : Андрей Сахаров\n",
      "T5 fine-tuned: Андрей Сахаров\n",
      "------------------------------------------------------------\n",
      "Файл         : 53085fa6-1df6-4d46-ae00-4ce2b89ac0ca.txt\n",
      "Whisper      : Интерстеллер\n",
      "T5 original  : Интерстеллер\n",
      "T5 fine-tuned: Интерстеллер\n",
      "------------------------------------------------------------\n",
      "Файл         : 871a6ddc-77b3-45e0-ab4d-2bdcddb78515.txt\n",
      "Whisper      : Звездной войны. Эпизод 5. Империя наносит ответный удар.\n",
      "T5 original  : Эпизод 5. Империя наносит ответный удар.\n",
      "T5 fine-tuned: Эпизод 5. Империя наносит ответный удар\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Применение модели к 10 примерам\n",
    "# Возьмём те же самые 10 транскриптов Whisper - sample_txt_files\n",
    "\n",
    "print(\"10 примеров: Whisper -> Fine-tuned T5\")\n",
    "print(\"=\" * 60)\n",
    "for p in sample_txt_files:\n",
    "    src = p.read_text(encoding=\"utf-8\").strip()\n",
    "    inputs = inf_tokenizer(src, return_tensors=\"pt\").to(inf_model.device)\n",
    "    with torch.no_grad():\n",
    "        gen_ids = inf_model.generate(**inputs, max_length=64)\n",
    "    pred = inf_tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # путь к файлу с исправлениями предобученной T5 (из Шага 2)\n",
    "    t5_file = p.parent.parent / \"t5\" / p.name\n",
    "    t5_file_text = (\n",
    "        t5_file.read_text(encoding=\"utf-8\").strip()\n",
    "        if t5_file.exists()\n",
    "        else \"(нет файла)\"\n",
    "    )\n",
    "\n",
    "    print(f\"Файл         : {p.name}\")\n",
    "    print(f\"Whisper      : {src}\")\n",
    "    print(\n",
    "        f\"T5 original  : {t5_file_text}\"\n",
    "    )  # содержимое t5/*.txt для визуального сравнения\n",
    "    print(f\"T5 fine-tuned: {pred}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение дообученной модели ко всем файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 файлов для исправления\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c8c354c660471d93817c24adb2056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы исправлены!\n"
     ]
    }
   ],
   "source": [
    "corrected_files = correct_text_files(\n",
    "    model=inf_model,\n",
    "    tokenizer=inf_tokenizer,\n",
    "    input_files=created_files,  # список путей к txt файлам для исправления\n",
    "    output_path=\"whisper/t5-ft\",  # папка для сохранения исправленных файлов\n",
    "    suffix=\"\",  # суффикс для имен файлов\n",
    ")\n",
    "\n",
    "model_cleanup(inf_model, inf_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tnKOwwAjNsF"
   },
   "source": [
    "## Шаг 5 (1 балл)\n",
    "\n",
    "Время считать метрики и возвращаться к дообучению модели по необходимости. В этом шаге мы оцениваем только выполнение задания, а не значения метрик.\n",
    "\n",
    "a) [Здесь](https://disk.yandex.ru/d/SPJU3lCt_cMDcw) лежат правильные ответы почти на все аудио - считайте метрики только для аудио, для которых мы дали вам ответы. Посчитайте [WER](https://docs.pytorch.org/torcheval/main/generated/torcheval.metrics.WordErrorRate.html) для модели whisper-small.\n",
    "\n",
    "б) Посчитайте WER для whisper-small + исправление опечаток предобученной моделью (модель выберите самостоятельно!)\n",
    "\n",
    "в) Посчитайте WER для whisper-small + дообученная Вами модель (данные для дообучения и модель выберите самостоятельно!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8Ik_jNo2jNzC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/197f271b-b23f-4ee0-b240-e956a172d7af',\n",
       " 'text': 'жизнь других'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "import json\n",
    "\n",
    "# Файл `result_array.json` как-то уже скачали в текущую директорию\n",
    "with open(\"result_array.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    result_array = json.load(f)\n",
    "result_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это не списывание - это из ДЗ по NLP-1\n",
    "# Define a function to preprocess a single line\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess_line(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses a single line of text by:\n",
    "    1. Removing all punctuation except apostrophes.\n",
    "    2. Converting the text to lowercase.\n",
    "\n",
    "    Args:\n",
    "        line (str): The input line of text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed line of text.\n",
    "    \"\"\"\n",
    "    chars_to_ignore_regex = r\"[\\,\\?\\.\\!\\-\\;\\:\\\"]\"\n",
    "\n",
    "    line = re.sub(chars_to_ignore_regex, \" \", line)\n",
    "    line = \" \".join(line.split())  # удаляем лишние пробелы\n",
    "\n",
    "    return line.strip().lower()\n",
    "\n",
    "\n",
    "def calculate_wer(\n",
    "    result_array: list[dict], predictions_path: Path, preprocess_text=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Вычисляет Word Error Rate (WER) для сравнения эталонных текстов из result_array\n",
    "    с предсказаниями из файлов в указанной директории.\n",
    "\n",
    "    Args:\n",
    "        result_array (list): Список словарей с ключами 'url' и 'text'\n",
    "        predictions_path (str): Путь к директории с файлами предсказаний\n",
    "        preprocess_text (bool): Нужно ли предобрабатывать тексты (по умолчанию True)\n",
    "\n",
    "    Returns:\n",
    "        float: Значение WER\n",
    "    \"\"\"\n",
    "    from torcheval.metrics import WordErrorRate\n",
    "    from pathlib import Path\n",
    "\n",
    "    wer_metric = WordErrorRate()\n",
    "\n",
    "    for item in result_array:\n",
    "        file_name = item[\"url\"].split(\"/\")[-1] + \".txt\"\n",
    "\n",
    "        # Получаем эталонный текст\n",
    "        if preprocess_text:\n",
    "            reference = preprocess_line(item[\"text\"])\n",
    "        else:\n",
    "            reference = item[\"text\"]\n",
    "\n",
    "        try:\n",
    "            # Читаем предсказание из файла\n",
    "            pred_file = Path(predictions_path) / file_name\n",
    "            prediction = pred_file.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "            if preprocess_text:\n",
    "                prediction = preprocess_line(prediction)\n",
    "\n",
    "            # Обновляем метрику\n",
    "            wer_metric.update(reference, prediction)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Файл {file_name} не найден в {predictions_path}\")\n",
    "            continue\n",
    "\n",
    "    return wer_metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитаем WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER Whisper: 0.3750\n",
      "WER Whisper+T5 original: 0.8220\n",
      "WER Whisper+T5 fine-tuned: 0.3896\n"
     ]
    }
   ],
   "source": [
    "# Для Whisper\n",
    "wer_whisper = calculate_wer(result_array, \"whisper/txt\", preprocess_text=True)\n",
    "print(f\"WER Whisper: {wer_whisper:.4f}\")\n",
    "\n",
    "# Для T5 original\n",
    "wer_t5 = calculate_wer(result_array, \"whisper/t5\", preprocess_text=True)\n",
    "print(f\"WER Whisper+T5 original: {wer_t5:.4f}\")\n",
    "\n",
    "# Для T5 fine-tuned\n",
    "wer_t5_ft = calculate_wer(result_array, \"whisper/t5-ft\", preprocess_text=True)\n",
    "print(f\"WER Whisper+T5 fine-tuned: {wer_t5_ft:.4f}\")\n",
    "\n",
    "# Сохраним все в словарик для выводов в конце\n",
    "WER_data = {}\n",
    "WER_data[\"openai/whisper-small\"] = wer_whisper\n",
    "WER_data[\"Whisper+T5\"] = wer_t5\n",
    "WER_data[\"Whisper+T5_fine-tune\"] = wer_t5_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "\n",
    "Результат неожиданный. На глаз, по сэмплам, было видно что Whisper более-менее неплохо распознал. \n",
    "Удивительно, что T5 так провалился! Но дообучение сделало его немного лучше.\n",
    "\n",
    "Будем считать это учебным примером для изучения подхода как такового, а не для борьбы за качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sUQNgLjj4lQ"
   },
   "source": [
    "## Шаг 6 (3 балла)\n",
    "\n",
    "В этом шаге предлагаем вам провести максимум рисерча и экспериментов для наиболее качественного решения задачи (в бесплатном google colab, без привлечения дополнительных мощностей)\n",
    "\n",
    "* Поищите предобученные модели, применение которых для задачи speech-to-text дает меньше опечаток (меньше WER)\n",
    "\n",
    "* Протестируйте несколько spell-correction моделей и сделайте выводы какая из них лучше (с точки зрения WER)\n",
    "\n",
    "* Возьмите лучшую из найденных моделей и попытайтесь улучшить ее через шаг 4, как делали ранее. Попробуйте немного изменить обучение в шаге 4, чтобы добиться еще более хороших результатов (изменить данные/гиперпараметры и т.п.) и проведите соответствующий эксперимент. Объясните почему ваша модификация шага 4 теоретически может улучшить результаты и сделайте выводы о том, получилось ли улучшить качество (если нет, то предположите почему)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Испытание STT моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper-large-v3-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "W1oi72ysj9ao"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af339feb7c4841cb9524aa97687fc7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 аудиофайлов для обработки\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0f7a47e3264e1d9cbbf1dbd5b20105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы обработаны!\n",
      "WER Whisper-large: 0.2035\n"
     ]
    }
   ],
   "source": [
    "# ваши эксперименты здесь\n",
    "\n",
    "# Возьмем другую модель для распознавания\n",
    "model_name_6_1 = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "processor_6_1 = WhisperProcessor.from_pretrained(model_name_6_1, cache_dir=\"./models\")\n",
    "model_6_1 = WhisperForConditionalGeneration.from_pretrained(model_name_6_1, cache_dir=\"./models\").to(device)\n",
    "model_6_1.eval()\n",
    "\n",
    "# Используем функцию для обработки файлов\n",
    "output_path=\"whisper-large/txt\"\n",
    "created_files = process_audio_files(\n",
    "    model=model_6_1,\n",
    "    processor=processor_6_1,\n",
    "    wav_files_path=DATA_ROOT,  # путь к папке с wav файлами\n",
    "    output_path=output_path,  # папка для сохранения результатов\n",
    "    language=\"ru\",  # язык транскрипции\n",
    "    task=\"transcribe\",  # задача\n",
    ")\n",
    "\n",
    "wer_whisper_large = calculate_wer(\n",
    "    result_array, output_path, preprocess_text=True\n",
    ")\n",
    "print(f\"WER Whisper-large: {wer_whisper_large:.4f}\")\n",
    "WER_data[\"Whisper-large-v3-turbo\"] = wer_whisper_large  # для вывода в конце\n",
    "model_cleanup(model_6_1, processor_6_1)  # очистка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper-large-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d247d9bfebe401bb458e80ac072924d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 аудиофайлов для обработки\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f93d395bd58467a9521bd942d451f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы обработаны!\n",
      "WER Whisper-large-v3: 0.1485\n"
     ]
    }
   ],
   "source": [
    "# Возьмем другую модель для распознавания\n",
    "model_name_6_2 = \"openai/whisper-large-v3\"\n",
    "processor_6_2 = WhisperProcessor.from_pretrained(model_name_6_2, cache_dir=\"./models\")\n",
    "model_6_2 = WhisperForConditionalGeneration.from_pretrained(model_name_6_2, cache_dir=\"./models\").to(device)\n",
    "model_6_2.eval()\n",
    "\n",
    "# Используем функцию для обработки файлов\n",
    "output_path=\"whisper-large-v3/txt\"\n",
    "created_files = process_audio_files(\n",
    "    model=model_6_2,\n",
    "    processor=processor_6_2,\n",
    "    wav_files_path=DATA_ROOT,  # путь к папке с wav файлами\n",
    "    output_path=output_path,  # папка для сохранения результатов\n",
    "    language=\"ru\",  # язык транскрипции\n",
    "    task=\"transcribe\",  # задача\n",
    ")\n",
    "\n",
    "wer_whisper_large_v3 = calculate_wer(\n",
    "    result_array, output_path, preprocess_text=True\n",
    ")\n",
    "print(f\"WER Whisper-large-v3: {wer_whisper_large_v3:.4f}\")\n",
    "WER_data[\"Whisper-large-v3\"] = wer_whisper_large_v3  # для вывода в конце\n",
    "model_cleanup(model_6_2, processor_6_2)  # очистка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wav2vec2-large-ru-golos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad40ff1c01e2438aac8d0dcfdc52ac1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# load model and tokenizer\n",
    "model_name_6_3 = \"bond005/wav2vec2-large-ru-golos\"\n",
    "processor_6_3 = Wav2Vec2Processor.from_pretrained(model_name_6_3, cache_dir=\"./models\")\n",
    "model_6_3 = Wav2Vec2ForCTC.from_pretrained(model_name_6_3, cache_dir=\"./models\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут пришлось модифицировать функцию обработки файлов, т.к. вызов `wav2vec` немного отличается от `whisper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_files_wav2vec(\n",
    "    model, processor, wav_files_path: str | Path, output_path: str | Path\n",
    ") -> list[Path]:\n",
    "    \"\"\"\n",
    "    Функция для обработки аудиофайлов моделью типа Wav2Vec2\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для транскрипции\n",
    "    - processor: процессор для обработки аудио\n",
    "    - wav_files_path: путь к папке с wav файлами (str или Path)\n",
    "    - output_path: путь к папке для сохранения результатов (str или Path)\n",
    "\n",
    "    Возвращает:\n",
    "    - список путей к созданным txt файлам ([Path])\n",
    "    \"\"\"\n",
    "\n",
    "    # Преобразуем пути в Path объекты\n",
    "    wav_path = Path(wav_files_path)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    # Создаем папку для результатов если её нет\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Находим все wav файлы\n",
    "    wav_paths = list(wav_path.rglob(\"*.wav\"))\n",
    "    print(f\"Найдено {len(wav_paths)} аудиофайлов для обработки\")\n",
    "\n",
    "    created_files = []\n",
    "\n",
    "    for i, p in tqdm(enumerate(wav_paths), total=len(wav_paths)):\n",
    "        try:\n",
    "            # Загружаем аудио\n",
    "            wav, sr = load_audio(str(p))\n",
    "\n",
    "            # Обрабатываем аудио через процессор\n",
    "            inputs = processor(\n",
    "                wav, sampling_rate=sr, return_tensors=\"pt\", padding=\"longest\"\n",
    "            )\n",
    "            input_features = inputs.input_values.to(model.device)\n",
    "            attention_mask = inputs.attention_mask.to(model.device)\n",
    "\n",
    "            # Генерация выходных токенов\n",
    "            logits = model(input_features, attention_mask=attention_mask).logits\n",
    "\n",
    "            # Декодирование в текст\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "            transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "            # Сохраняем транскрипцию в файл\n",
    "            txt_filename = (\n",
    "                p.stem + \".txt\"\n",
    "            )  # p.stem дает имя файла без пути и без расширения\n",
    "            txt_path = output_path / txt_filename\n",
    "            txt_path.write_text(transcription, encoding=\"utf-8\")\n",
    "\n",
    "            created_files.append(txt_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {p.name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Все файлы обработаны!\")\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 аудиофайлов для обработки\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ff6b4445cb4e86afda7f969e5e80c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы обработаны!\n",
      "WER Wav2Vec2-large-ru-golos: 0.2478\n"
     ]
    }
   ],
   "source": [
    "output_path=\"wav2vec2-large-ru-golos/txt\"\n",
    "\n",
    "# Используем функцию для обработки файлов\n",
    "created_files_6_3 = process_audio_files_wav2vec(\n",
    "    model=model_6_3,\n",
    "    processor=processor_6_3,\n",
    "    wav_files_path=DATA_ROOT,  # путь к папке с wav файлами\n",
    "    output_path=output_path,  # папка для сохранения результатов\n",
    ")\n",
    "\n",
    "wer_wav2vec2_large_ru_golos = calculate_wer(\n",
    "    result_array, output_path, preprocess_text=True\n",
    ")\n",
    "print(f\"WER Wav2Vec2-large-ru-golos: {wer_wav2vec2_large_ru_golos:.4f}\")\n",
    "WER_data[\"Wav2Vec2-large-ru-golos\"] = wer_wav2vec2_large_ru_golos  # для вывода в конце\n",
    "model_cleanup(model_6_3, processor_6_3)  # очистка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты и выводы\n",
    "\n",
    "Ниже представлена сводная таблица результатов Word Error Rate (WER) для различных моделей и подходов:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТОВ\n",
      "========================================\n",
      "                  Model      WER\n",
      "       Whisper-large-v3 0.148472\n",
      " Whisper-large-v3-turbo 0.203463\n",
      "Wav2Vec2-large-ru-golos 0.247788\n",
      "   openai/whisper-small 0.375000\n",
      "   Whisper+T5_fine-tune 0.389610\n",
      "             Whisper+T5 0.821954\n"
     ]
    }
   ],
   "source": [
    "def print_wer_table():\n",
    "    import pandas as pd\n",
    "\n",
    "    # Воспользуемся словариком WER_data для создания таблицы\n",
    "    df_wer = pd.DataFrame(list(WER_data.items()), columns=[\"Model\", \"WER\"])\n",
    "    df_wer[\"WER\"] = df_wer[\"WER\"].astype(\"float\")\n",
    "\n",
    "    # Сортируем по WER для печатного вида\n",
    "    df_wer = df_wer.sort_values(\"WER\")\n",
    "\n",
    "    print(\"РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТОВ\")\n",
    "    print(\"=\" * 40)\n",
    "    print(df_wer.to_string(index=False))\n",
    "\n",
    "print_wer_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ результатов**  \n",
    "В качестве бейзлайна взята модель `openai/whisper-small`, которая показала `WER = 0.375`.\n",
    "\n",
    "1. **Лучшая модель**:  \n",
    "   `Whisper-large-v3` показала наилучший результат `WER = 0.1485`\n",
    "2. **Эффективность больших моделей**:  \n",
    "    `Whisper-large-v3-turbo` также показала хороший результат `WER = 0.2035`\n",
    "3. **Специализированные модели**:  \n",
    "   `Wav2Vec2-large-ru-golos`, обученная на русском языке, показала `WER = 0.2478`, но работала **быстрее остальных** \n",
    "4. **Проблема с post-processing**:  \n",
    "   Применение T5 для исправления опечаток значительно ухудшило результаты:\n",
    "   - `T5` без дообучения: `WER = 0.822`, что в 2+ раза хуже бейзлайна\n",
    "   - `T5 fine-tuned`: `WER = 0.3803`, все еще хуже бейзлайна\n",
    "\n",
    "**Возможные причины неудач с T5:**\n",
    "- Модель T5 была обучена на других данных и не подходит для исправления ошибок Whisper\n",
    "- Недостаточное качество собранного датасета для дообучения (он, конечно странный получился)\n",
    "- Неправильные гиперпараметры обучения\n",
    "- Несоответствие между типами ошибок в датасете и реальными ошибками Whisper\n",
    "\n",
    "**Вывод:**\n",
    "- Для общих задач удобнее использовать более мощные STT модели (`Whisper-large-v3` или `Whisper-large-v3-turbo`) вместо post-processing.\n",
    "- Для специфических доменов (например, медицина) возможен post-processing или специализированные модели.\n",
    "- Для дообучения требуется собирать более качественный и репрезентативный датасет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Испытание spell-checker моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничимся испытанием следующих моделей:  \n",
    "- `ai-forever/FRED-T5-large-spell` - https://huggingface.co/ai-forever/FRED-T5-large-spell\n",
    "- `ai-forever/sage-v1.1.0` - https://huggingface.co/ai-forever/sage-v1.1.0\n",
    "\n",
    "Так как именно они являются наиболее популярными для задачи коррекции ошибок на Русском языке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRED-T5-large-spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_files_FRED(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    input_files: list[Path],\n",
    "    output_path: Path,\n",
    "    input_prefix=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для исправления текста в файлах с помощью модели FRED\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для исправления текста\n",
    "    - tokenizer: токенизатор для модели\n",
    "    - input_files: список путей к txt файлам для исправления\n",
    "    - output_path: путь к папке для сохранения исправленных файлов\n",
    "    - input_prefix: префикс для входных текстов (по умолчанию None)\n",
    "\n",
    "    Возвращает:\n",
    "    - список путей к созданным исправленным файлам\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = Path(output_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Найдено {len(input_files)} файлов для исправления\")\n",
    "\n",
    "    corrected_files = []\n",
    "\n",
    "    for txt_file in tqdm(input_files, total=len(input_files)):\n",
    "        try:\n",
    "            transcription = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "            if input_prefix:\n",
    "                transcription = input_prefix + transcription\n",
    "\n",
    "            # print(\"transcription:\", transcription)\n",
    "            # Токенизируем и генерируем исправленный текст\n",
    "            encodings = tokenizer(transcription, return_tensors=\"pt\").to(model.device)\n",
    "            # print(\"encodings:\", encodings)\n",
    "\n",
    "            generated_tokens = model.generate(\n",
    "                **encodings, eos_token_id=tokenizer.eos_token_id, early_stopping=True\n",
    "            )\n",
    "            corrected_text = tokenizer.decode(\n",
    "                generated_tokens[0], skip_special_tokens=True\n",
    "            )\n",
    "            # print(\"corrected_text:\", corrected_text)\n",
    "\n",
    "            # Сохраняем исправленный текст в файл\n",
    "            new_filename = Path(txt_file).stem + \".txt\"\n",
    "            new_path = output_path / new_filename\n",
    "            new_path.write_text(corrected_text, encoding=\"utf-8\")\n",
    "\n",
    "            corrected_files.append(new_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при исправлении файла {txt_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Все файлы исправлены!\")\n",
    "    encodings.to(\"cpu\")\n",
    "    generated_tokens.to(\"cpu\")\n",
    "    del encodings, generated_tokens\n",
    "    return corrected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['прийдя в МГТУ я был удивлен никого необнаружив там...прийдя в МГ']\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "path_to_model = \"ai-forever/FRED-T5-large-spell\"\n",
    "tokenizer_6_4 = AutoTokenizer.from_pretrained(path_to_model, eos_token=\"</s>\", cache_dir=\"./models\")\n",
    "model_6_4 = T5ForConditionalGeneration.from_pretrained(path_to_model, cache_dir=\"./models\").to(device)\n",
    "model_6_4.eval()\n",
    "\n",
    "# Пример использования\n",
    "prefix = \"Исправь: \"\n",
    "sentence = \"прийдя в МГТУ я был удивлен никого необноружив там...\"\n",
    "sentence = prefix + sentence\n",
    "\n",
    "encodings = tokenizer_6_4(sentence, return_tensors=\"pt\").to(device)\n",
    "generated_tokens = model_6_4.generate(\n",
    "                **encodings, eos_token_id=tokenizer_6_4.eos_token_id, early_stopping=True)\n",
    "answer = tokenizer_6_4.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(answer)\n",
    "encodings.to(\"cpu\")\n",
    "generated_tokens.to(\"cpu\")\n",
    "del encodings, generated_tokens, answer\n",
    "\n",
    "# [\"прийдя в МГТУ я был удивлен никого не обнаружив там.. «при\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 файлов для исправления\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5658410f33641e8b1e8a390fc592c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы исправлены!\n",
      "WER FRED: 0.7638\n"
     ]
    }
   ],
   "source": [
    "input_files = list(Path(\"whisper-large-v3/txt\").glob(\"*.txt\"))\n",
    "\n",
    "# Используем функцию для исправления файлов\n",
    "corrected_files = correct_text_files_FRED(\n",
    "    model=model_6_4,\n",
    "    tokenizer=tokenizer_6_4,\n",
    "    input_files=input_files,  # список путей к txt файлам для исправления\n",
    "    output_path=\"whisper-large-v3/FRED\",  # папка для сохранения исправленных файлов\n",
    "    input_prefix=\"Исправь: \",  # префикс для входных текстов\n",
    ")\n",
    "\n",
    "wer_FRED = calculate_wer(\n",
    "    result_array, \"whisper-large-v3/FRED\", preprocess_text=True\n",
    ")\n",
    "print(f\"WER FRED: {wer_FRED:.4f}\")\n",
    "WER_data[\"FRED-T5-large-spell\"] = wer_FRED  # для вывода в конце\n",
    "\n",
    "model_cleanup(model_6_4, tokenizer_6_4)  # очистка памяти\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sage-v1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Привет, как дела?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer_sage = AutoTokenizer.from_pretrained(\"ai-forever/FRED-T5-1.7B\", cache_dir=\"./models\")\n",
    "model_sage = T5ForConditionalGeneration.from_pretrained(\"ai-forever/sage-v1.1.0\", cache_dir=\"./models\")\n",
    "model_sage.to(device)\n",
    "model_sage.eval()\n",
    "\n",
    "tokenizer_config = {\n",
    "            'max_length': None,\n",
    "            'padding': 'longest',\n",
    "            'truncation': False,\n",
    "            \"return_tensors\": \"pt\",\n",
    "        }\n",
    "\n",
    "def inference(sentence):\n",
    "    text = \"<LM>\" + sentence\n",
    "    with torch.inference_mode():\n",
    "        encodings = tokenizer_sage(text, **tokenizer_config)\n",
    "        for k, v in encodings.items():\n",
    "            encodings[k] = v.to(device)\n",
    "        res = model_sage.generate(\n",
    "            **encodings,\n",
    "            use_cache=True,\n",
    "            max_length = encodings['input_ids'].size(1) * 1.5\n",
    "        )\n",
    "        res = res.cpu().tolist()\n",
    "        res = tokenizer_sage.batch_decode(res, skip_special_tokens=True)\n",
    "    return res\n",
    "\n",
    "text = 'Првет какдила'\n",
    "text = re.sub(r'\\n+', '\\n', text)\n",
    "print(inference(text))\n",
    "\n",
    "# ['Привет, как дела?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_files_SAGE(\n",
    "    input_files: list[Path],\n",
    "    output_path: Path,\n",
    "):\n",
    "    \"\"\"\n",
    "    Функция для исправления текста в файлах с помощью модели SAGE\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для исправления текста\n",
    "    - tokenizer: токенизатор для модели\n",
    "    - input_files: список путей к txt файлам для исправления\n",
    "    - output_path: путь к папке для сохранения исправленных файлов\n",
    "    - input_prefix: префикс для входных текстов (по умолчанию None)\n",
    "\n",
    "    Возвращает:\n",
    "    - список путей к созданным исправленным файлам\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = Path(output_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Найдено {len(input_files)} файлов для исправления\")\n",
    "\n",
    "    corrected_files = []\n",
    "\n",
    "    for txt_file in tqdm(input_files, total=len(input_files)):\n",
    "        try:\n",
    "            transcription = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "            corrected_text = inference(transcription)[0]\n",
    "\n",
    "            # Сохраняем исправленный текст в файл\n",
    "            new_filename = Path(txt_file).stem + \".txt\"\n",
    "            new_path = output_path / new_filename\n",
    "            new_path.write_text(corrected_text, encoding=\"utf-8\")\n",
    "\n",
    "            corrected_files.append(new_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при исправлении файла {txt_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Все файлы исправлены!\")\n",
    "    return corrected_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим спелл-корректор к самой лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 файлов для исправления\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49922076098148bb821db1646f342eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы исправлены!\n",
      "WER SAGE: 0.1485\n"
     ]
    }
   ],
   "source": [
    "input_files = list(Path(\"whisper-large-v3/txt\").glob(\"*.txt\"))\n",
    "\n",
    "# Используем функцию для исправления файлов\n",
    "corrected_files = correct_text_files_SAGE(\n",
    "    input_files=input_files,  # список путей к txt файлам для исправления\n",
    "    output_path=\"whisper-large-v3/SAGE\",  # папка для сохранения исправленных файлов\n",
    ")\n",
    "\n",
    "wer_SAGE = calculate_wer(\n",
    "    result_array, \"whisper-large-v3/SAGE\", preprocess_text=True\n",
    ")\n",
    "print(f\"WER SAGE: {wer_SAGE:.4f}\")\n",
    "WER_data[\"Whisper-large-v3/sage-v1.1.0\"] = wer_SAGE  # для вывода в конце"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применим спелл-корректор к модели похуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 100 файлов для исправления\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4698153db1049f0b2ca872b5b78bd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все файлы исправлены!\n",
      "WER SAGE: 0.3578\n"
     ]
    }
   ],
   "source": [
    "input_files = list(Path(\"whisper/txt\").glob(\"*.txt\"))\n",
    "\n",
    "# Используем функцию для исправления файлов\n",
    "corrected_files = correct_text_files_SAGE(\n",
    "    input_files=input_files,  # список путей к txt файлам для исправления\n",
    "    output_path=\"whisper/SAGE\",  # папка для сохранения исправленных файлов\n",
    ")\n",
    "\n",
    "wer_SAGE = calculate_wer(\n",
    "    result_array, \"whisper/SAGE\", preprocess_text=True\n",
    ")\n",
    "print(f\"WER SAGE: {wer_SAGE:.4f}\")\n",
    "WER_data[\"Whisper-small/sage-v1.1.0\"] = wer_SAGE  # для вывода в конце\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cleanup(model_sage, tokenizer_sage)  # очистка памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дообучение SAGE\n",
    "\n",
    "Теперь дообучим модель SAGE на собранном датасете аналогично тому, как это было сделано с T5 в Шаге 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного набора: 1473\n",
      "Размер тестового набора: 164\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет для дообучения SAGE\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "# Загружаем датасет\n",
    "full_dataset_sage = load_dataset(\"psaw77/russian-spell-correction-dataset\")\n",
    "dataset_sage = full_dataset_sage[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "print(f\"Размер тренировочного набора: {len(dataset_sage['train'])}\")\n",
    "print(f\"Размер тестового набора: {len(dataset_sage['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель SAGE загружена для дообучения\n"
     ]
    }
   ],
   "source": [
    "# Загружаем оригинальную модель SAGE для дообучения\n",
    "model_name_sage_ft = \"ai-forever/sage-v1.1.0\"\n",
    "tokenizer_sage_ft = AutoTokenizer.from_pretrained(\"ai-forever/FRED-T5-1.7B\", cache_dir=\"./models\")\n",
    "model_sage_ft = T5ForConditionalGeneration.from_pretrained(model_name_sage_ft, cache_dir=\"./models\").to(device)\n",
    "\n",
    "print(\"Модель SAGE загружена для дообучения\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0aa8dd468b4fde8840081893c80e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные подготовлены для дообучения SAGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для SAGE\n",
    "MAX_LENGTH_SAGE = 12\n",
    "\n",
    "def preprocess_batch_sage(batch):\n",
    "    \"\"\"Функция предобработки для SAGE модели\"\"\"\n",
    "    # Добавляем префикс <LM> как требует SAGE\n",
    "    inputs = [\"<LM>\" + text for text in batch[\"input\"]]\n",
    "    targets = batch[\"target\"]\n",
    "    \n",
    "    # Токенизируем входы\n",
    "    model_inputs = tokenizer_sage_ft(\n",
    "        inputs, \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH_SAGE, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Токенизируем таргеты\n",
    "    with tokenizer_sage_ft.as_target_tokenizer():\n",
    "        labels = tokenizer_sage_ft(\n",
    "            targets,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH_SAGE,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Применяем предобработку\n",
    "dataset_sage_tok = dataset_sage.map(\n",
    "    preprocess_batch_sage,\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"target\", \"__index_level_0__\"],\n",
    ")\n",
    "\n",
    "print(\"Данные подготовлены для дообучения SAGE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настройки дообучения SAGE готовы\n"
     ]
    }
   ],
   "source": [
    "# Настройка дообучения SAGE\n",
    "data_collator_sage = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer_sage_ft, \n",
    "    model=model_sage_ft, \n",
    "    padding=True\n",
    ")\n",
    "\n",
    "output_dir_sage = \"./models/sage-russian-spell-ft\"\n",
    "\n",
    "# Аргументы обучения для SAGE\n",
    "training_args_sage = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir_sage,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,  # для fine-tuning больше 3-х не нужно\n",
    "    per_device_train_batch_size=8,  # уменьшили batch size для SAGE\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    save_strategy=\"no\",  # не сохранять чекпоинты\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),  # ускорение на GPU\n",
    "    gradient_accumulation_steps=1,\n",
    "    report_to=[],  # без репортинга\n",
    ")\n",
    "\n",
    "print(\"Настройки дообучения SAGE готовы\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> К соажелению, мне не удалось вместить этот процесс даже на NVIDIA L4 (24GB), \n",
    "> поэтому далее код закоментирован, чтобы при проверке можно было выполнить весь ноутбук без ошибок.\n",
    "> Выводы буду делать теоретические исходя из того, что было в шаге 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создаем trainer для SAGE\n",
    "# trainer_sage = Seq2SeqTrainer(\n",
    "#     model=model_sage_ft,\n",
    "#     args=training_args_sage,\n",
    "#     train_dataset=dataset_sage_tok[\"train\"],\n",
    "#     eval_dataset=dataset_sage_tok[\"test\"],\n",
    "#     data_collator=data_collator_sage,\n",
    "#     tokenizer=tokenizer_sage_ft,\n",
    "# )\n",
    "\n",
    "# print(\"Начинаем дообучение SAGE...\")\n",
    "# trainer_sage.train()\n",
    "\n",
    "# # Сохраняем дообученную модель SAGE\n",
    "# trainer_sage.save_model(output_dir_sage)\n",
    "# tokenizer_sage_ft.save_pretrained(output_dir_sage)\n",
    "\n",
    "# print(\"Дообучение SAGE завершено, модель сохранена\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТОВ\n",
      "========================================\n",
      "                       Model      WER\n",
      "Whisper-large-v3/sage-v1.1.0 0.148472\n",
      "            Whisper-large-v3 0.148472\n",
      "      Whisper-large-v3-turbo 0.203463\n",
      "     Wav2Vec2-large-ru-golos 0.247788\n",
      "   Whisper-small/sage-v1.1.0 0.357759\n",
      "        openai/whisper-small 0.375000\n",
      "        Whisper+T5_fine-tune 0.389610\n",
      "         FRED-T5-large-spell 0.763780\n",
      "                  Whisper+T5 0.821954\n"
     ]
    }
   ],
   "source": [
    "print_wer_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальные выводы\n",
    "\n",
    "### Основные результаты эксперимента\n",
    "\n",
    "В рамках данного исследования была проведена комплексная оценка различных подходов к решению задачи speech-to-text с последующим исправлением опечаток. Основные результаты представлены в таблице выше.\n",
    "\n",
    "### Ключевые выводы:\n",
    "\n",
    "#### 1. **Эффективность различных STT моделей**\n",
    "- **Лучший результат**: `Whisper-large-v3` показал наименьший WER = 0.1485\n",
    "- **Whisper-large-v3-turbo**: WER = 0.2035 (хороший баланс скорости и качества)\n",
    "- **Wav2Vec2-large-ru-golos**: WER = 0.2478 (специализированная русская модель)\n",
    "- **Whisper-small**: WER = 0.3750 (базовая модель)\n",
    "\n",
    "**Вывод**: Использование более мощных STT моделей значительно эффективнее post-processing подходов.\n",
    "\n",
    "#### 2. **Проблемы с post-processing**\n",
    "- **T5 без дообучения**: WER = 0.822 (катастрофическое ухудшение)\n",
    "- **T5 fine-tuned**: WER = 0.385 (практичеки без изменения)\n",
    "- **FRED-T5-large-spell**: WER = 0.764 (также ухудшение)\n",
    "\n",
    "**Причины неудач**:\n",
    "- Несоответствие типов ошибок в обучающих данных и реальных ошибках Whisper\n",
    "- Недостаточное качество собранного датасета\n",
    "- (возможно?) Неправильные гиперпараметры обучения\n",
    "\n",
    "#### 3. **Успешные spell-correction модели**\n",
    "- **SAGE v1.1.0**: показала отличные результаты при применении к качественным STT моделям\n",
    "- При применении к `Whisper-large-v3`: WER остался на уровне 0.1485\n",
    "- При применении к `Whisper-small`: WER улучшился с 0.375 до 0.358\n",
    "\n",
    "#### 4. **Практические выводы**\n",
    "\n",
    "**Для production систем**:\n",
    "1. **Использовать более мощные STT модели** (`Whisper-large-v3`) вместо post-processing\n",
    "2. **Для специфических доменов** (медицина, юриспруденция) рассматривать специализированные модели\n",
    "3. **SAGE v1.1.0** показала себя как надежный spell-corrector для русского языка\n",
    "\n",
    "**Для исследовательских задач**:\n",
    "1. **Сбор качественных данных** - ключевой фактор успеха дообучения\n",
    "2. **Анализ типов ошибок** - важно понимать, какие ошибки делает STT модель\n",
    "3. **Гиперпараметры** - требуют тщательной настройки для каждой конкретной задачи\n",
    "\n",
    "#### 5. **Технические ограничения**\n",
    "- **Вычислительные ресурсы**: Дообучение больших моделей (SAGE) требует значительных ресурсов\n",
    "\n",
    "### Заключение\n",
    "\n",
    "Эксперимент показал, что **инвестиции в более качественные STT модели** (Whisper-large-v3) дают значительно лучший результат, чем попытки исправить ошибки post-processing методами. \n",
    "\n",
    "Однако **SAGE v1.1.0** продемонстрировала потенциал для улучшения результатов менее качественных STT моделей, что может быть полезно в условиях ограниченных вычислительных ресурсов.\n",
    "\n",
    "**Главный урок**: В задачах speech-to-text качество исходной STT модели критически важно, и post-processing должен быть тщательно спроектирован под конкретные типы ошибок целевой STT системы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNA0WBwajj0aat4A693n8Zo",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
