{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7361e7d5-1ee8-4dd6-9495-54328bd3f655",
   "metadata": {},
   "source": [
    "## Homework 2: Glow\n",
    "\n",
    "Напомним, что нормализующие потоки — это класс генеративных моделей, которые строят сложную, но при этом обратимую функцию $\\boldsymbol{f}_{\\boldsymbol{\\theta}}$, отображающую некоторое простое распределение в сложное распределения наших данных. Обучая эту функцию, мы сможем генерировать новые данные и оценивать их плотность $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$.\n",
    "\n",
    "Это становится возможным благодаря теореме о замене переменных, которая лежит в основе нормализующих потоков. Она позволяет связать плотность $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$ с плотностью базового распределения $p(\\mathbf{z}$) через обратимую функцию $\\boldsymbol{f}_{\\boldsymbol{\\theta}}$\n",
    "и её якобиан:\n",
    "\n",
    "$$p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = p(\\boldsymbol{f}_{\\boldsymbol{\\theta}}(\\mathbf{x})) \\bigg| \\det\\left(\\frac{\\partial\\boldsymbol{f_{\\boldsymbol{\\theta}}}​}{\\partial \\mathbf{x}} \\right) \\bigg|$$\n",
    "\n",
    "Обычно функция $\\boldsymbol{f}_{\\boldsymbol{\\theta}}$ — это не простое преобразование, а сложная композиция нескольких обратимых функций:\n",
    "\n",
    "$$\\boldsymbol{f}_{\\boldsymbol{\\theta}} = \\boldsymbol{f}_{K, \\boldsymbol{\\theta}}\\circ \\dots\\circ \\boldsymbol{f}_{1,\\boldsymbol{\\theta}}$$\n",
    "​\n",
    "Поскольку детерминант якобиана всей композиции равен произведению детерминантов якобианов каждого преобразования, мы можем переписать формулу в следующем виде:\n",
    "\n",
    "$$p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = p(\\mathbf{z}_K) \\left| \\prod_{k=1}^K \\det\\left(\\frac{\\partial \\boldsymbol{f}_{k,\\boldsymbol{\\theta}}}{\\partial \\mathbf{z}_{k-1}} \\right) \\right|$$\n",
    "\n",
    "<center><img src=\"images/flow.png\" width=700></center>\n",
    "\n",
    "На семинаре мы познакомились с архитектурой **RealNVP** и увидели две главные особенности модели — **Affine Coupling Layers** и **Multi-Scale архитектуру**.\n",
    "\n",
    "Однако, как и в любой работе, в **RealNVP** оставались моменты, которые можно было улучшить. Именно этим и занялись исследователи из `OpenAI` и предложили модель [Glow](https://arxiv.org/pdf/1807.03039). Она берет лучшее от RealNVP и улучшает слабые места:\n",
    "\n",
    "- Вместо фиксированной перестановки использует `обратимую 1x1 свертку`, которая позволяет модели самой находить оптимальный способ перемешивания каналов.\n",
    "\n",
    "- Вместо стандартного `BatchNorm`, который плохо работает с маленькими батчами, использует `ActNorm`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48014561",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "Вам предстоит реализовать модель `Glow` и обучить модель на датасете `CelebA` для решения задачи генерации лиц.\n",
    "\n",
    "За выполнение домашнего задания можно получить до **10 баллов**. Для части заданий мы написали для вас скелет. Заполните в них пропуски, выделенные с помощью `...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import List, Optional, Tuple\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c1762",
   "metadata": {},
   "source": [
    "### Задание 1: Dataset (0.5 балла)\n",
    "\n",
    "Для обучения нашей модели мы будем использовать датасет `CelebA`, который содержит более $200$ тыс. изображений лиц знаменитостей. Поскольку стандартные средства torchvision для его загрузки часто нестабильны, мы скачаем архив с изображениями напрямую и напишем датасет самостоятельно.\n",
    "\n",
    "**Ваша задача**:\n",
    "\n",
    "- Скачать и распаковать архив с датасетом\n",
    "\n",
    "- Создать преобразования для всех изображений: \n",
    "    - обрезать до квадрата по центру размером $148\\times148$ (`CenterCrop`), \n",
    "    - измененить размера до $64\\times64$ (`Resize`) \n",
    "    - преобразовать в тензор (`ToTensor`).\n",
    "\n",
    "- Реализовать и создать класс CelebADataset.\n",
    "\n",
    "- Разделить созданный датасет на обучающую и валидационную выборки в соотношении $90\\% / 10\\%$\n",
    "\n",
    "- Создать DataLoader'ы для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad868a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url, save_path, extract_path, chunk_size=128):\n",
    "    if os.path.exists(extract_path):\n",
    "        print(f\"Directory '{extract_path}' already exists. Skipping download.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Downloading archive from {url}...\")\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=chunk_size)):\n",
    "            fd.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "    \n",
    "    print(f\"Unzipping archive '{save_path}'...\")\n",
    "    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(extract_path))\n",
    "    print(\"Unzipping complete.\")\n",
    "    os.remove(save_path)\n",
    "    print(f\"Archive '{save_path}' deleted.\")\n",
    "    \n",
    "DATASET_URL = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\" \n",
    "ZIP_PATH = \"celeba.zip\"\n",
    "DATA_ROOT = \"data/celeba\"\n",
    "IMAGE_DIR = os.path.join(DATA_ROOT, \"images\")\n",
    "\n",
    "download_and_unzip(DATASET_URL, ZIP_PATH, IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = sorted(os.listdir(root_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        ...\n",
    "    def __getitem__(self, idx):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)   # for train_test split\n",
    "\n",
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ \n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e8571",
   "metadata": {},
   "source": [
    "Давайте взглянем на наши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa69cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(train_dataset))[:40]\n",
    "\n",
    "fig, axes = plt.subplots(5, 8, figsize=(16, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image = train_dataset[indices[i]]  \n",
    "\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c773b",
   "metadata": {},
   "source": [
    "### Задание 2: ActNorm (1 балл)\n",
    "\n",
    "Одним из важных нововведений модели Glow является слой `ActNorm`. Как и `BatchNorm`, он выполняет аффинное преобразование $y = s\\cdot x + b$ для каждого канала, чтобы стабилизировать и ускорить обучение. Однако параметры масштаба (`scale`) и сдвига (`bias`) в `ActNorm` не зависят от текущего батча, а являются обучаемыми параметрами модели.\n",
    "\n",
    "При этом есть небольшая особенность в их инициализации, которая **зависит от данных**:\n",
    "\n",
    "- При первом проходе данных через модель (на самом первом батче), параметры `scale` и `bias` вычисляются таким образом, чтобы выходные активации для каждого канала имели нулевое среднее и единичную дисперсию.\n",
    "\n",
    "- После такой инициализации, они становятся обычными параметрами и обновляются с помощью градиентного спуска, как и все остальные веса сети.\n",
    "\n",
    "Такой подход делает `ActNorm` независимым от размера батча, что важно для обучения на больших изображениях, где размер батча часто приходится делать очень маленьким.\n",
    "\n",
    "Как и любой слой в нормализующем потоке, `ActNorm` должен быть обратимым и иметь легко вычисляемый детерминант якобиана. Для преобразования $\\mathbf{z}=\\mathbf{s}\\odot\\mathbf{x}+\\mathbf{b}$, логарифм детерминанта имеет вид:\n",
    "\n",
    "$$\\log|\\det(\\mathbf{J}^{Actnorm})| = h \\cdot w \\cdot \\sum_{c=1}^C(\\log|s_c|)$$\n",
    "\n",
    "​\n",
    "Здесь $s_c$ — это параметр масшта для $c$-го канала, $h\\cdot w$ — количество пикселей в изображении.\n",
    "\n",
    "Вам необходимо реализовать класс `ActNorm`. В конструкторе уже определены параметры `scale`, `bias` и флаг `initialized`.\n",
    "\n",
    "Ваша задача — заполнить пропуски в методах `forward` и `inverse`.\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21923338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, num_channels: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, num_channels, 1, 1))\n",
    "        \n",
    "        # Register a buffer to track whether the layer has been initialized.\n",
    "        self.register_buffer(\"initialized\", torch.tensor(False, dtype=torch.bool))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Data-dependent initialization: this block runs only once, on the first forward pass.\n",
    "        if not self.initialized:\n",
    "                \n",
    "            # Calculate mean and std for each channel\n",
    "            mean = ...\n",
    "            std = ...\n",
    "                \n",
    "            # Initialize scale and bias using the calculated statistics.\n",
    "            # To make the output have mean=0, std=1, we need b = -mean and s = 1/std.\n",
    "            ...\n",
    "                \n",
    "            # Mark the layer as initialized\n",
    "            ...\n",
    "\n",
    "        # Apply the forward affine transformation\n",
    "        z = ...\n",
    "        \n",
    "        # Calculate the log-determinant of the Jacobian for the forward pass.\n",
    "        logdet = ...\n",
    "        \n",
    "        return z, logdet\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply the inverse transformation.\n",
    "        x = ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed725f",
   "metadata": {},
   "source": [
    "### Задание 3: Invertible 1x1 Convolution (1.5 балла)\n",
    "\n",
    "В **слоях связи** (**Affine Coupling Layers**) за один шаг преобразование затрагивает только половину каналов. Чтобы модель была мощной, информация между этими шагами должна \"перемешиваться\", позволяя всем каналам влиять друг на друга. В RealNVP для этого использовалась фиксированная перестановка каналов. Это работало, но было неоптимально, так как модель не могла \"научиться\" лучшему способу перемешивания.\n",
    "\n",
    "В **Glow** для этого предложили использовать **обратимую свертку $1\\times 1$** (`Invertible 1x1 Convolution`). С точки зрения математики, свертка $1\\times1$ с матрицей весов $\\mathbf{W}$ размера $C\\times C$ эквивалентна умножению вектора каналов C на эту матрицу для каждого пикселя в изображении. Таким образом, эта свертка и есть наше обучаемое перемешивание.\n",
    "\n",
    "Основная сложность здесь — вычислить детерминант якобиана. Для свертки $1\\times1$ якобиан — это и есть матрица весов $\\mathbf{W}$. Прямое вычисление $\\det(\\mathbf{W})$ имеет сложность $\\mathcal{O}(C^3)$. Чтобы избежать этого, авторы **Glow** параметризуют матрицу $\\mathbf{W}$ через ее `LU-разложение`:\n",
    "\n",
    "$$\\mathbf{W}=\\mathbf{P}\\mathbf{L}(\\mathbf{U}+diag(\\mathbf{s}))$$\n",
    "\n",
    "где $\\mathbf{P}$ — матрица перестановки, $\\mathbf{L}$ — нижнетреугольная матрица, $\\mathbf{U}$ — верхнетреугольная матрица с нулями на диагонали, $diag(\\mathbf{s})$ - диагональная матрица, у которой на диагонали стоят элементы вектора $\\mathbf{s}$, а в остальных местах — нули.\n",
    "\n",
    "В результате мы получим, что \n",
    "\n",
    "$$\\log|\\det(\\mathbf{J}^{Conv1x1 ​ })| = h \\cdot w \\cdot \\log |\\det (\\mathbf{W})|$$\n",
    "\n",
    "$$\\log|\\det(\\mathbf{W})| = \\sum_{c=1}^C \\log|s_c|,$$\n",
    "\n",
    "где $s_c$ — диагональные элементы матрицы $\\mathbf{U}$.\n",
    "\n",
    "В этом задании вам предстоит реализовать слой `Invertible1x1Conv`.\n",
    "\n",
    "Для выполнения задания рекомендуем ознакомиться с [`LU-разложением`](https://docs.pytorch.org/docs/stable/generated/torch.linalg.lu.html) в `Pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c31b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invertible1x1Conv(nn.Module):\n",
    "    def __init__(self, num_channels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize with a random orthogonal matrix\n",
    "        w_init = torch.linalg.qr(torch.randn(num_channels, num_channels))[0]\n",
    "        \n",
    "        # Perform LU-decomposition\n",
    "        ...\n",
    "        \n",
    "        # Extract diagonal elements 's' from U\n",
    "        ...\n",
    "        \n",
    "        # Register P (permutation), sign_s, L and U masks as non-trainable buffers\n",
    "        ...\n",
    "\n",
    "        # Define L, U (without diagonal) and log_s as learnable parameters\n",
    "        ...\n",
    "        \n",
    "    def _calculate_weight(self, inverse: bool) -> torch.Tensor:\n",
    "        \n",
    "        # Reconstruct L from the learnable part self.l and an identity matrix\n",
    "        l = ...\n",
    "        \n",
    "        # Reconstruct U\n",
    "        u = ...\n",
    "        \n",
    "        if inverse:\n",
    "            w_inv = ...\n",
    "            return w_inv\n",
    "        else:\n",
    "            w = ...\n",
    "            return w\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # Get the weight matrix\n",
    "        weight = ...\n",
    "        \n",
    "        # Apply the 1x1 convolution\n",
    "        z = ...\n",
    "        \n",
    "        # Calculate the log-determinant\n",
    "        logdet = ...\n",
    "        \n",
    "        return z, logdet\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Get the inverse weight matrix\n",
    "        weight_inv = ...\n",
    "        \n",
    "        # Apply the inverse 1x1 convolution\n",
    "        x = ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fecae1",
   "metadata": {},
   "source": [
    "### Задание 4: Affine Coupling Layers (1 балл)\n",
    "\n",
    "Основой как RealNVP, так и Glow, является **афинный слой связи** (**Affine Coupling Layer**). Его дизайн был настолько удачен, что в Glow он остался без изменений. \n",
    "\n",
    "Напомним, что в таких слоях входной вектор делился на две части $\\mathbf{x}_{1:d}$ и $\\mathbf{x}_{d+1:D}$, а латентный вектор $\\mathbf{z}$ получался следующим образом:\n",
    "\n",
    "$$\\begin{cases} \\mathbf{z}_{1:d} &= \\mathbf{x}_{1:d} \\\\ \\mathbf{z}_{d+1:D} &= \\mathbf{x}_{d+1:D}\\odot e^{s(\\mathbf{x}_{1:d})} + t(\\mathbf{x}_{1:d}) \\end{cases}$$\n",
    "\n",
    "Благодаря такому преобразованию, искомый определитель якобиана вычислялся очень просто:\n",
    "\n",
    "$$\\det(\\mathbf{J}) = \\prod_{j=1}^{D-d}e^{s(\\mathbf{x}_{1:d})_j} = e^{\\sum_{j=1}^{D-d} s(\\mathbf{x}_{1:d})_j}$$\n",
    "\n",
    "$$\\log|\\det(\\mathbf{J}^{Coupling})| = \\sum_{j=1}^{D-d} s(\\mathbf{x}_{1:d})_j$$\n",
    "\n",
    "В этом задании вам предстоит реализовать слой `AffineCouplingLayer`. В конструкторе уже определена нейросеть `self.net`, которая будет вычислять параметры `s` и `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b85a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(nn.Module):\n",
    "    def __init__(self, num_channels: int, hidden_channels: int = 512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(num_channels // 2, hidden_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_channels, num_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        # We initialize the last layer with zeros, so the whole coupling layer starts\n",
    "        # as a near-identity function (z ≈ x), which ensures a stable start to training.\n",
    "        self.net[-1].weight.data.zero_()\n",
    "        self.net[-1].bias.data.zero_()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Split the input tensor into two halves along the channel dimension\n",
    "        x_a, x_b = ... \n",
    "        \n",
    "        # Pass one half through the network to get the parameters for the other half and get log_s and t\n",
    "        log_s, t = ...\n",
    "        \n",
    "        # Get s\n",
    "        s = ...\n",
    "    \n",
    "        #  Apply the affine transformation to the other half\n",
    "        z_b = ...\n",
    "        \n",
    "        # Concatenate the transformed half and the unchanged half\n",
    "        z = ... \n",
    "        \n",
    "        #  Calculate the log-determinant\n",
    "        logdet = ...\n",
    "        \n",
    "        return z, logdet\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # Split the input tensor z into two halves\n",
    "        z_a, z_b = ...\n",
    "        \n",
    "        # Pass the unchanged half to get the parameters\n",
    "        log_s, t = ...\n",
    "        s = ...\n",
    "        \n",
    "        # Apply the inverse affine transformation\n",
    "        x_b = ...\n",
    "        \n",
    "        # Concatenate the result with the unchanged half\n",
    "        x = ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe98514",
   "metadata": {},
   "source": [
    "### Задание 5: Squeeze (0.5 балла)\n",
    "\n",
    "Операция **сжатия** (**Squeeze**) является важной особенностью **Multi-Scale архитектуры**, унаследованной от `RealNVP`. Её задача — изменить форму тензора, преобразуя пространственные размерности в канальные.\n",
    "\n",
    "В этом задании вам нужно реализовать прямое и обратное преобразование для слоя `Squeeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff73ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze(nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Reshape the tensor to factor out 2x2 blocks from spatial dimensions\n",
    "        x = ...\n",
    "        \n",
    "        # Permute the dimensions to bring the 2x2 factors next to the channel dimension\n",
    "        x = ...\n",
    "        \n",
    "        # Reshape again to merge the new dimensions with the channel dimension.\n",
    "        x = ...\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # Reshape to factor out the channel dimension back into 2x2 blocks.\n",
    "        z = ...\n",
    "        \n",
    "        # Permute the dimensions to move the 2x2 blocks back to the spatial dimensions.\n",
    "        z = ...\n",
    "        \n",
    "        # Reshape again to get the final output.\n",
    "        z = ...\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20203c54",
   "metadata": {},
   "source": [
    "### Задание 6: Split and GaussianPrior (1 балл)\n",
    "\n",
    "**Multi-Scale архитектура** `Glow/RealNVP` работает по принципу **factoring out**. На каждом уровне (кроме последнего) мы **отщепляем** половину каналов, превращая их в латентные переменные $\\mathbf{z}$, а оставшуюся часть отправляем снова в модель. За это отвечают слои `Split` и `GaussianPrior`.\n",
    "\n",
    "- Задача `Split`разделить входной тензор $\\mathbf{x}$ на две половины, $\\mathbf{x}_1$ и $\\mathbf{x}_2$, затем передать их в `GaussianPrior` для обработки и собирать результаты.\n",
    "\n",
    "- `GaussianPrior` принимает $\\mathbf{x}_1$ как условие и $\\mathbf{x}_2$ как таргет. С помощью нейросети он предсказывает параметры `mean` и `log_std` нормального распределения для $\\mathbf{x}_2$, основываясь на $\\mathbf{x}_1$. Затем он использует эти параметры, чтобы выполнить преобразование из $\\mathbf{x}_2$ в $\\mathbf{z}_2$ и вычислить `logdet`.\n",
    "\n",
    "<center><img src=\"images/factor_out.png\" width=250></center>\n",
    "\n",
    "Важная операция внутри `GaussianPrior` — это стандартизация. Её цель — выполнить обратимое преобразование из $\\mathbf{x}_2$ в $\\mathbf{z}_2$ так, чтобы $\\mathbf{z}_2$ подчинялся простому стандартному нормальному распределению $\\mathcal{N}(\\mathbf{0},\\mathbf{I})$:\n",
    "\n",
    "$$\\mathbf{z}= \\frac{\\mathbf{x} - \\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}$$\n",
    "\n",
    "**Заметка об обозначениях:** В описании выше мы использовали букву $\\mathbf{x}$ для простоты и общности. Однако важно понимать, что операция `Split` применяется **на каждом уровне Multi-Scale архитектуры**, а не только к исходному изображению. Поэтому в коде мы будем использовать букву $\\mathbf{h}$ (**hidden**), которая обозначает скрытое состояние на промежуточных слоях.\n",
    "\n",
    "**Hint**:\n",
    "Деление на `std` эквивалентно умножению на $e^{-log\\_std}$.\n",
    "\n",
    "Вам необходимо реализовать классы `GaussianPrior` и `Split`, заполнив пропуски в коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPrior(nn.Module):\n",
    "    def __init__(self, num_channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Conv2d(num_channels, 2 * num_channels, kernel_size=3, padding=1)\n",
    "        # Initialize with zeros for a stable start\n",
    "        self.net.weight.data.zero_()\n",
    "        self.net.bias.data.zero_()\n",
    "\n",
    "    def forward(self, h1: torch.Tensor, h2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Predict parameters for the distribution of h2, conditioned on h1.\n",
    "        mean, log_std = ...\n",
    "        \n",
    "        # Transform h2 into z2 using the standardization formula.\n",
    "        z2 = ...\n",
    "        \n",
    "        # Calculate the log-determinant\n",
    "        logdet = ...\n",
    "        \n",
    "        return z2, logdet\n",
    "    \n",
    "    def inverse(self, h1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:\n",
    "        # Predict parameters from h1, just like in the forward pass.\n",
    "        mean, log_std = ...\n",
    "        \n",
    "        # Perform the inverse transformation to generate h2 from the noise z2.\n",
    "        h2 = ...\n",
    "        \n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e444247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(nn.Module):\n",
    "    def __init__(self, num_channels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.prior = GaussianPrior(num_channels // 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Split the input tensor into two halves\n",
    "        x1, x2 = ...\n",
    "        \n",
    "        # Delegate the transformation of x2 to the prior.\n",
    "        z2, logdet = ... \n",
    "        \n",
    "        return x1, z2, logdet\n",
    "\n",
    "    def inverse(self, x1: torch.Tensor, z2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Delegate the inverse transformation to the prior.\n",
    "        x2 = ... \n",
    "        \n",
    "        # Concatenate x1 and the reconstructed x2.\n",
    "        x = ... \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88707a1",
   "metadata": {},
   "source": [
    "### Задание 7: Preprocess (0.5 балла)\n",
    "\n",
    "Как вы знаете, нормализующие потоки по своей природе работают с непрерывными данными, в то время как изображения состоят из дискретных пикселей от $0$ до $255$. Чтобы подружить модель с данными, мы будем применять специальный слой предобработки, который выполняет две функции:\n",
    "\n",
    "1. **Деквантизация** (**Dequantization**): Здесь мы превращаем дискретные значения в непрерывные. Стандартный способ — добавить к каждому значению пикселя равномерный шум из распределения $\\mathcal{U}(0, \\frac{1}{256})$. Это \"размывает\" каждое дискретное значение, что делает данные совместимыми с моделью.\n",
    "\n",
    "2. **Центрирование** (**Centering**): Большинство нейронных сетей лучше обучаются, когда их входные данные центрированы вокруг нуля, поэтому мы сдвигаем диапазон данных из $[0, 1]$ в $[-0.5, 0.5]$.\n",
    "\n",
    "Весь этот процесс является обратимым аффинным преобразованием. А значит, мы обязаны вычислить логарифм детерминанта его якобиана, чтобы корректно посчитать итоговое правдоподобие. Для масштабирования на $\\frac{1}{256}$ `logdet` на один пиксель равен $\\log(\\frac{1}{256})=−\\log(256)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6847c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:        \n",
    "        # Dequantize the data by adding uniform noise.\n",
    "        x = ...\n",
    "        \n",
    "        # Calculate the log-determinant for this transformation.\n",
    "        logdet = ... \n",
    "        \n",
    "        # Center the data from [0, 1] to [-0.5, 0.5]\n",
    "        z = x - 0.5\n",
    "        \n",
    "        return z, logdet\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Un-center the data from [-0.5, 0.5] back to [0, 1]\n",
    "        x = ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ae0e3",
   "metadata": {},
   "source": [
    "### Задание 8: Flow Step (0.5 балла)\n",
    "\n",
    "До этого момента мы реализовывали отдельные обратимые преобразования. Теперь наша задача — объединить их в единый блок `Flow Step`, который и будет составлять основу нашей нейросети. В модели `Glow` каждый `FlowStep` представляет собой композицию из трех последовательных преобразований, которые мы уже реализовали:\n",
    "\n",
    "1. `ActNorm`\n",
    "\n",
    "2. `Invertible1x1Conv`\n",
    "\n",
    "3. `AffineCouplingLayer`\n",
    "\n",
    "Вам необходимо реализовать класс `FlowStep`, который последовательно применяет слои `ActNorm`, `Invertible1x1Conv` и `AffineCoupling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae914abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowStep(nn.Module):\n",
    "    def __init__(self, num_channels: int, hidden_channels: int):\n",
    "        super().__init__()\n",
    "        self.actnorm = ...\n",
    "        self.conv = ...\n",
    "        self.coupling = ...\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # Apply the transformations in the correct forward order and accumulate the log-determinants\n",
    "        x, logdet_act = ...\n",
    "        x, logdet_conv = ...\n",
    "        x, logdet_coupling = ...\n",
    "        \n",
    "        # Sum the log-determinants from each step\n",
    "        total_logdet = ...\n",
    "        return x, total_logdet\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Apply the inverse transformations in the reverse order.\n",
    "        z = ...\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2314b",
   "metadata": {},
   "source": [
    "### Задание 9: MultiScaleBlock (1 балл)\n",
    "\n",
    "Основная идея **MultiScale архитектуры** — обработка данных на разных масштабах. На каждом уровне модель анализирует текущее представление данных, **отщепляет** (**factor out**) часть информации, которую она уже смогла смоделировать, а оставшуюся часть передает дальше.\n",
    "\n",
    "`MultiScaleBlock` состоит из трех последовательных этапов, которые мы уже реализовали:\n",
    "\n",
    "1. `Squeeze`: Пространственное разрешение уменьшается, а глубина каналов увеличивается.\n",
    "\n",
    "2. `K шагов FlowStep`: К новому представлению применяется композиция из $K$ обратимых преобразований.\n",
    "\n",
    "3. `Split`: Половина обработанных каналов **отщепляется** и превращается в латентные переменные $\\mathbf{z}$, другая половина передается на вход следующему `MultiScaleBlock`.\n",
    "\n",
    "Этот процесс повторяется несколько раз. Самый последний блок в модели не выполняет `Split`, так как передавать оставшиеся данные уже некуда.\n",
    "\n",
    "Вам необходимо реализовать класс `MultiScaleBlock`, который объединяет ранее созданные вами слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleBlock(nn.Module):\n",
    "    def __init__(self, num_channels: int, num_flows: int, hidden_channels: int, split: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.squeeze = Squeeze()\n",
    "        \n",
    "        # Calculate the number of channels after the Squeeze operation\n",
    "        squeezed_channels = ... \n",
    "        \n",
    "        # Initialize a list of FlowStep layers\n",
    "        self.flow_steps = ...\n",
    "        \n",
    "        # Initialize the Split layer if required\n",
    "        self.split = split\n",
    "        if self.split:\n",
    "            self.split_layer = ...\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - x_out: The tensor to be passed to the next level.\n",
    "        - logdet_sum: The total log-determinant from all operations in this block.\n",
    "        - z_split: The factored-out latent z, or None if split=False.\n",
    "        \"\"\"\n",
    "        x = self.squeeze(x)\n",
    "        \n",
    "        # Initialize the log-determinant accumulator for this block\n",
    "        logdet_sum = ...\n",
    "        \n",
    "        # Apply the sequence of FlowSteps\n",
    "        for flow in self.flow_steps:\n",
    "            # Get the output tensor and the logdet from the flow step\n",
    "            x, logdet = ...\n",
    "            logdet_sum = ...\n",
    "            \n",
    "        z_split = None\n",
    "        # Apply the Split layer if this is not the last block\n",
    "        if self.split:\n",
    "            # The Split layer returns the ongoing tensor x, the factored-out z, and its logdet\n",
    "            x, z, logdet = ...\n",
    "            logdet_sum = ...\n",
    "            z_split = z\n",
    "            \n",
    "        return x, z_split, logdet_sum\n",
    "\n",
    "    def inverse(self, x_next: torch.Tensor, z_split: Optional[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Accepts:\n",
    "        - x_next: The output from the next (deeper) block.\n",
    "        - z_split: The factored-out z that was created by this block during the forward pass.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the inverse Split operation first (if it exists) to reconstruct the tensor\n",
    "        if self.split:\n",
    "            # Reconstruct the full tensor before the Squeeze operation\n",
    "            x = ...\n",
    "        else:\n",
    "            x = ...\n",
    "\n",
    "        # Apply the inverse of FlowSteps in reverse order\n",
    "        for flow in reversed(self.flow_steps):\n",
    "            x = ...\n",
    "            \n",
    "        # Apply the inverse Squeeze operation\n",
    "        x = ...\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37375f7c",
   "metadata": {},
   "source": [
    "### Задание 10: Glow (1 балл)\n",
    "\n",
    "Нам остался последний шаг — собрать все компоненты вместе.\n",
    "\n",
    "Вам предстоит собрать финальный класс `Glow`. Все необходимые блоки у вас уже есть.\n",
    "\n",
    "#### Bits Per Dimension\n",
    "\n",
    "Когда мы обучаем генеративные модели, мы максимизируем логарифм правдоподобия $\\log p_{\\boldsymbol{\\theta}}(\\mathbf{x})$. Однако сами по себе эти значения не очень интуитивны. Что значит $\\log p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = 1500$? Это хороший или плохой результат? Более того, это значение сильно зависит от размера изображения — для картинки $64\\times 64$ оно будет гораздо ниже, чем для $32\\times 32$, что мешает сравнивать модели.\n",
    "\n",
    "Чтобы решить эти проблемы, используется более интерпретируемая метрика — **биты на размерность** (**Bits Per Dimension**, **BPD**).\n",
    "\n",
    "**BPD** — это среднее количество бит, которое требуется нашей модели для кодирования одной размерности данных (одного цветового канала одного пикселя).\n",
    "\n",
    "Чем ниже BPD, тем лучше. Низкий BPD означает, что модель хорошо выучила распределение данных, считает их очень вероятными и может \"сжать\" их с минимальными затратами.\n",
    "\n",
    "Оптимальное количество бит, необходимое для кодирования события с вероятностью $p(\\mathbf{x})$, равно $-\\log p(\\mathbf{x})$. Наша модель вычисляет $\\ln p(\\mathbf{x})$. Чтобы перейти к логарифму по основанию $2$, используется простая формула $\\log_2 p(\\mathbf{x})= \\frac{\\ln p(\\mathbf{x})}{ln(2)}$. Таким образом, общее число бит для кодирования всего изображения равно $-\\frac{\\ln p(\\mathbf{x})}{ln(2)}$.\n",
    "\n",
    "Чтобы получить среднее значение на размерность, мы делим общее число бит на количество всех размерностей и получаем финальную формулу для **BPD**:\n",
    "\n",
    "$$BPD = -\\frac{\\ln p(\\mathbf{x})}{ln(2)\\cdot h\\cdot w\\cdot c}$$\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "Исходные 8-битные цветные изображения требуют ровно $8$ бит на каждую размерность. Модель, которая не выучила ничего, будет иметь **BPD** около $8.0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glow(nn.Module):\n",
    "    \"\"\"\n",
    "    The final, complete Glow model, built using the MultiScaleBlock abstraction.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: Tuple[int, int, int], num_levels: int, num_flows_per_level: int, hidden_channels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.preprocess = Preprocess()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        C, H, W = input_shape\n",
    "        current_channels = C\n",
    "        for i in range(num_levels):\n",
    "            is_last_block = (i == num_levels - 1)\n",
    "            # Append a MultiScaleBlock to the self.blocks list, use the `split` argument to control whether it's the last block.\n",
    "            self.blocks.append(\n",
    "                ...\n",
    "            )\n",
    "            # Update the number of channels for the next block.\n",
    "            if not is_last_block:\n",
    "                current_channels = ...\n",
    "\n",
    "        # Calculate and store the final shape of z\n",
    "        self.final_z_shape = self._calculate_final_z_shape(input_shape, num_levels)\n",
    "        \n",
    "        self.register_buffer('base_dist_mean', torch.zeros(1))\n",
    "        self.register_buffer('base_dist_var', torch.ones(1))\n",
    "\n",
    "    def _calculate_final_z_shape(self, input_shape: Tuple[int, int, int], num_levels: int) -> Tuple[int, int, int]:\n",
    "        C, H, W = input_shape\n",
    "        for i in range(num_levels):\n",
    "            H //= 2\n",
    "            W //= 2\n",
    "            C *= 4\n",
    "            \n",
    "            if i < num_levels - 1:\n",
    "                C //= 2\n",
    "        return C, H, W\n",
    "\n",
    "    @property\n",
    "    def base_dist(self):\n",
    "        return D.Normal(self.base_dist_mean, self.base_dist_var)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[List[torch.Tensor], torch.Tensor]:\n",
    "        zs = []\n",
    "        # Apply the preprocessing layer and get the initial logdet\n",
    "        x, logdet_sum = ...\n",
    "\n",
    "        for block in self.blocks:\n",
    "            # Pass x through the block and get the outputs\n",
    "            x, z_split, logdet = ...\n",
    "            \n",
    "            # Accumulate the log-determinant\n",
    "            logdet_sum = ...\n",
    "            \n",
    "            # If z_split is not None, add it to the list of zs\n",
    "            if z_split is not None:\n",
    "                ...\n",
    "        \n",
    "        # Append the final x (which is the last z) to the list\n",
    "        ...\n",
    "        \n",
    "        return zs, logdet_sum\n",
    "\n",
    "    def inverse(self, batch_size: int, z_std: float = 1.0) -> torch.Tensor:\n",
    "        device = self.base_dist_mean.device\n",
    "        \n",
    "        # Start by sampling z from the base distribution\n",
    "        C, H, W = self.final_z_shape\n",
    "        x = self.base_dist.sample((batch_size, C, H, W)).squeeze(-1).to(device) * z_std\n",
    "        \n",
    "        # Loop through the blocks in reverse order\n",
    "        for block in reversed(self.blocks):\n",
    "            # If the block had a split, we need to generate a z_split to merge with x\n",
    "            if block.split:\n",
    "                # Generate z_split on the fly, with the same shape as x\n",
    "                z_split = ...\n",
    "                x = ...\n",
    "            else:\n",
    "                x = ...\n",
    "        \n",
    "        # Apply the inverse of the preprocessing layer\n",
    "        x = ...\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def log_prob(self, x: torch.Tensor, bits_per_pixel: bool = True) -> torch.Tensor:\n",
    "       \n",
    "        # Get the latent variables and the total log-determinant from the forward pass\n",
    "        zs, logdet = ...\n",
    "        \n",
    "        # Calculate the log-probability of each z under the base distribution.\n",
    "        base_log_prob = ...\n",
    "        \n",
    "        # Combine everything using the Change of Variables formula.\n",
    "        log_prob = ...\n",
    "\n",
    "        if bits_per_pixel:\n",
    "            # Convert log-likelihood to bits per dimension\n",
    "            bpd = ...\n",
    "            return bpd\n",
    "            \n",
    "        return log_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea805d8",
   "metadata": {},
   "source": [
    "### Задание 11: Sampling, Training and Validation Loop (0.5 балла)\n",
    "\n",
    "Теперь, когда у нас есть полностью собранная модель Glow, нам нужно ее обучить. Процесс обучения, валидации и генерации реализован в нескольких вспомогательных функциях. Ваша задача - заполнить недостающие части кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, n_samples=5, z_std=0.7):\n",
    "    model.eval()\n",
    "    samples = ...\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, device, grad_clip=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_x in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        x = ...\n",
    "\n",
    "        loss = ...\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        total_loss += ...\n",
    "\n",
    "    return ...\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_x in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "        x = ...\n",
    "        loss = ...\n",
    "        total_loss += ...\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c648b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Bits per dim')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(images, nrow=5, title=None):\n",
    "    if images.min() < 0:\n",
    "        images = images - images.min()\n",
    "        images = images / images.max()\n",
    "\n",
    "    grid = make_grid(images, nrow=nrow, padding=2)\n",
    "    np_img = grid.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(nrow * 2, (len(images) // nrow + 1) * 2))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.imshow(np_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path_template):\n",
    "    save_path = path_template.format(epoch=epoch)\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, save_path)\n",
    "\n",
    "    print(f\"Checkpoint saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13203b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, optimizer, train_loader, val_loader, num_epochs, device,\n",
    "                       grad_clip=None, checkpoint_path=None):\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = ...\n",
    "        val_loss = ...\n",
    "\n",
    "        print(f\"[Epoch {epoch}/{num_epochs}] Train: {train_loss :.4f} | Val: {val_loss:.4f}\")\n",
    "        \n",
    "        plot_losses(train_losses, val_losses)\n",
    "\n",
    "        samples = sample(model, n_samples=10, z_std=0.7)\n",
    "        plot_images(samples, nrow=5, title=f\"Epoch {epoch} samples\")\n",
    "\n",
    "        if checkpoint_path:\n",
    "            save_checkpoint(model, optimizer, epoch, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b042398",
   "metadata": {},
   "source": [
    "Итак, мы реализовали все основные блоки, необходимые для обучения модели `Glow`. Теперь осталось собрать все воедино, задать гиперпараметры и запустить процесс обучения. Вы можете экспериментировать с различными гиперпараметрами, чтобы добиться хороших результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "K = 32\n",
    "INPUT_SHAPE = (3, 64, 64)\n",
    "HIDDEN_CHANNELS = 512\n",
    "\n",
    "model = Glow(input_shape=(3, 64, 64), num_levels=L, num_flows_per_level=K, hidden_channels=HIDDEN_CHANNELS)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=50,\n",
    "    device=device,\n",
    "    sample_every=1,\n",
    "    grad_clip=3,\n",
    "    checkpoint_path=\"checkpoints_glow/epoch_{epoch}.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76094757",
   "metadata": {},
   "source": [
    "### Задание 12: Sampling Temperature (0.5 балла)\n",
    "\n",
    "После того как мы обучили модель, мы можем загрузить её, чтобы использовать для генерации. Код ниже загружает веса модели, которые были сохранены во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints_glow/epoch_30.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Model loaded from: {checkpoint_path}\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c933c",
   "metadata": {},
   "source": [
    "Теперь начинается самое интересное — исселедовать процесс генерации. Какой параметр, по вашему мнению, отвечает за температуру генерации? Каким образом это происходит?\n",
    "\n",
    "**Ваш ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df8306",
   "metadata": {},
   "source": [
    "Проверьте вашу гипотезу на практике. Сгенерируйте по $20$ изображений c различными значениями этого параметра и сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ \n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a97e2a",
   "metadata": {},
   "source": [
    "### Задание 13: Latent Space (0.5 балла)\n",
    "\n",
    "До сих пор мы рассматривали нашу модель как \"черный ящик\", который при обратном проходе возвращает изображение. Но самое интересное происходит в его латентном пространстве.\n",
    "\n",
    "**Латентное пространство** — это многомерное векторное пространство, в котором модель хранит свое понимание данных в некотором структурированном виде. \n",
    "\n",
    "В плохой, необученной модели это пространство хаотично. Но хорошо обученная модель организует его осмысленно.\n",
    "\n",
    "**Свойства \"хорошего\" латентного пространства**:\n",
    "\n",
    "- **Гладкость**: Точки, которые находятся близко друг к другу в латентном пространстве, должны соответствовать визуально похожим изображениям. Если мы возьмем вектор $\\mathbf{z}$ и немного его сдвинем, получив $\\mathbf{z}'$, то сгенерированное изображение $\\mathbf{x}'$ должно лишь слегка отличаться от исходного $\\mathbf{x}$.\n",
    "\n",
    "- **Семантическая структура**: Модель часто учится выстраивать в пространстве целые направления, соответствующие осмысленным атрибутам. Например, движение вдоль одной оси может делать лицо на картинке более улыбчивым, а движение вдоль другой — изменять цвет волос.\n",
    "\n",
    "Мы можем проверить, что наша модель действительно выучила такое гладкое и осмысленное пространство с помощью линейной интерполяции:\n",
    "\n",
    "1. Мы берем два разных изображения, например, мужское лицо ($\\mathbf{x}_{man}$) и женское ($\\mathbf{x}_{woman}$).\n",
    "\n",
    "2. Находим их вектора в латентном пространстве: $\\mathbf{z}_{man}= f(\\mathbf{x}_{man})$ и $\\mathbf{z}_{woman}= f(\\mathbf{x}_{woman})$\n",
    "\n",
    "3. Поскольку $\\mathbf{z}$ — это просто векторы, мы можем найти любую точку на прямой линии между ними по формуле:\n",
    "\n",
    "$$\\mathbf{z}_{interp} =  (1-\\alpha)\\cdot \\mathbf{x}_{man} + \\alpha \\cdot \\mathbf{x}_{woman}$$\n",
    "\n",
    "Если пространство действительно гладкое и осмысленное, то, декодируя эти промежуточные точки $\\mathbf{z}_{interp}$, мы должны увидеть плавный правдоподобный переход одного изображения в другое.\n",
    "\n",
    "В этом задании вам предстоит реализовать две новые функции:\n",
    "\n",
    "- `inverse_reconstruct`: декодер, который принимает на вход конкретный список латентных векторов `zs` и восстанавливает из них изображение.\n",
    "\n",
    "- `interpolate_glow`: функция для интерполяции, которая будет использовать `inverse_reconstruct` для визуализации плавного перехода между двумя изображениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_reconstruct(model, zs: List[torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Performs the inverse pass from a given list of latent tensors `zs`.\n",
    "    \"\"\"\n",
    "    \n",
    "    #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ \n",
    "    # Your code here\n",
    "    \n",
    "    return ...\n",
    "\n",
    "def interpolate_glow(model, image1: torch.Tensor, image2: torch.Tensor, num_steps: int, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Performs latent space interpolation between two images using the Glow model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x1 = image1.unsqueeze(0).to(device)\n",
    "    x2 = image2.unsqueeze(0).to(device)\n",
    "\n",
    "    # Encode the two images to get their latent representations using the model's forward pass.\n",
    "    zs1, _ = ...\n",
    "    zs2, _ = ...\n",
    "\n",
    "    # For simplicity, we will only interpolate the last (deepest) z-vector in the list.\n",
    "    z1_deepest = zs1[-1]\n",
    "    z2_deepest = zs2[-1]\n",
    "    \n",
    "    # Create a tensor of alpha values for interpolation (from 0.0 to 1.0).\n",
    "    alphas = ...\n",
    "    \n",
    "    interpolated_images = []\n",
    "    for alpha in tqdm(alphas, desc=\"Generating interpolation\"):\n",
    "        # Calculate the interpolated z-vectors \n",
    "        ...\n",
    "        \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32bfa8",
   "metadata": {},
   "source": [
    "Найдите в валидационном датасете пары изображений, соответствующие описаниям ниже, и, используя реализованные вами функции для каждой пары выполните интерполяцию с `num_steps=10`:\n",
    "\n",
    "- **Мужчина** $\\rightarrow$ **Женщина**\n",
    "- **Улыбающееся лицо** $\\rightarrow$ **Нейтральное лицо**\n",
    "- **Светлые волосы** $\\rightarrow$ **Темные волосы**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d26553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ \n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b43d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь можно оставить отзывы, пожелания и впечатления о ДЗ :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
